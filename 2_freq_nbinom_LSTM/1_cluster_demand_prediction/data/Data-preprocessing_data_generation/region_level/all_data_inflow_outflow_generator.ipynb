{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3261c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file can be used to generate inflfow and outflow at BOTH cluster-level (H=60 ,d = 0.5) and station-level (H=10 ,d = 0.01)\\n\\ncluster parameters:\\ncolumns=[\"start_cluster\"] #for station demand\\nH,d = 60,0.5 \\n\\nstation parameters:\\ncolumns=[\"start_station\"] #for station demand\\nH,d = 10,0.01 \\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file can be used to generate inflfow and outflow at BOTH cluster-level (H=60 ,d = 0.5) and station-level (H=10 ,d = 0.01)\n",
    "\n",
    "cluster parameters:\n",
    "columns=[\"start_cluster\"] #for station demand\n",
    "H,d = 60,0.5 \n",
    "\n",
    "station parameters:\n",
    "columns=[\"start_station\"] #for station demand\n",
    "H,d = 10,0.01 \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "334e549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from haversine import haversine_vector, Unit\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf4fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_clustering(H,demand):\n",
    "    \n",
    "    def str_to_dt(dt_str):\n",
    "        return datetime.datetime.strptime(dt_str, '%H:%M:%S').time()\n",
    "\n",
    "    \n",
    "    # temporal clustering\n",
    "    demand.insert(3,'start_timeslot', demand['start_time'].apply(lambda x:int(np.floor((60*str_to_dt(x).hour + str_to_dt(x).minute)/H))))\n",
    "    demand.insert(6,'end_timeslot', demand['end_time'].apply(lambda x:int(np.floor((60*str_to_dt(x).hour + str_to_dt(x).minute)/H))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71abd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_clustering(d,demand):\n",
    "    stations = pd.read_csv('stations.csv',index_col=0)\n",
    "    \n",
    "    stn_coords = list(zip(stations.y, stations.x))\n",
    "\n",
    "    D = haversine_vector(stn_coords, stn_coords, Unit.KILOMETERS, comb=True)\n",
    "    R = 1*(D < d) # 1 km threshold\n",
    "    \n",
    "    # ilp to select cluster centers\n",
    "    x = cp.Variable((len(stations),),boolean=True)\n",
    "    prob = cp.Problem(cp.Minimize(cp.sum(x)), [x.T@R>=1])\n",
    "    prob.solve()\n",
    "    \n",
    "    # map each station to a cluster\n",
    "    stations['cc'] = x.value\n",
    "    cluster_centers = stations.loc[stations.cc==1]\n",
    "    cc_coords = list(zip(cluster_centers.y, cluster_centers.x))\n",
    "    stations['cc_id'] = np.argmin(haversine_vector(cc_coords, stn_coords, Unit.KILOMETERS, comb=True), axis=1)\n",
    "    \n",
    "    station_to_cluster_map = dict(zip(stations.index, stations.cc_id))\n",
    "    \n",
    "    # spatial clustering\n",
    "    demand['start_cluster'] = demand['start_station'].apply(lambda x: station_to_cluster_map[x])\n",
    "    demand['end_cluster'] = demand['end_station'].apply(lambda x: station_to_cluster_map[x])\n",
    "    \n",
    "    return station_to_cluster_map, stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db67aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' windows \\ncd C:\\\\Work\\\\WORK_PACKAGE\\\\Demand_forecasting\\\\github\\x08lue-sg/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" windows \n",
    "cd C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\blue-sg/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "030b7519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/optimusprime/Desktop/peeterson/github/DeepAR_demand_prediction/2_freq_nbinom_LSTM/1_cluster_demand_prediction/data/demand_data/standalone'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43159661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{34: 2, 20: 0, 298: 1, 140: 1, 329: 1, 285: 2, 272: 2, 286: 3, 203: 4, 294: 5, 328: 8, 195: 5, 46: 6, 119: 7, 355: 8, 77: 8, 93: 10, 192: 9, 35: 10, 348: 9, 163: 10, 310: 11, 202: 11, 318: 12, 245: 12, 206: 13, 352: 14, 190: 11, 178: 15, 129: 16, 166: 16, 345: 16, 370: 17, 29: 171, 18: 18, 331: 19, 218: 19, 251: 19, 56: 20, 249: 21, 149: 22, 154: 23, 326: 23, 210: 24, 191: 23, 32: 25, 239: 24, 388: 27, 278: 25, 306: 25, 186: 26, 170: 27, 94: 30, 139: 28, 141: 31, 377: 29, 116: 30, 209: 34, 376: 45, 151: 30, 385: 33, 132: 32, 78: 31, 366: 32, 150: 31, 320: 33, 9: 33, 155: 34, 389: 35, 288: 34, 58: 34, 323: 36, 162: 39, 43: 36, 330: 36, 325: 37, 118: 38, 110: 39, 15: 39, 341: 37, 307: 40, 84: 40, 304: 38, 138: 41, 296: 42, 147: 43, 126: 44, 228: 48, 263: 54, 113: 45, 243: 46, 81: 48, 74: 47, 257: 48, 368: 54, 82: 49, 5: 50, 98: 51, 47: 51, 17: 52, 37: 55, 168: 53, 41: 45, 40: 54, 16: 105, 28: 55, 26: 108, 30: 54, 344: 56, 73: 57, 64: 58, 181: 58, 128: 59, 378: 60, 281: 60, 271: 62, 275: 62, 274: 61, 280: 62, 273: 58, 13: 63, 134: 63, 207: 64, 364: 65, 261: 65, 122: 66, 384: 66, 133: 67, 176: 66, 220: 71, 48: 73, 276: 73, 148: 68, 121: 69, 247: 69, 360: 69, 308: 69, 177: 70, 174: 70, 36: 71, 108: 72, 69: 73, 332: 74, 219: 74, 290: 74, 60: 80, 284: 75, 24: 76, 198: 77, 267: 77, 244: 83, 96: 76, 297: 81, 127: 78, 175: 79, 270: 80, 282: 81, 194: 152, 196: 82, 258: 83, 189: 83, 152: 76, 230: 76, 187: 84, 193: 90, 6: 86, 246: 85, 200: 85, 279: 85, 343: 86, 125: 87, 80: 88, 50: 89, 142: 89, 213: 90, 124: 91, 354: 91, 159: 92, 103: 91, 31: 93, 222: 94, 266: 94, 229: 96, 66: 95, 224: 96, 382: 97, 208: 97, 231: 98, 87: 99, 172: 100, 236: 102, 289: 101, 361: 102, 12: 103, 283: 104, 145: 106, 277: 105, 171: 105, 117: 106, 131: 106, 101: 110, 322: 176, 90: 109, 214: 107, 302: 107, 88: 108, 300: 107, 339: 109, 143: 110, 182: 111, 185: 112, 221: 114, 99: 113, 123: 113, 212: 114, 327: 115, 369: 116, 161: 120, 255: 116, 235: 119, 262: 117, 173: 117, 11: 116, 165: 118, 336: 118, 62: 118, 254: 119, 102: 119, 371: 120, 146: 121, 372: 121, 233: 116, 340: 123, 256: 122, 167: 124, 135: 122, 335: 123, 241: 125, 156: 123, 104: 123, 120: 122, 347: 124, 22: 124, 387: 125, 10: 123, 197: 125, 240: 125, 70: 126, 223: 127, 106: 128, 381: 128, 319: 133, 49: 129, 68: 130, 100: 130, 42: 131, 351: 132, 362: 132, 324: 133, 14: 134, 38: 133, 204: 136, 2: 135, 4: 135, 292: 136, 92: 32, 7: 139, 373: 137, 95: 139, 91: 138, 357: 139, 75: 139, 358: 139, 97: 140, 248: 140, 51: 140, 365: 141, 76: 141, 269: 147, 315: 147, 316: 142, 252: 145, 342: 146, 317: 142, 359: 142, 105: 148, 334: 143, 23: 148, 333: 143, 44: 144, 183: 144, 259: 144, 268: 145, 53: 144, 52: 142, 314: 145, 253: 146, 19: 147, 305: 148, 250: 149, 217: 150, 83: 151, 25: 152, 61: 154, 265: 153, 363: 154, 346: 152, 353: 155, 356: 155, 109: 156, 215: 157, 184: 163, 295: 159, 27: 158, 85: 159, 157: 159, 79: 168, 86: 160, 386: 161, 311: 167, 45: 164, 39: 162, 350: 163, 144: 164, 293: 163, 130: 163, 383: 164, 321: 165, 67: 166, 312: 166, 55: 167, 169: 167, 313: 167, 158: 168, 211: 168, 201: 160, 180: 160, 54: 169, 225: 170, 379: 171, 232: 173, 8: 175, 72: 172, 89: 173, 199: 174, 380: 175, 179: 176, 136: 177, 65: 178, 226: 179, 114: 183, 227: 184, 205: 186, 71: 179, 234: 182, 299: 180, 291: 180, 338: 181, 309: 181, 33: 181, 111: 182, 57: 183, 112: 184, 137: 179, 115: 182, 303: 185, 264: 186, 59: 191, 216: 191, 349: 192, 188: 192, 153: 187, 242: 190, 260: 191, 237: 192, 287: 187, 164: 188, 107: 193, 21: 189, 160: 190, 301: 190, 367: 191, 374: 192, 238: 193, 63: 192, 375: 193, 337: 193}\n",
      "start_cluster              0    1    2    3    4    5    6    7    8    9    \\\n",
      "start_date start_timeslot                                                     \n",
      "2021-09-24 0               0.0  2.0  1.0  1.0  0.0  0.0  0.0  0.0  1.0  2.0   \n",
      "           1               2.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "           2               0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "           3               0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "           4               1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...                        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2021-12-23 15              1.0  3.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0   \n",
      "           16              0.0  2.0  1.0  0.0  0.0  1.0  0.0  1.0  2.0  0.0   \n",
      "           17              3.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  2.0  2.0   \n",
      "           18              0.0  1.0  3.0  3.0  2.0  0.0  1.0  1.0  5.0  0.0   \n",
      "           19              0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "start_cluster              ...  184  185  186  187  188  189  190  191  192  \\\n",
      "start_date start_timeslot  ...                                                \n",
      "2021-09-24 0               ...  1.0  0.0  2.0  0.0  0.0  1.0  1.0  1.0  0.0   \n",
      "           1               ...  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  1.0   \n",
      "           2               ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "           3               ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "           4               ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
      "...                        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2021-12-23 15              ...  0.0  2.0  0.0  1.0  1.0  0.0  1.0  0.0  2.0   \n",
      "           16              ...  0.0  0.0  2.0  1.0  1.0  0.0  1.0  2.0  3.0   \n",
      "           17              ...  0.0  2.0  3.0  4.0  0.0  2.0  5.0  1.0  3.0   \n",
      "           18              ...  1.0  2.0  0.0  1.0  0.0  0.0  3.0  3.0  5.0   \n",
      "           19              ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "start_cluster              193  \n",
      "start_date start_timeslot       \n",
      "2021-09-24 0               0.0  \n",
      "           1               0.0  \n",
      "           2               1.0  \n",
      "           3               0.0  \n",
      "           4               0.0  \n",
      "...                        ...  \n",
      "2021-12-23 15              0.0  \n",
      "           16              3.0  \n",
      "           17              3.0  \n",
      "           18              2.0  \n",
      "           19              0.0  \n",
      "\n",
      "[2180 rows x 194 columns]\n",
      "end_cluster              0    1    2    3    4    5    6    7    8    9    \\\n",
      "end_date   end_timeslot                                                     \n",
      "2021-09-24 0             0.0  2.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "           1             0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "           2             1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0   \n",
      "           3             1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
      "           4             0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "...                      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2021-12-23 15            0.0  3.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n",
      "           16            0.0  0.0  0.0  1.0  3.0  1.0  0.0  0.0  3.0  1.0   \n",
      "           17            2.0  2.0  2.0  0.0  1.0  2.0  1.0  2.0  6.0  0.0   \n",
      "           18            0.0  3.0  0.0  2.0  1.0  1.0  1.0  1.0  2.0  0.0   \n",
      "           19            2.0  2.0  0.0  0.0  1.0  0.0  0.0  1.0  2.0  0.0   \n",
      "\n",
      "end_cluster              ...  184  185  186  187  188  189  190  191  192  193  \n",
      "end_date   end_timeslot  ...                                                    \n",
      "2021-09-24 0             ...  0.0  1.0  2.0  0.0  0.0  1.0  0.0  2.0  2.0  1.0  \n",
      "           1             ...  0.0  0.0  0.0  0.0  0.0  1.0  1.0  1.0  0.0  1.0  \n",
      "           2             ...  2.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
      "           3             ...  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "           4             ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "...                      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "2021-12-23 15            ...  1.0  0.0  2.0  0.0  2.0  0.0  2.0  2.0  0.0  2.0  \n",
      "           16            ...  0.0  1.0  2.0  3.0  0.0  1.0  4.0  1.0  4.0  1.0  \n",
      "           17            ...  1.0  3.0  1.0  3.0  0.0  1.0  2.0  7.0  4.0  4.0  \n",
      "           18            ...  3.0  1.0  0.0  1.0  1.0  0.0  2.0  5.0  5.0  5.0  \n",
      "           19            ...  2.0  0.0  0.0  1.0  0.0  0.0  1.0  3.0  3.0  0.0  \n",
      "\n",
      "[2180 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.chdir('/home/optimusprime/Desktop/peeterson/github/DeepAR_demand_prediction/2_freq_nbinom_LSTM/1_cluster_demand_prediction/data/demand_data/standalone')\n",
    "    demand = pd.read_csv('transaction_logs.csv',index_col=0)\n",
    "\n",
    "## start\n",
    "# DATAFRAME T cluster level demand\n",
    "\n",
    "    H,d = 60,0.5 # H:Timeslot duration in minutes, d = radius for clustering in km\n",
    "    #temporal clustering\n",
    "    temporal_clustering(H,demand)\n",
    "    \n",
    "    #spatial clustering\n",
    "    station_to_cluster_map, stations = spatial_clustering(d,demand)\n",
    "    print(station_to_cluster_map)\n",
    "    #print(stations['region'])\n",
    "    stations.to_csv('station_cc_id_'+str(H)+'_'+str(d)+'.csv', index=False)\n",
    "\n",
    "    #aggregated demand table\n",
    "    T = pd.pivot_table(demand, values = 'car', index=[\"start_date\",\"start_timeslot\"], columns=[\"start_cluster\"], aggfunc=lambda x: len(x.unique()))\n",
    "    IN = pd.pivot_table(demand, values = 'car', index=[\"end_date\",\"end_timeslot\"], columns=[\"end_cluster\"], aggfunc=lambda x: len(x.unique()))\n",
    "    IN.fillna(0, inplace=True)\n",
    "    T.fillna(0, inplace=True)\n",
    "    \n",
    "    # missing_clusters = [x for x in range(T.columns[-1]) if x not in T.columns]\n",
    "    # missing_clusters.sort()\n",
    "\n",
    "    # for ms in missing_clusters:\n",
    "    #     T.insert(ms, ms, 0)\n",
    "    \"\"\"\n",
    "    Ensure that the index of T and IN are of the same length and aligned\n",
    "\n",
    "    \"\"\"\n",
    "    start_idx = max(IN.index[0],T.index[0])\n",
    "    end_idx = min(IN.index[-1],T.index[-1])\n",
    "    T = T.loc[start_idx:end_idx]\n",
    "    IN = IN.loc[start_idx:end_idx]\n",
    "\n",
    "    print(T)\n",
    "    T.to_csv('outflow_cluster_dem.csv', index=False)\n",
    "\n",
    "    # missing_clusters = [x for x in range(IN.columns[-1]) if x not in IN.columns]\n",
    "    # missing_clusters.sort()\n",
    "    \n",
    "    # for ms in missing_clusters:\n",
    "    #     IN.insert(ms, ms, 0)\n",
    "\n",
    "    print(IN)\n",
    "    IN.to_csv('inflow_cluster_dem.csv', index=False)\n",
    "    \n",
    "## stop\n",
    "\n",
    "    #raw_data = T.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68343c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c97397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3492f4d3e3c55a6ecd296255a1842ef4032fa21edc5071abaeda59e7bc7b3161"
  },
  "kernelspec": {
   "display_name": "Python 3.5.6 ('dem_forcast')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
