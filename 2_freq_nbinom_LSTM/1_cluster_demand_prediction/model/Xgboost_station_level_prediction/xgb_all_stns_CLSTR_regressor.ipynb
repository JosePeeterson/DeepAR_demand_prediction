{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tweedie\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import pygraphviz\n",
    "#warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "from xgboost import plot_tree\n",
    "from sklearn.utils import class_weight\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class train_validate_n_test(object):\n",
    "\n",
    "    def __init__(self) -> None:    \n",
    "        dataset_filename = \"xgboost_feat_train_ds_all_stns.csv\"\n",
    "        full_set = pd.read_csv(dataset_filename,parse_dates=['dt_ts'])\n",
    "        full_set = full_set.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "        self.train_stop_time_fold_1 = '2021/11/30 00:00'\n",
    "        self.val_stop_time_fold_1 = '2021/12/05 00:00'\n",
    "        self.train_stop_time_fold_2 = self.val_stop_time_fold_1\n",
    "        self.val_stop_time_fold_2 = '2021/12/10 00:00'\n",
    "        self.train_stop_time_fold_3 = self.val_stop_time_fold_2\n",
    "        self.val_stop_time_fold_3 = '2021/12/16 00:00'\n",
    "\n",
    "        #self.classes_weights = self.analyze_target(full_set)\n",
    "        self.full_set = self.onehotencode_cat_var(full_set)\n",
    "\n",
    "\n",
    "    def analyze_target(self,full_set):\n",
    "        print('###################################### TARGET data EXPLORATION ###########################################')\n",
    "        print('Target class frequency:')\n",
    "        print(full_set['target'].value_counts())\n",
    "\n",
    "        full_set['target'].hist()\n",
    "        plt.title('Target histogram')\n",
    "        plt.xlabel('demand value (class)')\n",
    "        plt.ylabel('count')\n",
    "        plt.show()\n",
    "\n",
    "        classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=full_set['target'])\n",
    "        print('\\nTarget class weights:')\n",
    "        print(np.unique(classes_weights))\n",
    "        print('##########################################################################################################')\n",
    "        return classes_weights\n",
    "\n",
    "\n",
    "    def onehotencode_cat_var(self,full_set):\n",
    "        full_set = full_set.astype({\"stn_id\":str,\"block_id\":str,\"ts_of_day\":str,\"hr_of_day\":str,\"day_of_wk\":str,\"day_of_mn\":str,\"wk_of_mon\":str })\n",
    "        full_set = pd.get_dummies(full_set, prefix_sep=\"_\",columns =[\"stn_id\",\"block_id\",\"ts_of_day\",\"hr_of_day\",\"day_of_wk\",\"day_of_mn\",\"wk_of_mon\"],drop_first=True)\n",
    "        #ds_df = ds_df.drop('rem_blk_outf_'+self.stn,axis=1)\n",
    "        return full_set\n",
    "\n",
    "\n",
    "    def walk_forward_val_n_train_set(self,fold):\n",
    "        # split validation set into 3 parts\n",
    "        if (fold==1):\n",
    "            train1 = self.full_set.loc[self.full_set['dt_ts'] < self.train_stop_time_fold_1]\n",
    "            tr1 = train1.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_train1 = pd.DataFrame(train1[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_train1)\n",
    "            dtrain1 = xgb.DMatrix(tr1, label=label_train1,weight=classes_weights)\n",
    "\n",
    "            print('\\n',train1.isnull().values.any(),'\\n')\n",
    "\n",
    "            val1 = self.full_set.loc[(self.full_set['dt_ts'] >= self.train_stop_time_fold_1) & (self.full_set['dt_ts'] < self.val_stop_time_fold_1)]\n",
    "            v1 = val1.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_val1 = pd.DataFrame(val1[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_val1)\n",
    "            dval1 = xgb.DMatrix(v1, label=label_val1,weight=classes_weights)\n",
    "            print('\\n',val1.isnull().values.any(),'\\n')\n",
    "\n",
    "            return dtrain1, dval1\n",
    "        \n",
    "        elif (fold==2):\n",
    "            train2 = self.full_set.loc[self.full_set['dt_ts'] < self.train_stop_time_fold_2]\n",
    "            tr2 = train2.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_train2 = pd.DataFrame(train2[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_train2)\n",
    "            dtrain2 = xgb.DMatrix(tr2, label=label_train2,weight=classes_weights)\n",
    "\n",
    "            print('\\n',train2.isnull().values.any(),'\\n')\n",
    "\n",
    "            val2 = self.full_set.loc[(self.full_set['dt_ts'] >= self.train_stop_time_fold_2) & (self.full_set['dt_ts'] < self.val_stop_time_fold_2)]\n",
    "            v2 = val2.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_val2 = pd.DataFrame(val2[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_val2)\n",
    "            dval2 = xgb.DMatrix(v2, label=label_val2,weight=classes_weights)\n",
    "\n",
    "            print('\\n',val2.isnull().values.any(),'\\n')\n",
    "\n",
    "            return dtrain2,dval2\n",
    "        \n",
    "        else:\n",
    "            train3 = self.full_set.loc[self.full_set['dt_ts'] < self.train_stop_time_fold_3]\n",
    "            tr3 = train3.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_train3 = pd.DataFrame(train3[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_train3)\n",
    "            dtrain3 = xgb.DMatrix(tr3, label=label_train3,weight=classes_weights)\n",
    "\n",
    "            print('\\n',train3.isnull().values.any(),'\\n')\n",
    "\n",
    "            val3 = self.full_set.loc[(self.full_set['dt_ts'] >= self.train_stop_time_fold_3) & (self.full_set['dt_ts'] < self.val_stop_time_fold_3)]\n",
    "            v3 = val3.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "            label_val3 = pd.DataFrame(val3[\"target\"])\n",
    "            classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_val3)\n",
    "            dval3 = xgb.DMatrix(v3, label=label_val3,weight=classes_weights)\n",
    "\n",
    "            print('\\n',val3.isnull().values.any(),'\\n')\n",
    "\n",
    "            return dtrain3,dval3\n",
    "\n",
    "\n",
    "\n",
    "    def xgb_train_validate(self,params,num_round, e_s_r,t_v_p):\n",
    "        dtrain1, dval1 = self.walk_forward_val_n_train_set(fold=1)\n",
    "        watchlist1  = [(dtrain1,'train1_tweedie_loss'), (dval1, 'val1_tweedie_loss')]\n",
    "        evals_result1 = {}\n",
    "        model1 = xgb.train(params=params, dtrain=dtrain1, num_boost_round=num_round, evals=watchlist1, evals_result=evals_result1,  early_stopping_rounds=e_s_r,verbose_eval=False)\n",
    "        val1_error = evals_result1['val1_tweedie_loss']['tweedie-nloglik@'+str(t_v_p)]\n",
    "\n",
    "        dtrain2, dval2 = self.walk_forward_val_n_train_set(fold=2)\n",
    "        watchlist2  = [(dtrain2,'train2_tweedie_loss'), (dval2, 'val2_tweedie_loss')]\n",
    "        evals_result2 = {}\n",
    "        model2 = xgb.train(params=params, dtrain=dtrain2, num_boost_round=num_round, evals=watchlist2, evals_result=evals_result2, early_stopping_rounds=e_s_r,xgb_model=model1,verbose_eval=False )\n",
    "        val2_error = evals_result2['val2_tweedie_loss']['tweedie-nloglik@'+str(t_v_p)]\n",
    "\n",
    "        dtrain3, dval3 = self.walk_forward_val_n_train_set(fold=3)\n",
    "        watchlist3  = [(dtrain3,'train3_tweedie_loss'), (dval3, 'val3_tweedie_loss')]\n",
    "        evals_result3 = {}\n",
    "        self.model3 = xgb.train(params=params, dtrain=dtrain3, num_boost_round=num_round, evals=watchlist3, evals_result=evals_result3, early_stopping_rounds=e_s_r,xgb_model=model2,verbose_eval=False )\n",
    "        val3_error = evals_result3['val3_tweedie_loss']['tweedie-nloglik@'+str(t_v_p)]\n",
    "\n",
    "        print('\\n')\n",
    "        print('###################################### VALIDATION Loss ###########################################')\n",
    "        print('Last estimator val1_error',val1_error[-1]) # Result is a list of validation loss from each of boosters/estimators, last one is final val loss.\n",
    "        print('Last estimator val2_error',val2_error[-1])\n",
    "        print('Last estimator val3_error',val3_error[-1])\n",
    "\n",
    "        val_avg_error = np.mean(np.array([val1_error[-1],val2_error[-1],val3_error[-1]]))\n",
    "        print('val_avg_error',val_avg_error)\n",
    "        print('##################################################################################################')\n",
    "        return val_avg_error\n",
    "\n",
    "\n",
    "    def display_tweedie_plot(self,):\n",
    "        tvs = tweedie.tweedie(mu=1, p=1.1, phi=1.5).rvs(6000)\n",
    "        sn.set(rc={'figure.figsize':(10,5)})\n",
    "        # plt.figure(figsize=(25,10))\n",
    "        sn.displot(tvs)\n",
    "        plt.title('Parametric tweedie distribution')\n",
    "        plt.xlabel('demand value (class)')\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "\n",
    "    def evaluate_predictions(self,model):\n",
    "        test = self.full_set.loc[self.full_set['dt_ts'] >= self.val_stop_time_fold_3]\n",
    "        X_test = test.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "        label_test = pd.DataFrame(test[\"target\"])\n",
    "        classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_test)\n",
    "        dtest = xgb.DMatrix(X_test, label=label_test,weight=classes_weights)\n",
    "\n",
    "        print('\\n',test.isnull().values.any(),'\\n')\n",
    "\n",
    "        preds = model.predict(dtest)\n",
    "        preds = np.rint(preds)\n",
    "        label_test = label_test['target'].to_numpy()\n",
    "\n",
    "        print('####################################### PREDICTION #################################################')    \n",
    "        plt.plot(preds,'*')\n",
    "        plt.ylabel('Demand value (prediction)')\n",
    "        plt.xlabel('Time')     \n",
    "        plt.show()\n",
    "        plt.plot(label_test,'*')\n",
    "        plt.ylabel('Demand value (Ground-truth)')\n",
    "        plt.xlabel('Time')     \n",
    "        plt.show()\n",
    "        # plt.plot(label_test[40:60],'*')\n",
    "        # plt.title('zoomed true label test')\n",
    "        # plt.ylabel('Demand value')\n",
    "        # plt.xlabel('Time')     \n",
    "        # plt.show()\n",
    "        # plt.plot(preds[40:60],'*')\n",
    "        # plt.title('zoomed pred label')\n",
    "        # plt.ylabel('Demand value')\n",
    "        # plt.xlabel('Time')     \n",
    "        # plt.show()\n",
    "\n",
    "        #\"use confusion matrix, ROC, F1 scores to evaluate\"\n",
    "        cm = confusion_matrix(label_test,preds)\n",
    "        max_classes = max(len(np.unique(label_test)),len(np.unique(preds)))\n",
    "        df_cm = pd.DataFrame(cm, index = [i for i in range(max_classes)],\n",
    "                        columns = [i for i in range(max_classes)])\n",
    "        plt.figure(figsize = (10,7))      \n",
    "        s = sn.heatmap(df_cm, annot=True, )\n",
    "        s.set(xlabel='Predicted-Label', ylabel='True-Label')\n",
    "        print('##################################################################################################')\n",
    "\n",
    "        return X_test,label_test, preds\n",
    "\n",
    "\n",
    "    def identify_tweedie_variance_param():\n",
    "        #TODO:#\"fit on data\"\n",
    "        # follow this tutorial https://notebook.community/thequackdaddy/tweedie/example/tweedie_demo\n",
    "        # GLM.estimate_tweedie_power()\n",
    "        # #Training model\n",
    "        # tweedie_model = sm.GLM(y_train, X_train, exposure = df_train.exposure, family=sm.families.Tweedie(link=None,var_power=1.5,eql=True))\n",
    "        # tweedie_result = tweedie_model.fit()\n",
    "        # #Using the initial model output to decide the optimum index parameter \"p\"\n",
    "        # GLM.estimate_tweedie_power(training_result, method='brentq', low=1.01, high=5.0)\n",
    "        # tweedie_model.estimate_tweedie_power(tweedie_result.mu, method='brentq', low=1.01, high=5.0)\n",
    "        return\n",
    "\n",
    "\n",
    "    def make_predictions(self,best_params,num_round, e_s_r):\n",
    "        #TODO:#for new predictions after tuning model\n",
    "        train4 = self.full_set.loc[self.full_set['dt_ts'] < self.val_stop_time_fold_3]\n",
    "        tr4 = train4.drop([\"target\",\"dt_ts\"], axis=1)\n",
    "        label_train4 = pd.DataFrame(train4[\"target\"])\n",
    "        classes_weights = class_weight.compute_sample_weight(class_weight='balanced',y=label_train4)\n",
    "        dtrain4 = xgb.DMatrix(tr4, label=label_train4,weight=classes_weights)\n",
    "\n",
    "        watchlist4  = [(dtrain4,'train3_tweedie_loss')]\n",
    "        evals_result4 = {}\n",
    "        self.model4 = xgb.train(params=best_params, dtrain=dtrain4, num_boost_round=num_round, evals=watchlist4, evals_result=evals_result4, early_stopping_rounds=e_s_r,verbose_eval=False )\n",
    "        return self.model4 # best_model\n",
    "    \n",
    "\n",
    "    def visualize_tree(self,):\n",
    "        #TODO:#\"draw out a few trees to interpret results\"        \n",
    "        #xgb.plot_tree(self.train3)\n",
    "        plot_tree(self.model3)\n",
    "\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "\n",
    "    os.chdir(\"c:\\Work\\WORK_PACKAGE\\Demand_forecasting\\BLUESG_Demand_data\\Data-preprocessing_data_generation\")\n",
    "    t_v_t = train_validate_n_test()\n",
    "\n",
    "    tweedie_variance_power = round(trial.suggest_float(name='tweedie_variance_power',low=1.1,high=1.9,step=0.1,log=False),1)\n",
    "\n",
    "    ######  SET Hyperparameter's range for tuning ######\n",
    "    early_stopping_rounds = 30\n",
    "    eval_metric = 'tweedie-nloglik@'+str(tweedie_variance_power)\n",
    "    num_round= 1000\n",
    "    # Hyperparameters and algorithm parameters are described here\n",
    "    params = {\"max_depth\": trial.suggest_int('max_depth', 3, 10),\n",
    "            \"eta\": trial.suggest_float(name='learning_rate', low=0.0001, high=0.1,log=True),\n",
    "            \"subsample\" : round(trial.suggest_float(name='subsample', low=0.1, high=1.0,step=0.1),1),\n",
    "            \"colsample_bytree\": round(trial.suggest_float(name='colsample_bytree', low=0.1, high=1.0,step=0.1),1),\n",
    "            'eval_metric':eval_metric, ## try using AUC as well.. \n",
    "            'tweedie_variance_power': tweedie_variance_power,\n",
    "            'gamma': trial.suggest_int('gamma', 0, 5),\n",
    "            'reg_alpha': trial.suggest_int('reg_alpha', 0, 5), \n",
    "            'reg_lambda': trial.suggest_int('reg_lambda', 0, 5),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            \"objective\": 'reg:tweedie',\n",
    "            }\n",
    "    ######  SET Hyperparameter's range for tuning ######\n",
    "\n",
    "    val_avg_error = t_v_t.xgb_train_validate(params,num_round, early_stopping_rounds,tweedie_variance_power)\n",
    "    return val_avg_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:23:45,738]\u001b[0m A new study created in memory with name: no-name-7f663655-4d85-4997-9879-49209cd3b071\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:25:00,585]\u001b[0m Trial 0 finished with value: 4.698616666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 8, 'learning_rate': 0.0003764051051512748, 'subsample': 0.8, 'colsample_bytree': 0.2, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 4, 'min_child_weight': 7}. Best is trial 0 with value: 4.698616666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.256751\n",
      "Last estimator val2_error 4.028064\n",
      "Last estimator val3_error 4.811035\n",
      "val_avg_error 4.698616666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:26:34,435]\u001b[0m Trial 1 finished with value: 4.529419666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 10, 'learning_rate': 0.0029997196032076137, 'subsample': 0.9, 'colsample_bytree': 0.4, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 2}. Best is trial 1 with value: 4.529419666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.844291\n",
      "Last estimator val2_error 4.017507\n",
      "Last estimator val3_error 4.726461\n",
      "val_avg_error 4.529419666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:26:43,421]\u001b[0m Trial 2 finished with value: 4.484123 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 5, 'learning_rate': 0.0638647589382723, 'subsample': 0.4, 'colsample_bytree': 0.8, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 5}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.867233\n",
      "Last estimator val2_error 3.725765\n",
      "Last estimator val3_error 4.859371\n",
      "val_avg_error 4.484123\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:28:42,325]\u001b[0m Trial 3 finished with value: 4.891925333333333 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 5, 'learning_rate': 0.00032895752021031656, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 3, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 2}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.572202\n",
      "Last estimator val2_error 3.964798\n",
      "Last estimator val3_error 5.138776\n",
      "val_avg_error 4.891925333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:28:50,894]\u001b[0m Trial 4 finished with value: 5.629361 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 3, 'learning_rate': 0.035019518937087324, 'subsample': 1.0, 'colsample_bytree': 0.9, 'gamma': 4, 'reg_alpha': 1, 'reg_lambda': 4, 'min_child_weight': 4}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.85441\n",
      "Last estimator val2_error 5.176646\n",
      "Last estimator val3_error 5.857027\n",
      "val_avg_error 5.629361\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:30:24,908]\u001b[0m Trial 5 finished with value: 4.907066333333333 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 6, 'learning_rate': 0.0003226905525937058, 'subsample': 1.0, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 6}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.583934\n",
      "Last estimator val2_error 3.985194\n",
      "Last estimator val3_error 5.152071\n",
      "val_avg_error 4.907066333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:31:27,565]\u001b[0m Trial 6 finished with value: 8.142830333333334 and parameters: {'tweedie_variance_power': 1.2000000000000002, 'max_depth': 4, 'learning_rate': 0.00010171357189346834, 'subsample': 0.1, 'colsample_bytree': 0.8, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 9.184613\n",
      "Last estimator val2_error 6.303529\n",
      "Last estimator val3_error 8.940349\n",
      "val_avg_error 8.142830333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:32:56,607]\u001b[0m Trial 7 finished with value: 4.675372 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 9, 'learning_rate': 0.0003075154861678151, 'subsample': 0.9, 'colsample_bytree': 0.30000000000000004, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 0, 'min_child_weight': 6}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.280854\n",
      "Last estimator val2_error 3.88917\n",
      "Last estimator val3_error 4.856092\n",
      "val_avg_error 4.675372\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:34:33,383]\u001b[0m Trial 8 finished with value: 5.686279 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 9, 'learning_rate': 0.0029352688650674187, 'subsample': 0.8, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.989248\n",
      "Last estimator val2_error 5.165251\n",
      "Last estimator val3_error 5.904338\n",
      "val_avg_error 5.686279\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:34:47,941]\u001b[0m Trial 9 finished with value: 4.596403666666666 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 10, 'learning_rate': 0.03817135483072482, 'subsample': 1.0, 'colsample_bytree': 0.2, 'gamma': 1, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 9}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.883074\n",
      "Last estimator val2_error 4.033298\n",
      "Last estimator val3_error 4.872839\n",
      "val_avg_error 4.596403666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:34:56,497]\u001b[0m Trial 10 finished with value: 14.083874999999999 and parameters: {'tweedie_variance_power': 1.1, 'max_depth': 7, 'learning_rate': 0.07834928219646153, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 15.610437\n",
      "Last estimator val2_error 10.796185\n",
      "Last estimator val3_error 15.845003\n",
      "val_avg_error 14.083874999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:35:51,366]\u001b[0m Trial 11 finished with value: 9.718005 and parameters: {'tweedie_variance_power': 1.9, 'max_depth': 6, 'learning_rate': 0.005063210969634764, 'subsample': 0.6, 'colsample_bytree': 0.4, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 1}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 10.078862\n",
      "Last estimator val2_error 9.082239\n",
      "Last estimator val3_error 9.992914\n",
      "val_avg_error 9.718005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:36:22,297]\u001b[0m Trial 12 finished with value: 5.390986333333333 and parameters: {'tweedie_variance_power': 1.3, 'max_depth': 5, 'learning_rate': 0.0070078369005192225, 'subsample': 0.5, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 4}. Best is trial 2 with value: 4.484123.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.918481\n",
      "Last estimator val2_error 4.364853\n",
      "Last estimator val3_error 5.889625\n",
      "val_avg_error 5.390986333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:37:49,477]\u001b[0m Trial 13 finished with value: 4.162259333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 7, 'learning_rate': 0.0019530229590260513, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'gamma': 3, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 13 with value: 4.162259333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.529297\n",
      "Last estimator val2_error 3.576457\n",
      "Last estimator val3_error 4.381024\n",
      "val_avg_error 4.162259333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:39:25,727]\u001b[0m Trial 14 finished with value: 4.250552666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 7, 'learning_rate': 0.0012253296611240908, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'gamma': 3, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 4}. Best is trial 13 with value: 4.162259333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.724524\n",
      "Last estimator val2_error 3.541862\n",
      "Last estimator val3_error 4.485272\n",
      "val_avg_error 4.250552666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:40:55,808]\u001b[0m Trial 15 finished with value: 4.246308 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 7, 'learning_rate': 0.0013409373655209262, 'subsample': 0.2, 'colsample_bytree': 0.7000000000000001, 'gamma': 2, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 13 with value: 4.162259333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.694236\n",
      "Last estimator val2_error 3.621891\n",
      "Last estimator val3_error 4.422797\n",
      "val_avg_error 4.246308\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:42:28,041]\u001b[0m Trial 16 finished with value: 4.375980333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 8, 'learning_rate': 0.0010915602940096097, 'subsample': 0.1, 'colsample_bytree': 0.7000000000000001, 'gamma': 0, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 13 with value: 4.162259333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.889807\n",
      "Last estimator val2_error 3.701719\n",
      "Last estimator val3_error 4.536415\n",
      "val_avg_error 4.375980333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:43:06,270]\u001b[0m Trial 17 finished with value: 4.111476333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 8, 'learning_rate': 0.01032329306020988, 'subsample': 0.2, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 3, 'reg_lambda': 2, 'min_child_weight': 1}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.38262\n",
      "Last estimator val2_error 3.568338\n",
      "Last estimator val3_error 4.383471\n",
      "val_avg_error 4.111476333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:44:01,859]\u001b[0m Trial 18 finished with value: 4.507167666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 8, 'learning_rate': 0.011680945417141216, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 2, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.768927\n",
      "Last estimator val2_error 3.997513\n",
      "Last estimator val3_error 4.755063\n",
      "val_avg_error 4.507167666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:44:30,108]\u001b[0m Trial 19 finished with value: 10.235527666666668 and parameters: {'tweedie_variance_power': 1.9, 'max_depth': 9, 'learning_rate': 0.017470180885870382, 'subsample': 0.2, 'colsample_bytree': 0.9, 'gamma': 3, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 1}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 10.152803\n",
      "Last estimator val2_error 9.418126\n",
      "Last estimator val3_error 11.135654\n",
      "val_avg_error 10.235527666666668\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:45:09,462]\u001b[0m Trial 20 finished with value: 4.1687639999999995 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 6, 'learning_rate': 0.015545499404452186, 'subsample': 0.6, 'colsample_bytree': 0.1, 'gamma': 0, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.529408\n",
      "Last estimator val2_error 3.516478\n",
      "Last estimator val3_error 4.460406\n",
      "val_avg_error 4.1687639999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:45:35,472]\u001b[0m Trial 21 finished with value: 4.129764000000001 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 6, 'learning_rate': 0.01252090568150884, 'subsample': 0.6, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 1, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.450699\n",
      "Last estimator val2_error 3.48568\n",
      "Last estimator val3_error 4.452913\n",
      "val_avg_error 4.129764000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:46:13,709]\u001b[0m Trial 22 finished with value: 4.122221 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 7, 'learning_rate': 0.009043346780855626, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.393692\n",
      "Last estimator val2_error 3.552795\n",
      "Last estimator val3_error 4.420176\n",
      "val_avg_error 4.122221\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:47:07,938]\u001b[0m Trial 23 finished with value: 4.165924333333334 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 8, 'learning_rate': 0.007043702942279315, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 1, 'reg_lambda': 3, 'min_child_weight': 2}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.49276\n",
      "Last estimator val2_error 3.487995\n",
      "Last estimator val3_error 4.517018\n",
      "val_avg_error 4.165924333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:47:24,753]\u001b[0m Trial 24 finished with value: 5.405981999999999 and parameters: {'tweedie_variance_power': 1.3, 'max_depth': 6, 'learning_rate': 0.025217390631609646, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.4, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 1}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.931323\n",
      "Last estimator val2_error 4.361376\n",
      "Last estimator val3_error 5.925247\n",
      "val_avg_error 5.405981999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:48:06,129]\u001b[0m Trial 25 finished with value: 4.517424 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 7, 'learning_rate': 0.010150865465660828, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.5, 'gamma': 0, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.761788\n",
      "Last estimator val2_error 3.986868\n",
      "Last estimator val3_error 4.803616\n",
      "val_avg_error 4.517424\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:48:52,018]\u001b[0m Trial 26 finished with value: 5.687100333333333 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 4, 'learning_rate': 0.0056834605692157505, 'subsample': 0.4, 'colsample_bytree': 0.30000000000000004, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 3, 'min_child_weight': 10}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.959388\n",
      "Last estimator val2_error 5.192462\n",
      "Last estimator val3_error 5.909451\n",
      "val_avg_error 5.687100333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:49:16,053]\u001b[0m Trial 27 finished with value: 4.143971 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 8, 'learning_rate': 0.022934397220475782, 'subsample': 0.6, 'colsample_bytree': 0.6, 'gamma': 0, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.42101\n",
      "Last estimator val2_error 3.552509\n",
      "Last estimator val3_error 4.458394\n",
      "val_avg_error 4.143971\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:50:40,227]\u001b[0m Trial 28 finished with value: 5.4569806666666665 and parameters: {'tweedie_variance_power': 1.3, 'max_depth': 9, 'learning_rate': 0.004238050147204214, 'subsample': 0.5, 'colsample_bytree': 0.30000000000000004, 'gamma': 2, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 1}. Best is trial 17 with value: 4.111476333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 6.012601\n",
      "Last estimator val2_error 4.375093\n",
      "Last estimator val3_error 5.983248\n",
      "val_avg_error 5.4569806666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:51:15,761]\u001b[0m Trial 29 finished with value: 4.098597333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.009678005622041122, 'subsample': 0.8, 'colsample_bytree': 0.4, 'gamma': 1, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.378271\n",
      "Last estimator val2_error 3.555166\n",
      "Last estimator val3_error 4.362355\n",
      "val_avg_error 4.098597333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:52:15,746]\u001b[0m Trial 30 finished with value: 4.484554666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0006587327041809475, 'subsample': 0.8, 'colsample_bytree': 0.2, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.000572\n",
      "Last estimator val2_error 3.893059\n",
      "Last estimator val3_error 4.560033\n",
      "val_avg_error 4.484554666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:53:03,847]\u001b[0m Trial 31 finished with value: 4.1022 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.008420418970087806, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.4, 'gamma': 0, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.382103\n",
      "Last estimator val2_error 3.556976\n",
      "Last estimator val3_error 4.367521\n",
      "val_avg_error 4.1022\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:53:46,851]\u001b[0m Trial 32 finished with value: 4.479205 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.008436399151458463, 'subsample': 0.9, 'colsample_bytree': 0.4, 'gamma': 1, 'reg_alpha': 1, 'reg_lambda': 0, 'min_child_weight': 8}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.730598\n",
      "Last estimator val2_error 3.98979\n",
      "Last estimator val3_error 4.717227\n",
      "val_avg_error 4.479205\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:54:50,896]\u001b[0m Trial 33 finished with value: 4.552414 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 3, 'learning_rate': 0.0027016951320968235, 'subsample': 0.8, 'colsample_bytree': 0.30000000000000004, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.87209\n",
      "Last estimator val2_error 4.078947\n",
      "Last estimator val3_error 4.706205\n",
      "val_avg_error 4.552414\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:55:03,798]\u001b[0m Trial 34 finished with value: 4.099261 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.04129353967960751, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.4, 'gamma': 2, 'reg_alpha': 2, 'reg_lambda': 1, 'min_child_weight': 8}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.392412\n",
      "Last estimator val2_error 3.562641\n",
      "Last estimator val3_error 4.34273\n",
      "val_avg_error 4.099261\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:55:14,391]\u001b[0m Trial 35 finished with value: 4.493991 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 5, 'learning_rate': 0.04556199139714894, 'subsample': 0.9, 'colsample_bytree': 0.4, 'gamma': 2, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 8}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.886755\n",
      "Last estimator val2_error 3.71923\n",
      "Last estimator val3_error 4.875988\n",
      "val_avg_error 4.493991\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:55:38,284]\u001b[0m Trial 36 finished with value: 4.137225666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05074243697307494, 'subsample': 0.8, 'colsample_bytree': 0.1, 'gamma': 2, 'reg_alpha': 3, 'reg_lambda': 0, 'min_child_weight': 8}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.477857\n",
      "Last estimator val2_error 3.56127\n",
      "Last estimator val3_error 4.37255\n",
      "val_avg_error 4.137225666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:55:45,297]\u001b[0m Trial 37 finished with value: 5.708537 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 5, 'learning_rate': 0.09407789215171077, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.2, 'gamma': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'min_child_weight': 6}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.977521\n",
      "Last estimator val2_error 5.198244\n",
      "Last estimator val3_error 5.949846\n",
      "val_avg_error 5.708537\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:56:03,591]\u001b[0m Trial 38 finished with value: 4.113708333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.023943690062883327, 'subsample': 0.8, 'colsample_bytree': 0.30000000000000004, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.440781\n",
      "Last estimator val2_error 3.488718\n",
      "Last estimator val3_error 4.411626\n",
      "val_avg_error 4.113708333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:56:17,077]\u001b[0m Trial 39 finished with value: 4.480361333333334 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.027660923887037128, 'subsample': 0.5, 'colsample_bytree': 0.4, 'gamma': 3, 'reg_alpha': 1, 'reg_lambda': 1, 'min_child_weight': 9}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.867542\n",
      "Last estimator val2_error 3.729569\n",
      "Last estimator val3_error 4.843973\n",
      "val_avg_error 4.480361333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:56:41,853]\u001b[0m Trial 40 finished with value: 4.475141666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.016594918673890836, 'subsample': 0.9, 'colsample_bytree': 0.6, 'gamma': 2, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 6}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.725262\n",
      "Last estimator val2_error 3.988587\n",
      "Last estimator val3_error 4.711576\n",
      "val_avg_error 4.475141666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:56:57,036]\u001b[0m Trial 41 finished with value: 4.490892333333334 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 4, 'learning_rate': 0.030507254283361433, 'subsample': 0.8, 'colsample_bytree': 0.30000000000000004, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 7}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.895501\n",
      "Last estimator val2_error 3.72368\n",
      "Last estimator val3_error 4.853496\n",
      "val_avg_error 4.490892333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:57:08,056]\u001b[0m Trial 42 finished with value: 4.134535333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 5, 'learning_rate': 0.05672022334441835, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.30000000000000004, 'gamma': 1, 'reg_alpha': 2, 'reg_lambda': 0, 'min_child_weight': 8}. Best is trial 29 with value: 4.098597333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.460544\n",
      "Last estimator val2_error 3.486426\n",
      "Last estimator val3_error 4.456636\n",
      "val_avg_error 4.134535333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:57:25,942]\u001b[0m Trial 43 finished with value: 4.096131333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.019490962045155873, 'subsample': 0.9, 'colsample_bytree': 0.4, 'gamma': 2, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 7}. Best is trial 43 with value: 4.096131333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.412949\n",
      "Last estimator val2_error 3.489478\n",
      "Last estimator val3_error 4.385967\n",
      "val_avg_error 4.096131333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:57:54,361]\u001b[0m Trial 44 finished with value: 4.071516333333332 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.017648866162048905, 'subsample': 0.9, 'colsample_bytree': 0.4, 'gamma': 2, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 6}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333742\n",
      "Last estimator val2_error 3.56301\n",
      "Last estimator val3_error 4.317797\n",
      "val_avg_error 4.071516333333332\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:58:12,490]\u001b[0m Trial 45 finished with value: 4.0907116666666665 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.018037278499449385, 'subsample': 1.0, 'colsample_bytree': 0.4, 'gamma': 3, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.38935\n",
      "Last estimator val2_error 3.49809\n",
      "Last estimator val3_error 4.384695\n",
      "val_avg_error 4.0907116666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:58:21,562]\u001b[0m Trial 46 finished with value: 4.476628 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.06948433655480885, 'subsample': 1.0, 'colsample_bytree': 0.4, 'gamma': 3, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.861413\n",
      "Last estimator val2_error 3.728234\n",
      "Last estimator val3_error 4.840237\n",
      "val_avg_error 4.476628\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:58:38,809]\u001b[0m Trial 47 finished with value: 4.092084666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.03474067151748575, 'subsample': 0.9, 'colsample_bytree': 0.5, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.398463\n",
      "Last estimator val2_error 3.494645\n",
      "Last estimator val3_error 4.383146\n",
      "val_avg_error 4.092084666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:59:02,476]\u001b[0m Trial 48 finished with value: 4.089996999999999 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.019818143148232385, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.391306\n",
      "Last estimator val2_error 3.496412\n",
      "Last estimator val3_error 4.382273\n",
      "val_avg_error 4.089996999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 13:59:23,145]\u001b[0m Trial 49 finished with value: 4.088994666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.017594889304134765, 'subsample': 1.0, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.389794\n",
      "Last estimator val2_error 3.499982\n",
      "Last estimator val3_error 4.377208\n",
      "val_avg_error 4.088994666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:00:11,130]\u001b[0m Trial 50 finished with value: 5.142186 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.00012880494687873825, 'subsample': 1.0, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.814311\n",
      "Last estimator val2_error 4.166101\n",
      "Last estimator val3_error 5.446146\n",
      "val_avg_error 5.142186\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:00:41,909]\u001b[0m Trial 51 finished with value: 4.088658 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.01600564980142287, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.389319\n",
      "Last estimator val2_error 3.497811\n",
      "Last estimator val3_error 4.378844\n",
      "val_avg_error 4.088658\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:00:59,944]\u001b[0m Trial 52 finished with value: 4.089912333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.03451170758534077, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.391017\n",
      "Last estimator val2_error 3.497563\n",
      "Last estimator val3_error 4.381157\n",
      "val_avg_error 4.089912333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:01:34,153]\u001b[0m Trial 53 finished with value: 4.469779333333334 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.012855567294298247, 'subsample': 1.0, 'colsample_bytree': 0.6, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.845208\n",
      "Last estimator val2_error 3.732021\n",
      "Last estimator val3_error 4.832109\n",
      "val_avg_error 4.469779333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:01:54,930]\u001b[0m Trial 54 finished with value: 4.089976333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.020016102946287705, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.393358\n",
      "Last estimator val2_error 3.49564\n",
      "Last estimator val3_error 4.380931\n",
      "val_avg_error 4.089976333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:02:03,789]\u001b[0m Trial 55 finished with value: 5.378818333333334 and parameters: {'tweedie_variance_power': 1.3, 'max_depth': 3, 'learning_rate': 0.03364315531514966, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.885143\n",
      "Last estimator val2_error 4.371991\n",
      "Last estimator val3_error 5.879321\n",
      "val_avg_error 5.378818333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:02:33,315]\u001b[0m Trial 56 finished with value: 4.4701976666666665 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.013547978557873049, 'subsample': 1.0, 'colsample_bytree': 0.7000000000000001, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 6}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.844788\n",
      "Last estimator val2_error 3.732561\n",
      "Last estimator val3_error 4.833244\n",
      "val_avg_error 4.4701976666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:02:56,058]\u001b[0m Trial 57 finished with value: 4.0930523333333335 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.023178800896083502, 'subsample': 0.9, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.397599\n",
      "Last estimator val2_error 3.490506\n",
      "Last estimator val3_error 4.391052\n",
      "val_avg_error 4.0930523333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:03:03,169]\u001b[0m Trial 58 finished with value: 4.093675 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.060958666266913285, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.392259\n",
      "Last estimator val2_error 3.50007\n",
      "Last estimator val3_error 4.388696\n",
      "val_avg_error 4.093675\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:03:40,479]\u001b[0m Trial 59 finished with value: 13.985302666666668 and parameters: {'tweedie_variance_power': 1.1, 'max_depth': 3, 'learning_rate': 0.0049785544613249605, 'subsample': 0.9, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 6}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 15.589613\n",
      "Last estimator val2_error 10.784906\n",
      "Last estimator val3_error 15.581389\n",
      "val_avg_error 13.985302666666668\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:03:59,591]\u001b[0m Trial 60 finished with value: 4.096526 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.014689009856453656, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.40697\n",
      "Last estimator val2_error 3.49471\n",
      "Last estimator val3_error 4.387898\n",
      "val_avg_error 4.096526\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:04:19,479]\u001b[0m Trial 61 finished with value: 4.089882 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.017386315318856604, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.390081\n",
      "Last estimator val2_error 3.497136\n",
      "Last estimator val3_error 4.382429\n",
      "val_avg_error 4.089882\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:04:40,055]\u001b[0m Trial 62 finished with value: 4.470149333333333 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 3, 'learning_rate': 0.0199073089608885, 'subsample': 1.0, 'colsample_bytree': 0.5, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 5}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.849033\n",
      "Last estimator val2_error 3.728376\n",
      "Last estimator val3_error 4.833039\n",
      "val_avg_error 4.470149333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:05:02,614]\u001b[0m Trial 63 finished with value: 4.085809333333334 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.039955236910305295, 'subsample': 0.9, 'colsample_bytree': 0.6, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 4}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.389905\n",
      "Last estimator val2_error 3.491333\n",
      "Last estimator val3_error 4.37619\n",
      "val_avg_error 4.085809333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:05:17,771]\u001b[0m Trial 64 finished with value: 4.089357666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.041995651361079155, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.399117\n",
      "Last estimator val2_error 3.494289\n",
      "Last estimator val3_error 4.374667\n",
      "val_avg_error 4.089357666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:05:32,974]\u001b[0m Trial 65 finished with value: 4.072710333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04546087206730641, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338419\n",
      "Last estimator val2_error 3.56364\n",
      "Last estimator val3_error 4.316072\n",
      "val_avg_error 4.072710333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:05:41,215]\u001b[0m Trial 66 finished with value: 4.076485333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08005810804217295, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 4, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 44 with value: 4.071516333333332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.350214\n",
      "Last estimator val2_error 3.563814\n",
      "Last estimator val3_error 4.315428\n",
      "val_avg_error 4.076485333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:05:49,089]\u001b[0m Trial 67 finished with value: 4.069543666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.09203411518209473, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 67 with value: 4.069543666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331136\n",
      "Last estimator val2_error 3.557848\n",
      "Last estimator val3_error 4.319647\n",
      "val_avg_error 4.069543666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:00,514]\u001b[0m Trial 68 finished with value: 4.0750443333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08761041439975839, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 67 with value: 4.069543666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.343758\n",
      "Last estimator val2_error 3.56127\n",
      "Last estimator val3_error 4.320105\n",
      "val_avg_error 4.0750443333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:08,401]\u001b[0m Trial 69 finished with value: 4.469779 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.09843365164359016, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 67 with value: 4.069543666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.719187\n",
      "Last estimator val2_error 3.999189\n",
      "Last estimator val3_error 4.690961\n",
      "val_avg_error 4.469779\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:18,071]\u001b[0m Trial 70 finished with value: 4.074683666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07204364477573864, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 67 with value: 4.069543666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.343882\n",
      "Last estimator val2_error 3.566072\n",
      "Last estimator val3_error 4.314097\n",
      "val_avg_error 4.074683666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:24,908]\u001b[0m Trial 71 finished with value: 4.074247333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07488492139405792, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 67 with value: 4.069543666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33448\n",
      "Last estimator val2_error 3.563834\n",
      "Last estimator val3_error 4.324428\n",
      "val_avg_error 4.074247333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:30,955]\u001b[0m Trial 72 finished with value: 4.067977333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07837087977857655, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328811\n",
      "Last estimator val2_error 3.562803\n",
      "Last estimator val3_error 4.312318\n",
      "val_avg_error 4.067977333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:39,276]\u001b[0m Trial 73 finished with value: 4.075503 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08220730060338266, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.342951\n",
      "Last estimator val2_error 3.564831\n",
      "Last estimator val3_error 4.318727\n",
      "val_avg_error 4.075503\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:46,586]\u001b[0m Trial 74 finished with value: 4.072949333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07717549980883655, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335017\n",
      "Last estimator val2_error 3.56439\n",
      "Last estimator val3_error 4.319441\n",
      "val_avg_error 4.072949333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:06:54,924]\u001b[0m Trial 75 finished with value: 4.458478666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.06459577900325465, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.697514\n",
      "Last estimator val2_error 3.994486\n",
      "Last estimator val3_error 4.683436\n",
      "val_avg_error 4.458478666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:03,655]\u001b[0m Trial 76 finished with value: 4.070968333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05059467269226239, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331568\n",
      "Last estimator val2_error 3.568071\n",
      "Last estimator val3_error 4.313266\n",
      "val_avg_error 4.070968333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:15,050]\u001b[0m Trial 77 finished with value: 4.458266666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.05225964392852761, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 72 with value: 4.067977333333334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.697779\n",
      "Last estimator val2_error 3.994076\n",
      "Last estimator val3_error 4.682945\n",
      "val_avg_error 4.458266666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:23,763]\u001b[0m Trial 78 finished with value: 4.067475333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.07096288394426943, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332173\n",
      "Last estimator val2_error 3.554502\n",
      "Last estimator val3_error 4.315751\n",
      "val_avg_error 4.067475333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:37,660]\u001b[0m Trial 79 finished with value: 4.0779749999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.050286356618442885, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.343465\n",
      "Last estimator val2_error 3.554444\n",
      "Last estimator val3_error 4.336016\n",
      "val_avg_error 4.0779749999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:48,726]\u001b[0m Trial 80 finished with value: 4.460929333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.06163846114225631, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.704069\n",
      "Last estimator val2_error 3.985794\n",
      "Last estimator val3_error 4.692925\n",
      "val_avg_error 4.460929333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:07:57,981]\u001b[0m Trial 81 finished with value: 4.070731333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07322425330126613, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329733\n",
      "Last estimator val2_error 3.562155\n",
      "Last estimator val3_error 4.320306\n",
      "val_avg_error 4.070731333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:08:07,707]\u001b[0m Trial 82 finished with value: 4.073409 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.0739408018046006, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335995\n",
      "Last estimator val2_error 3.561\n",
      "Last estimator val3_error 4.323232\n",
      "val_avg_error 4.073409\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:08:16,598]\u001b[0m Trial 83 finished with value: 4.0731633333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.046693968328480204, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327364\n",
      "Last estimator val2_error 3.557349\n",
      "Last estimator val3_error 4.334777\n",
      "val_avg_error 4.0731633333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:08:32,067]\u001b[0m Trial 84 finished with value: 4.073756333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.04638918951049332, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338722\n",
      "Last estimator val2_error 3.553818\n",
      "Last estimator val3_error 4.328729\n",
      "val_avg_error 4.073756333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:08:40,334]\u001b[0m Trial 85 finished with value: 4.467149 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.09568387630161702, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.708463\n",
      "Last estimator val2_error 3.992122\n",
      "Last estimator val3_error 4.700862\n",
      "val_avg_error 4.467149\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:08:53,040]\u001b[0m Trial 86 finished with value: 4.078147333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.05440967304540634, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.344457\n",
      "Last estimator val2_error 3.555855\n",
      "Last estimator val3_error 4.33413\n",
      "val_avg_error 4.078147333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:09,281]\u001b[0m Trial 87 finished with value: 4.457837333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.030260085916597224, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 3}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.690912\n",
      "Last estimator val2_error 3.99666\n",
      "Last estimator val3_error 4.68594\n",
      "val_avg_error 4.457837333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:17,622]\u001b[0m Trial 88 finished with value: 4.071631 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05878452854448729, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334909\n",
      "Last estimator val2_error 3.564664\n",
      "Last estimator val3_error 4.31532\n",
      "val_avg_error 4.071631\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:28,056]\u001b[0m Trial 89 finished with value: 5.730411 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 10, 'learning_rate': 0.0631437727811533, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.929007\n",
      "Last estimator val2_error 5.194627\n",
      "Last estimator val3_error 6.067599\n",
      "val_avg_error 5.730411\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:35,336]\u001b[0m Trial 90 finished with value: 4.071095333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.09956753575490426, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330278\n",
      "Last estimator val2_error 3.567362\n",
      "Last estimator val3_error 4.315646\n",
      "val_avg_error 4.071095333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:42,434]\u001b[0m Trial 91 finished with value: 4.079974 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0991958607860392, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.343821\n",
      "Last estimator val2_error 3.568477\n",
      "Last estimator val3_error 4.327624\n",
      "val_avg_error 4.079974\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:47,619]\u001b[0m Trial 92 finished with value: 4.077289 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08190666092394712, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.340897\n",
      "Last estimator val2_error 3.568982\n",
      "Last estimator val3_error 4.321988\n",
      "val_avg_error 4.077289\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:09:56,063]\u001b[0m Trial 93 finished with value: 4.07861 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.057824198089704154, 'subsample': 0.6, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.354737\n",
      "Last estimator val2_error 3.565192\n",
      "Last estimator val3_error 4.315901\n",
      "val_avg_error 4.07861\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:10:03,943]\u001b[0m Trial 94 finished with value: 4.462472333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.07042246979128165, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 78 with value: 4.067475333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.698816\n",
      "Last estimator val2_error 4.000273\n",
      "Last estimator val3_error 4.688328\n",
      "val_avg_error 4.462472333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:10:19,465]\u001b[0m Trial 95 finished with value: 4.066834 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.042982748574615016, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32718\n",
      "Last estimator val2_error 3.557894\n",
      "Last estimator val3_error 4.315428\n",
      "val_avg_error 4.066834\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:10:33,280]\u001b[0m Trial 96 finished with value: 4.463488333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.038813411588415794, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.708683\n",
      "Last estimator val2_error 3.987541\n",
      "Last estimator val3_error 4.694241\n",
      "val_avg_error 4.463488333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:10:45,216]\u001b[0m Trial 97 finished with value: 4.073118 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02918675175333595, 'subsample': 0.4, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332551\n",
      "Last estimator val2_error 3.568043\n",
      "Last estimator val3_error 4.31876\n",
      "val_avg_error 4.073118\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:10:54,161]\u001b[0m Trial 98 finished with value: 4.081809 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.057303021370108044, 'subsample': 0.6, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 3}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.348071\n",
      "Last estimator val2_error 3.562695\n",
      "Last estimator val3_error 4.334661\n",
      "val_avg_error 4.081809\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:11:04,672]\u001b[0m Trial 99 finished with value: 4.457236666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.04548593168685629, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.690495\n",
      "Last estimator val2_error 3.998008\n",
      "Last estimator val3_error 4.683207\n",
      "val_avg_error 4.457236666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:11:17,324]\u001b[0m Trial 100 finished with value: 4.071967333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03664271116294638, 'subsample': 0.9, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338512\n",
      "Last estimator val2_error 3.56184\n",
      "Last estimator val3_error 4.31555\n",
      "val_avg_error 4.071967333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:11:31,373]\u001b[0m Trial 101 finished with value: 4.072442 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03649258135346505, 'subsample': 0.9, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339898\n",
      "Last estimator val2_error 3.562719\n",
      "Last estimator val3_error 4.314709\n",
      "val_avg_error 4.072442\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:11:47,151]\u001b[0m Trial 102 finished with value: 4.071829 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.036142717788721614, 'subsample': 0.9, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333752\n",
      "Last estimator val2_error 3.563154\n",
      "Last estimator val3_error 4.318581\n",
      "val_avg_error 4.071829\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:04,126]\u001b[0m Trial 103 finished with value: 4.071766333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.027113722881630692, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332608\n",
      "Last estimator val2_error 3.552721\n",
      "Last estimator val3_error 4.32997\n",
      "val_avg_error 4.071766333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:22,057]\u001b[0m Trial 104 finished with value: 4.073298 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.026210703257811913, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329917\n",
      "Last estimator val2_error 3.555054\n",
      "Last estimator val3_error 4.334923\n",
      "val_avg_error 4.073298\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:30,377]\u001b[0m Trial 105 finished with value: 4.071086333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.06733084552447723, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33593\n",
      "Last estimator val2_error 3.5579\n",
      "Last estimator val3_error 4.319429\n",
      "val_avg_error 4.071086333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:38,994]\u001b[0m Trial 106 finished with value: 4.073871 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.08774111459035928, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339165\n",
      "Last estimator val2_error 3.556186\n",
      "Last estimator val3_error 4.326262\n",
      "val_avg_error 4.073871\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:46,805]\u001b[0m Trial 107 finished with value: 4.460986 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 5, 'learning_rate': 0.06680636212486135, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.695784\n",
      "Last estimator val2_error 3.995029\n",
      "Last estimator val3_error 4.692145\n",
      "val_avg_error 4.460986\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:12:57,130]\u001b[0m Trial 108 finished with value: 4.075258666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.051574695308831575, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331156\n",
      "Last estimator val2_error 3.553207\n",
      "Last estimator val3_error 4.341413\n",
      "val_avg_error 4.075258666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:13:04,798]\u001b[0m Trial 109 finished with value: 4.083212333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.08819206375038255, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 6}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.361831\n",
      "Last estimator val2_error 3.55354\n",
      "Last estimator val3_error 4.334266\n",
      "val_avg_error 4.083212333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:14:51,118]\u001b[0m Trial 110 finished with value: 4.402158333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.0005257961084738489, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.968181\n",
      "Last estimator val2_error 3.755398\n",
      "Last estimator val3_error 4.482896\n",
      "val_avg_error 4.402158333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:14:59,840]\u001b[0m Trial 111 finished with value: 4.074976333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.06294112396563006, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.347518\n",
      "Last estimator val2_error 3.557679\n",
      "Last estimator val3_error 4.319732\n",
      "val_avg_error 4.074976333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:15:20,486]\u001b[0m Trial 112 finished with value: 4.067860333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030996889629883954, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33024\n",
      "Last estimator val2_error 3.561073\n",
      "Last estimator val3_error 4.312268\n",
      "val_avg_error 4.067860333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:15:30,391]\u001b[0m Trial 113 finished with value: 4.073541333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06950368259824587, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.343052\n",
      "Last estimator val2_error 3.56166\n",
      "Last estimator val3_error 4.315912\n",
      "val_avg_error 4.073541333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:16:51,701]\u001b[0m Trial 114 finished with value: 4.502844 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.001981649582200613, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 3, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.803508\n",
      "Last estimator val2_error 4.02201\n",
      "Last estimator val3_error 4.683014\n",
      "val_avg_error 4.502844\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:17:08,651]\u001b[0m Trial 115 finished with value: 4.071719666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03204135429495806, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333869\n",
      "Last estimator val2_error 3.563511\n",
      "Last estimator val3_error 4.317779\n",
      "val_avg_error 4.071719666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:17:18,466]\u001b[0m Trial 116 finished with value: 4.090704666666666 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.04225387117272038, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.397435\n",
      "Last estimator val2_error 3.495944\n",
      "Last estimator val3_error 4.378735\n",
      "val_avg_error 4.090704666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:17:32,187]\u001b[0m Trial 117 finished with value: 4.070059666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03280343661946973, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328532\n",
      "Last estimator val2_error 3.562395\n",
      "Last estimator val3_error 4.319252\n",
      "val_avg_error 4.070059666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:17:44,062]\u001b[0m Trial 118 finished with value: 4.0763506666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05317368267464799, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 3, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.341932\n",
      "Last estimator val2_error 3.55945\n",
      "Last estimator val3_error 4.32767\n",
      "val_avg_error 4.0763506666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:17:54,774]\u001b[0m Trial 119 finished with value: 4.093697333333334 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.07901898833394877, 'subsample': 0.9, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.389259\n",
      "Last estimator val2_error 3.497883\n",
      "Last estimator val3_error 4.39395\n",
      "val_avg_error 4.093697333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:02,660]\u001b[0m Trial 120 finished with value: 4.465408 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.09931465780605796, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.709749\n",
      "Last estimator val2_error 3.997561\n",
      "Last estimator val3_error 4.688914\n",
      "val_avg_error 4.465408\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:11,523]\u001b[0m Trial 121 finished with value: 4.068421333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05696513548539849, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329266\n",
      "Last estimator val2_error 3.56224\n",
      "Last estimator val3_error 4.313758\n",
      "val_avg_error 4.068421333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:25,088]\u001b[0m Trial 122 finished with value: 4.070299666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05653589974574841, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333787\n",
      "Last estimator val2_error 3.5608\n",
      "Last estimator val3_error 4.316312\n",
      "val_avg_error 4.070299666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:32,801]\u001b[0m Trial 123 finished with value: 7.444328333333334 and parameters: {'tweedie_variance_power': 1.2000000000000002, 'max_depth': 4, 'learning_rate': 0.04854966487803635, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 8.227064\n",
      "Last estimator val2_error 5.893879\n",
      "Last estimator val3_error 8.212042\n",
      "val_avg_error 7.444328333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:39,976]\u001b[0m Trial 124 finished with value: 4.067528666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08403203197758452, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.320141\n",
      "Last estimator val2_error 3.564312\n",
      "Last estimator val3_error 4.318133\n",
      "val_avg_error 4.067528666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:46,736]\u001b[0m Trial 125 finished with value: 4.069398666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0849142686055157, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32872\n",
      "Last estimator val2_error 3.566186\n",
      "Last estimator val3_error 4.31329\n",
      "val_avg_error 4.069398666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:18:55,318]\u001b[0m Trial 126 finished with value: 4.0677449999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07498040128971857, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324471\n",
      "Last estimator val2_error 3.563498\n",
      "Last estimator val3_error 4.315266\n",
      "val_avg_error 4.0677449999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:19:04,328]\u001b[0m Trial 127 finished with value: 4.068613333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08177464247443103, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324307\n",
      "Last estimator val2_error 3.563011\n",
      "Last estimator val3_error 4.318522\n",
      "val_avg_error 4.068613333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:19:12,156]\u001b[0m Trial 128 finished with value: 4.070232333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0827463702503117, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.319173\n",
      "Last estimator val2_error 3.562976\n",
      "Last estimator val3_error 4.328548\n",
      "val_avg_error 4.070232333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:19:20,311]\u001b[0m Trial 129 finished with value: 4.457474333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.08801259600751914, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.690372\n",
      "Last estimator val2_error 3.997919\n",
      "Last estimator val3_error 4.684132\n",
      "val_avg_error 4.457474333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:20:45,066]\u001b[0m Trial 130 finished with value: 4.67383 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.0002112828438835698, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.304968\n",
      "Last estimator val2_error 3.876122\n",
      "Last estimator val3_error 4.8404\n",
      "val_avg_error 4.67383\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:20:54,966]\u001b[0m Trial 131 finished with value: 4.070739666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08042673522127984, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331721\n",
      "Last estimator val2_error 3.557583\n",
      "Last estimator val3_error 4.322915\n",
      "val_avg_error 4.070739666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:06,605]\u001b[0m Trial 132 finished with value: 4.070394 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0726674490964686, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332556\n",
      "Last estimator val2_error 3.565828\n",
      "Last estimator val3_error 4.312798\n",
      "val_avg_error 4.070394\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:12,997]\u001b[0m Trial 133 finished with value: 4.068184333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08121577697180332, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323201\n",
      "Last estimator val2_error 3.564833\n",
      "Last estimator val3_error 4.316519\n",
      "val_avg_error 4.068184333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:23,765]\u001b[0m Trial 134 finished with value: 4.072148666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.061251478523439616, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.3403\n",
      "Last estimator val2_error 3.559054\n",
      "Last estimator val3_error 4.317092\n",
      "val_avg_error 4.072148666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:32,279]\u001b[0m Trial 135 finished with value: 4.066863000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08448154656643588, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324534\n",
      "Last estimator val2_error 3.56049\n",
      "Last estimator val3_error 4.315565\n",
      "val_avg_error 4.066863000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:37,475]\u001b[0m Trial 136 finished with value: 4.105512333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08568159247866293, 'subsample': 0.1, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.355\n",
      "Last estimator val2_error 3.609733\n",
      "Last estimator val3_error 4.351804\n",
      "val_avg_error 4.105512333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:44,530]\u001b[0m Trial 137 finished with value: 4.4626280000000005 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.08133137601314162, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.704086\n",
      "Last estimator val2_error 3.996652\n",
      "Last estimator val3_error 4.687146\n",
      "val_avg_error 4.4626280000000005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:21:54,911]\u001b[0m Trial 138 finished with value: 4.0713593333333336 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06656848547184778, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330335\n",
      "Last estimator val2_error 3.562248\n",
      "Last estimator val3_error 4.321495\n",
      "val_avg_error 4.0713593333333336\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:02,756]\u001b[0m Trial 139 finished with value: 4.095272333333334 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.08913163944777835, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.4119\n",
      "Last estimator val2_error 3.503045\n",
      "Last estimator val3_error 4.370872\n",
      "val_avg_error 4.095272333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:11,360]\u001b[0m Trial 140 finished with value: 4.072355333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07663776101860924, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.336709\n",
      "Last estimator val2_error 3.563722\n",
      "Last estimator val3_error 4.316635\n",
      "val_avg_error 4.072355333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:20,010]\u001b[0m Trial 141 finished with value: 4.072936333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05724111934854996, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.341073\n",
      "Last estimator val2_error 3.562293\n",
      "Last estimator val3_error 4.315443\n",
      "val_avg_error 4.072936333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:26,847]\u001b[0m Trial 142 finished with value: 4.077054333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.09877559297439983, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.351565\n",
      "Last estimator val2_error 3.566201\n",
      "Last estimator val3_error 4.313397\n",
      "val_avg_error 4.077054333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:35,080]\u001b[0m Trial 143 finished with value: 4.0718776666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05605357740330609, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332333\n",
      "Last estimator val2_error 3.566067\n",
      "Last estimator val3_error 4.317233\n",
      "val_avg_error 4.0718776666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:48,667]\u001b[0m Trial 144 finished with value: 4.067004 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04212584536026867, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325175\n",
      "Last estimator val2_error 3.561083\n",
      "Last estimator val3_error 4.314754\n",
      "val_avg_error 4.067004\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:22:59,140]\u001b[0m Trial 145 finished with value: 4.0703293333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06901102566588568, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330488\n",
      "Last estimator val2_error 3.562677\n",
      "Last estimator val3_error 4.317823\n",
      "val_avg_error 4.0703293333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:23:11,931]\u001b[0m Trial 146 finished with value: 4.067968333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.041804212471702636, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.321456\n",
      "Last estimator val2_error 3.562461\n",
      "Last estimator val3_error 4.319988\n",
      "val_avg_error 4.067968333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:23:22,700]\u001b[0m Trial 147 finished with value: 4.088225666666666 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.04095642227405268, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.3907\n",
      "Last estimator val2_error 3.496615\n",
      "Last estimator val3_error 4.377362\n",
      "val_avg_error 4.088225666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:23:34,612]\u001b[0m Trial 148 finished with value: 4.073559333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04803922293963171, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.336262\n",
      "Last estimator val2_error 3.566186\n",
      "Last estimator val3_error 4.31823\n",
      "val_avg_error 4.073559333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:23:49,856]\u001b[0m Trial 149 finished with value: 4.068256000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.04292825499758596, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326474\n",
      "Last estimator val2_error 3.569968\n",
      "Last estimator val3_error 4.308326\n",
      "val_avg_error 4.068256000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:24:00,972]\u001b[0m Trial 150 finished with value: 4.069527666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.0414335544625359, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327729\n",
      "Last estimator val2_error 3.569561\n",
      "Last estimator val3_error 4.311293\n",
      "val_avg_error 4.069527666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:24:12,209]\u001b[0m Trial 151 finished with value: 4.069096333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.04518775427050801, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329848\n",
      "Last estimator val2_error 3.566827\n",
      "Last estimator val3_error 4.310614\n",
      "val_avg_error 4.069096333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:24:23,289]\u001b[0m Trial 152 finished with value: 4.069994333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.04141287863462671, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330243\n",
      "Last estimator val2_error 3.569594\n",
      "Last estimator val3_error 4.310146\n",
      "val_avg_error 4.069994333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:24:36,418]\u001b[0m Trial 153 finished with value: 4.07012 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.04257669508007531, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32584\n",
      "Last estimator val2_error 3.567783\n",
      "Last estimator val3_error 4.316737\n",
      "val_avg_error 4.07012\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:24:50,254]\u001b[0m Trial 154 finished with value: 4.074176666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.0382904668117906, 'subsample': 0.6, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334964\n",
      "Last estimator val2_error 3.57063\n",
      "Last estimator val3_error 4.316936\n",
      "val_avg_error 4.074176666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:25:00,636]\u001b[0m Trial 155 finished with value: 4.0727839999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.04838113715648413, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330094\n",
      "Last estimator val2_error 3.574028\n",
      "Last estimator val3_error 4.31423\n",
      "val_avg_error 4.0727839999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:25:09,517]\u001b[0m Trial 156 finished with value: 4.072206666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.0632624195673599, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329336\n",
      "Last estimator val2_error 3.5734\n",
      "Last estimator val3_error 4.313884\n",
      "val_avg_error 4.072206666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:25:16,609]\u001b[0m Trial 157 finished with value: 4.0727736666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.05077423429054989, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326867\n",
      "Last estimator val2_error 3.576684\n",
      "Last estimator val3_error 4.31477\n",
      "val_avg_error 4.0727736666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:26:29,939]\u001b[0m Trial 158 finished with value: 4.213536666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.001000430964223274, 'subsample': 0.6, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.649592\n",
      "Last estimator val2_error 3.648033\n",
      "Last estimator val3_error 4.342985\n",
      "val_avg_error 4.213536666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:27:33,012]\u001b[0m Trial 159 finished with value: 4.471213666666666 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 3, 'learning_rate': 0.003490164246957094, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.717789\n",
      "Last estimator val2_error 4.01582\n",
      "Last estimator val3_error 4.680032\n",
      "val_avg_error 4.471213666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:27:52,097]\u001b[0m Trial 160 finished with value: 4.069652666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.03114421756705422, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326435\n",
      "Last estimator val2_error 3.568009\n",
      "Last estimator val3_error 4.314514\n",
      "val_avg_error 4.069652666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:27:59,334]\u001b[0m Trial 161 finished with value: 4.079228333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.07373840952246451, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.347497\n",
      "Last estimator val2_error 3.574358\n",
      "Last estimator val3_error 4.31583\n",
      "val_avg_error 4.079228333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:28:08,047]\u001b[0m Trial 162 finished with value: 4.074811333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06097248069933935, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338318\n",
      "Last estimator val2_error 3.564117\n",
      "Last estimator val3_error 4.321999\n",
      "val_avg_error 4.074811333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:28:20,932]\u001b[0m Trial 163 finished with value: 4.074245333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0712042415549367, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.344039\n",
      "Last estimator val2_error 3.560823\n",
      "Last estimator val3_error 4.317874\n",
      "val_avg_error 4.074245333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:28:33,398]\u001b[0m Trial 164 finished with value: 4.0832006666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 7, 'learning_rate': 0.04398000414263492, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.354441\n",
      "Last estimator val2_error 3.554438\n",
      "Last estimator val3_error 4.340723\n",
      "val_avg_error 4.0832006666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:28:45,195]\u001b[0m Trial 165 finished with value: 4.076877666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.08827021662556778, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333606\n",
      "Last estimator val2_error 3.56805\n",
      "Last estimator val3_error 4.328977\n",
      "val_avg_error 4.076877666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:28:55,397]\u001b[0m Trial 166 finished with value: 4.069998333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.053435421918531185, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330381\n",
      "Last estimator val2_error 3.559618\n",
      "Last estimator val3_error 4.319996\n",
      "val_avg_error 4.069998333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:29:01,620]\u001b[0m Trial 167 finished with value: 9.660130666666667 and parameters: {'tweedie_variance_power': 1.9, 'max_depth': 4, 'learning_rate': 0.09927807530331065, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 9.950977\n",
      "Last estimator val2_error 9.06348\n",
      "Last estimator val3_error 9.965935\n",
      "val_avg_error 9.660130666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:29:07,746]\u001b[0m Trial 168 finished with value: 4.0934843333333335 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 3, 'learning_rate': 0.06334991415485886, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.400578\n",
      "Last estimator val2_error 3.509144\n",
      "Last estimator val3_error 4.370731\n",
      "val_avg_error 4.0934843333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:29:20,216]\u001b[0m Trial 169 finished with value: 4.4579173333333335 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.034936900421608345, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.698483\n",
      "Last estimator val2_error 3.993507\n",
      "Last estimator val3_error 4.681762\n",
      "val_avg_error 4.4579173333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:29:29,366]\u001b[0m Trial 170 finished with value: 4.070577 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07674874399993044, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333252\n",
      "Last estimator val2_error 3.563241\n",
      "Last estimator val3_error 4.315238\n",
      "val_avg_error 4.070577\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:29:50,837]\u001b[0m Trial 171 finished with value: 4.069932333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.024183440797390054, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329276\n",
      "Last estimator val2_error 3.57081\n",
      "Last estimator val3_error 4.309711\n",
      "val_avg_error 4.069932333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:30:06,049]\u001b[0m Trial 172 finished with value: 4.070726666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.03251452316765861, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329829\n",
      "Last estimator val2_error 3.570067\n",
      "Last estimator val3_error 4.312284\n",
      "val_avg_error 4.070726666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:30:21,158]\u001b[0m Trial 173 finished with value: 4.072860666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.027552161780691344, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331772\n",
      "Last estimator val2_error 3.574833\n",
      "Last estimator val3_error 4.311977\n",
      "val_avg_error 4.072860666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:30:33,921]\u001b[0m Trial 174 finished with value: 4.072372333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.029495659955157197, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327599\n",
      "Last estimator val2_error 3.573024\n",
      "Last estimator val3_error 4.316494\n",
      "val_avg_error 4.072372333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:30:44,787]\u001b[0m Trial 175 finished with value: 4.068939333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.038024396897980345, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32575\n",
      "Last estimator val2_error 3.566445\n",
      "Last estimator val3_error 4.314623\n",
      "val_avg_error 4.068939333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:30:54,228]\u001b[0m Trial 176 finished with value: 4.074708333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03892776024113669, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339922\n",
      "Last estimator val2_error 3.56589\n",
      "Last estimator val3_error 4.318313\n",
      "val_avg_error 4.074708333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:06,064]\u001b[0m Trial 177 finished with value: 4.0682583333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04585204138521771, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326302\n",
      "Last estimator val2_error 3.563097\n",
      "Last estimator val3_error 4.315376\n",
      "val_avg_error 4.0682583333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:16,804]\u001b[0m Trial 178 finished with value: 4.069516 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04625243432010743, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332096\n",
      "Last estimator val2_error 3.563522\n",
      "Last estimator val3_error 4.31293\n",
      "val_avg_error 4.069516\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:27,497]\u001b[0m Trial 179 finished with value: 4.069285333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04694634250641924, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328707\n",
      "Last estimator val2_error 3.563602\n",
      "Last estimator val3_error 4.315547\n",
      "val_avg_error 4.069285333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:36,467]\u001b[0m Trial 180 finished with value: 4.073483333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.052924493838987494, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.336807\n",
      "Last estimator val2_error 3.566121\n",
      "Last estimator val3_error 4.317522\n",
      "val_avg_error 4.073483333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:47,417]\u001b[0m Trial 181 finished with value: 4.069508333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04568243358420197, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331563\n",
      "Last estimator val2_error 3.563024\n",
      "Last estimator val3_error 4.313938\n",
      "val_avg_error 4.069508333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:31:59,691]\u001b[0m Trial 182 finished with value: 4.0725620000000005 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.055824194963640134, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338866\n",
      "Last estimator val2_error 3.56342\n",
      "Last estimator val3_error 4.3154\n",
      "val_avg_error 4.0725620000000005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:10,629]\u001b[0m Trial 183 finished with value: 4.071453333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.048291891464397316, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334521\n",
      "Last estimator val2_error 3.565947\n",
      "Last estimator val3_error 4.313892\n",
      "val_avg_error 4.071453333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:23,405]\u001b[0m Trial 184 finished with value: 4.074102 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03685645349890413, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335608\n",
      "Last estimator val2_error 3.566362\n",
      "Last estimator val3_error 4.320336\n",
      "val_avg_error 4.074102\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:30,620]\u001b[0m Trial 185 finished with value: 4.071186 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06591659794156875, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335217\n",
      "Last estimator val2_error 3.565534\n",
      "Last estimator val3_error 4.312807\n",
      "val_avg_error 4.071186\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:40,683]\u001b[0m Trial 186 finished with value: 4.068803666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04493044325277917, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323666\n",
      "Last estimator val2_error 3.565662\n",
      "Last estimator val3_error 4.317083\n",
      "val_avg_error 4.068803666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:48,261]\u001b[0m Trial 187 finished with value: 4.074237 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.06078463984358561, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.337301\n",
      "Last estimator val2_error 3.56731\n",
      "Last estimator val3_error 4.3181\n",
      "val_avg_error 4.074237\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:32:57,196]\u001b[0m Trial 188 finished with value: 4.068755666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07868176732999038, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329482\n",
      "Last estimator val2_error 3.561975\n",
      "Last estimator val3_error 4.31481\n",
      "val_avg_error 4.068755666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:33:11,346]\u001b[0m Trial 189 finished with value: 4.071222 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04005983264521185, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330018\n",
      "Last estimator val2_error 3.563823\n",
      "Last estimator val3_error 4.319825\n",
      "val_avg_error 4.071222\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:33:24,461]\u001b[0m Trial 190 finished with value: 4.087925333333334 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.05337115997818532, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.396195\n",
      "Last estimator val2_error 3.490852\n",
      "Last estimator val3_error 4.376729\n",
      "val_avg_error 4.087925333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:33:33,561]\u001b[0m Trial 191 finished with value: 4.0738883333333336 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07675363095186466, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.336785\n",
      "Last estimator val2_error 3.559978\n",
      "Last estimator val3_error 4.324902\n",
      "val_avg_error 4.0738883333333336\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:33:40,467]\u001b[0m Trial 192 finished with value: 4.076549666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08389106483547817, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33263\n",
      "Last estimator val2_error 3.569988\n",
      "Last estimator val3_error 4.327031\n",
      "val_avg_error 4.076549666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:33:52,504]\u001b[0m Trial 193 finished with value: 4.075304666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0674438250829374, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.345532\n",
      "Last estimator val2_error 3.562963\n",
      "Last estimator val3_error 4.317419\n",
      "val_avg_error 4.075304666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:50:48,878]\u001b[0m Trial 194 finished with value: 4.092667333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 9, 'learning_rate': 0.059006240423774566, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.375069\n",
      "Last estimator val2_error 3.561399\n",
      "Last estimator val3_error 4.341534\n",
      "val_avg_error 4.092667333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:51:36,292]\u001b[0m Trial 195 finished with value: 4.067420666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.006611688575262171, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324244\n",
      "Last estimator val2_error 3.565908\n",
      "Last estimator val3_error 4.31211\n",
      "val_avg_error 4.067420666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:51:50,999]\u001b[0m Trial 196 finished with value: 4.071698 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03434737321092715, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331579\n",
      "Last estimator val2_error 3.567459\n",
      "Last estimator val3_error 4.316056\n",
      "val_avg_error 4.071698\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:52:00,716]\u001b[0m Trial 197 finished with value: 4.070767333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.046603411551377115, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333046\n",
      "Last estimator val2_error 3.566723\n",
      "Last estimator val3_error 4.312533\n",
      "val_avg_error 4.070767333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:53:25,316]\u001b[0m Trial 198 finished with value: 4.125525 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0016707133742231593, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 7}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.465667\n",
      "Last estimator val2_error 3.59146\n",
      "Last estimator val3_error 4.319448\n",
      "val_avg_error 4.125525\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:53:38,051]\u001b[0m Trial 199 finished with value: 4.068494666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.040835484053030696, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327989\n",
      "Last estimator val2_error 3.563497\n",
      "Last estimator val3_error 4.313998\n",
      "val_avg_error 4.068494666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:54:27,307]\u001b[0m Trial 200 finished with value: 4.073098333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.0062429640483851415, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 7}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338594\n",
      "Last estimator val2_error 3.558961\n",
      "Last estimator val3_error 4.32174\n",
      "val_avg_error 4.073098333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:54:35,785]\u001b[0m Trial 201 finished with value: 4.074614 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.039224817522143324, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339114\n",
      "Last estimator val2_error 3.567451\n",
      "Last estimator val3_error 4.317277\n",
      "val_avg_error 4.074614\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:54:46,530]\u001b[0m Trial 202 finished with value: 4.067235666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.044876705788266864, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323595\n",
      "Last estimator val2_error 3.563697\n",
      "Last estimator val3_error 4.314415\n",
      "val_avg_error 4.067235666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:55:01,352]\u001b[0m Trial 203 finished with value: 4.07223 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03467306247533011, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333652\n",
      "Last estimator val2_error 3.567713\n",
      "Last estimator val3_error 4.315325\n",
      "val_avg_error 4.07223\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:55:10,663]\u001b[0m Trial 204 finished with value: 4.083485666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.043608121599906485, 'subsample': 0.4, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.350253\n",
      "Last estimator val2_error 3.56415\n",
      "Last estimator val3_error 4.336054\n",
      "val_avg_error 4.083485666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:55:20,288]\u001b[0m Trial 205 finished with value: 4.074585 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0725694081192752, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339038\n",
      "Last estimator val2_error 3.564693\n",
      "Last estimator val3_error 4.320024\n",
      "val_avg_error 4.074585\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:55:29,637]\u001b[0m Trial 206 finished with value: 4.0705946666666675 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.054986322797022515, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 7}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333764\n",
      "Last estimator val2_error 3.565417\n",
      "Last estimator val3_error 4.312603\n",
      "val_avg_error 4.0705946666666675\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:55:40,505]\u001b[0m Trial 207 finished with value: 4.0762453333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0378159727677722, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.341798\n",
      "Last estimator val2_error 3.569747\n",
      "Last estimator val3_error 4.317191\n",
      "val_avg_error 4.0762453333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:56:11,754]\u001b[0m Trial 208 finished with value: 4.069685 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.010949304260035774, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326762\n",
      "Last estimator val2_error 3.565434\n",
      "Last estimator val3_error 4.316859\n",
      "val_avg_error 4.069685\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:57:12,071]\u001b[0m Trial 209 finished with value: 4.086050333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.002682519674725694, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.368272\n",
      "Last estimator val2_error 3.574122\n",
      "Last estimator val3_error 4.315757\n",
      "val_avg_error 4.086050333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:57:18,972]\u001b[0m Trial 210 finished with value: 4.466237333333334 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.06359548457652733, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.706114\n",
      "Last estimator val2_error 4.006423\n",
      "Last estimator val3_error 4.686175\n",
      "val_avg_error 4.466237333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:57:29,707]\u001b[0m Trial 211 finished with value: 4.071212 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.048475355182522516, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335641\n",
      "Last estimator val2_error 3.564574\n",
      "Last estimator val3_error 4.313421\n",
      "val_avg_error 4.071212\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:58:05,929]\u001b[0m Trial 212 finished with value: 4.070579333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.007530318511446711, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327401\n",
      "Last estimator val2_error 3.57091\n",
      "Last estimator val3_error 4.313427\n",
      "val_avg_error 4.070579333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:58:17,508]\u001b[0m Trial 213 finished with value: 4.069756 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.043870584141763876, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329903\n",
      "Last estimator val2_error 3.56349\n",
      "Last estimator val3_error 4.315875\n",
      "val_avg_error 4.069756\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:58:27,185]\u001b[0m Trial 214 finished with value: 4.0691999999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.05164312230186377, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331154\n",
      "Last estimator val2_error 3.564041\n",
      "Last estimator val3_error 4.312405\n",
      "val_avg_error 4.0691999999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:58:44,509]\u001b[0m Trial 215 finished with value: 4.06907 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03073059099163347, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328404\n",
      "Last estimator val2_error 3.564609\n",
      "Last estimator val3_error 4.314197\n",
      "val_avg_error 4.06907\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:58:58,658]\u001b[0m Trial 216 finished with value: 4.073708333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023082956302472698, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 10}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331169\n",
      "Last estimator val2_error 3.567532\n",
      "Last estimator val3_error 4.322424\n",
      "val_avg_error 4.073708333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:59:17,427]\u001b[0m Trial 217 finished with value: 4.067969000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027969789345597, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327265\n",
      "Last estimator val2_error 3.563772\n",
      "Last estimator val3_error 4.31287\n",
      "val_avg_error 4.067969000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:59:28,611]\u001b[0m Trial 218 finished with value: 4.070293 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02712566307028695, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327569\n",
      "Last estimator val2_error 3.569935\n",
      "Last estimator val3_error 4.313375\n",
      "val_avg_error 4.070293\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 14:59:39,608]\u001b[0m Trial 219 finished with value: 4.1018273333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02943578840299538, 'subsample': 0.2, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.382261\n",
      "Last estimator val2_error 3.582977\n",
      "Last estimator val3_error 4.340244\n",
      "val_avg_error 4.1018273333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:00:02,706]\u001b[0m Trial 220 finished with value: 7.437712 and parameters: {'tweedie_variance_power': 1.2000000000000002, 'max_depth': 4, 'learning_rate': 0.03207037111434938, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 8.219178\n",
      "Last estimator val2_error 5.886149\n",
      "Last estimator val3_error 8.207809\n",
      "val_avg_error 7.437712\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:00:12,984]\u001b[0m Trial 221 finished with value: 4.070443666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03475090985929584, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324849\n",
      "Last estimator val2_error 3.567668\n",
      "Last estimator val3_error 4.318814\n",
      "val_avg_error 4.070443666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:00:27,906]\u001b[0m Trial 222 finished with value: 4.070270333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.040475338190696444, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 8}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325867\n",
      "Last estimator val2_error 3.564766\n",
      "Last estimator val3_error 4.320178\n",
      "val_avg_error 4.070270333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:00:45,271]\u001b[0m Trial 223 finished with value: 4.0701496666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02035467496643904, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330844\n",
      "Last estimator val2_error 3.564703\n",
      "Last estimator val3_error 4.314902\n",
      "val_avg_error 4.0701496666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:00:54,231]\u001b[0m Trial 224 finished with value: 4.071000000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07940588989896301, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330951\n",
      "Last estimator val2_error 3.561319\n",
      "Last estimator val3_error 4.32073\n",
      "val_avg_error 4.071000000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:01:05,910]\u001b[0m Trial 225 finished with value: 4.072090666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030181315301251756, 'subsample': 0.8, 'colsample_bytree': 0.9, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 9}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330449\n",
      "Last estimator val2_error 3.568611\n",
      "Last estimator val3_error 4.317212\n",
      "val_avg_error 4.072090666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:01:15,902]\u001b[0m Trial 226 finished with value: 4.0690273333333336 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.036133960256503166, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 1}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322602\n",
      "Last estimator val2_error 3.56667\n",
      "Last estimator val3_error 4.31781\n",
      "val_avg_error 4.0690273333333336\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:01:33,534]\u001b[0m Trial 227 finished with value: 4.068214666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02445532972769655, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325424\n",
      "Last estimator val2_error 3.563022\n",
      "Last estimator val3_error 4.316198\n",
      "val_avg_error 4.068214666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:01:49,149]\u001b[0m Trial 228 finished with value: 4.067797666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03522293132963262, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325798\n",
      "Last estimator val2_error 3.563729\n",
      "Last estimator val3_error 4.313866\n",
      "val_avg_error 4.067797666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:02:16,083]\u001b[0m Trial 229 finished with value: 4.088124333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 10, 'learning_rate': 0.025355265525889105, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.368302\n",
      "Last estimator val2_error 3.549702\n",
      "Last estimator val3_error 4.346369\n",
      "val_avg_error 4.088124333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:02:24,544]\u001b[0m Trial 230 finished with value: 4.074686333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.08911635477450065, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 2, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.340476\n",
      "Last estimator val2_error 3.567125\n",
      "Last estimator val3_error 4.316458\n",
      "val_avg_error 4.074686333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:02:37,239]\u001b[0m Trial 231 finished with value: 4.067980333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03509996453327621, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 95 with value: 4.066834.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323301\n",
      "Last estimator val2_error 3.563673\n",
      "Last estimator val3_error 4.316967\n",
      "val_avg_error 4.067980333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:02:49,258]\u001b[0m Trial 232 finished with value: 4.0667393333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03781099119927495, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324105\n",
      "Last estimator val2_error 3.564915\n",
      "Last estimator val3_error 4.311198\n",
      "val_avg_error 4.0667393333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:03:11,745]\u001b[0m Trial 233 finished with value: 4.068994666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02260527687312473, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330808\n",
      "Last estimator val2_error 3.559773\n",
      "Last estimator val3_error 4.316403\n",
      "val_avg_error 4.068994666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:03:25,872]\u001b[0m Trial 234 finished with value: 4.070668 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03363349859845728, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333151\n",
      "Last estimator val2_error 3.566497\n",
      "Last estimator val3_error 4.312356\n",
      "val_avg_error 4.070668\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:03:43,156]\u001b[0m Trial 235 finished with value: 4.068904666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.040218138378813564, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323206\n",
      "Last estimator val2_error 3.561849\n",
      "Last estimator val3_error 4.321659\n",
      "val_avg_error 4.068904666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:03:59,997]\u001b[0m Trial 236 finished with value: 4.069079666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02670617442339745, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322769\n",
      "Last estimator val2_error 3.564991\n",
      "Last estimator val3_error 4.319479\n",
      "val_avg_error 4.069079666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:04:10,712]\u001b[0m Trial 237 finished with value: 4.0742606666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.07215053163734067, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.339273\n",
      "Last estimator val2_error 3.565725\n",
      "Last estimator val3_error 4.317784\n",
      "val_avg_error 4.0742606666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:05:09,108]\u001b[0m Trial 238 finished with value: 4.069377 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.004806342143250523, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 4, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330445\n",
      "Last estimator val2_error 3.566216\n",
      "Last estimator val3_error 4.31147\n",
      "val_avg_error 4.069377\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:05:21,620]\u001b[0m Trial 239 finished with value: 4.074154333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.04166874766728017, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338331\n",
      "Last estimator val2_error 3.554119\n",
      "Last estimator val3_error 4.330013\n",
      "val_avg_error 4.074154333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:05:29,654]\u001b[0m Trial 240 finished with value: 4.071959 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.058163936252439145, 'subsample': 0.8, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33462\n",
      "Last estimator val2_error 3.567913\n",
      "Last estimator val3_error 4.313344\n",
      "val_avg_error 4.071959\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:05:41,693]\u001b[0m Trial 241 finished with value: 4.067412 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.038118249837673965, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324598\n",
      "Last estimator val2_error 3.563561\n",
      "Last estimator val3_error 4.314077\n",
      "val_avg_error 4.067412\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:05:59,574]\u001b[0m Trial 242 finished with value: 4.069099333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03392927644877105, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328413\n",
      "Last estimator val2_error 3.560026\n",
      "Last estimator val3_error 4.318859\n",
      "val_avg_error 4.069099333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:06:15,167]\u001b[0m Trial 243 finished with value: 4.067670333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03876397500234606, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.319963\n",
      "Last estimator val2_error 3.563548\n",
      "Last estimator val3_error 4.3195\n",
      "val_avg_error 4.067670333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:06:38,242]\u001b[0m Trial 244 finished with value: 4.066742333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030757612959129387, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326086\n",
      "Last estimator val2_error 3.561546\n",
      "Last estimator val3_error 4.312595\n",
      "val_avg_error 4.066742333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:06:53,084]\u001b[0m Trial 245 finished with value: 4.067716333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03117563449012902, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328942\n",
      "Last estimator val2_error 3.562767\n",
      "Last estimator val3_error 4.31144\n",
      "val_avg_error 4.067716333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:07:18,518]\u001b[0m Trial 246 finished with value: 4.067531 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02629515852756331, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 232 with value: 4.0667393333333335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329273\n",
      "Last estimator val2_error 3.560328\n",
      "Last estimator val3_error 4.312992\n",
      "val_avg_error 4.067531\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:07:45,182]\u001b[0m Trial 247 finished with value: 4.066033333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026524247762319743, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325695\n",
      "Last estimator val2_error 3.559354\n",
      "Last estimator val3_error 4.313051\n",
      "val_avg_error 4.066033333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:08:00,653]\u001b[0m Trial 248 finished with value: 4.070635666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02120381066797723, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329835\n",
      "Last estimator val2_error 3.567835\n",
      "Last estimator val3_error 4.314237\n",
      "val_avg_error 4.070635666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:08:22,925]\u001b[0m Trial 249 finished with value: 4.066388666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026137441696477467, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324986\n",
      "Last estimator val2_error 3.561731\n",
      "Last estimator val3_error 4.312449\n",
      "val_avg_error 4.066388666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:08:38,785]\u001b[0m Trial 250 finished with value: 4.069709333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.024858550615868134, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328359\n",
      "Last estimator val2_error 3.56816\n",
      "Last estimator val3_error 4.312609\n",
      "val_avg_error 4.069709333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:08:56,944]\u001b[0m Trial 251 finished with value: 4.08771 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.02462579011364593, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.388317\n",
      "Last estimator val2_error 3.494141\n",
      "Last estimator val3_error 4.380672\n",
      "val_avg_error 4.08771\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:09:15,261]\u001b[0m Trial 252 finished with value: 4.066620333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.029083736914147326, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324598\n",
      "Last estimator val2_error 3.560191\n",
      "Last estimator val3_error 4.315072\n",
      "val_avg_error 4.066620333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:09:32,275]\u001b[0m Trial 253 finished with value: 4.066198 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028358254017244726, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324208\n",
      "Last estimator val2_error 3.561732\n",
      "Last estimator val3_error 4.312654\n",
      "val_avg_error 4.066198\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:09:49,754]\u001b[0m Trial 254 finished with value: 4.066810333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02850985418045522, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324162\n",
      "Last estimator val2_error 3.561317\n",
      "Last estimator val3_error 4.314952\n",
      "val_avg_error 4.066810333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:10:06,409]\u001b[0m Trial 255 finished with value: 4.068776 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028629061559660978, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324852\n",
      "Last estimator val2_error 3.565999\n",
      "Last estimator val3_error 4.315477\n",
      "val_avg_error 4.068776\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:10:27,347]\u001b[0m Trial 256 finished with value: 4.066674666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02801852288556205, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327761\n",
      "Last estimator val2_error 3.559311\n",
      "Last estimator val3_error 4.312952\n",
      "val_avg_error 4.066674666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:10:45,999]\u001b[0m Trial 257 finished with value: 4.0675859999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02809813259583872, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327681\n",
      "Last estimator val2_error 3.562668\n",
      "Last estimator val3_error 4.312409\n",
      "val_avg_error 4.0675859999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:11:05,655]\u001b[0m Trial 258 finished with value: 4.0685986666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.018887117367858346, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329387\n",
      "Last estimator val2_error 3.565243\n",
      "Last estimator val3_error 4.311166\n",
      "val_avg_error 4.0685986666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:11:25,753]\u001b[0m Trial 259 finished with value: 4.067131 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027239829370184765, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326545\n",
      "Last estimator val2_error 3.56003\n",
      "Last estimator val3_error 4.314818\n",
      "val_avg_error 4.067131\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:11:44,188]\u001b[0m Trial 260 finished with value: 4.066264666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0284645242234113, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327215\n",
      "Last estimator val2_error 3.559315\n",
      "Last estimator val3_error 4.312264\n",
      "val_avg_error 4.066264666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:12:08,591]\u001b[0m Trial 261 finished with value: 4.067319666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022199838347185114, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329721\n",
      "Last estimator val2_error 3.559219\n",
      "Last estimator val3_error 4.313019\n",
      "val_avg_error 4.067319666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:12:26,926]\u001b[0m Trial 262 finished with value: 4.06928 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.021997698981644206, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329472\n",
      "Last estimator val2_error 3.563656\n",
      "Last estimator val3_error 4.314712\n",
      "val_avg_error 4.06928\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:12:49,058]\u001b[0m Trial 263 finished with value: 4.0673319999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02677975735393568, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327659\n",
      "Last estimator val2_error 3.560024\n",
      "Last estimator val3_error 4.314313\n",
      "val_avg_error 4.0673319999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:13:06,977]\u001b[0m Trial 264 finished with value: 4.455328333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.02656669349509269, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.687535\n",
      "Last estimator val2_error 3.996405\n",
      "Last estimator val3_error 4.682045\n",
      "val_avg_error 4.455328333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:13:23,935]\u001b[0m Trial 265 finished with value: 4.069990333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02121202544550791, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331536\n",
      "Last estimator val2_error 3.564586\n",
      "Last estimator val3_error 4.313849\n",
      "val_avg_error 4.069990333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:13:53,269]\u001b[0m Trial 266 finished with value: 4.068262666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.015587772811969205, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327335\n",
      "Last estimator val2_error 3.55923\n",
      "Last estimator val3_error 4.318223\n",
      "val_avg_error 4.068262666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:14:09,539]\u001b[0m Trial 267 finished with value: 4.069815333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028992427340312828, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326245\n",
      "Last estimator val2_error 3.560524\n",
      "Last estimator val3_error 4.322677\n",
      "val_avg_error 4.069815333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:14:28,665]\u001b[0m Trial 268 finished with value: 4.072740666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02397935404615313, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.337796\n",
      "Last estimator val2_error 3.562689\n",
      "Last estimator val3_error 4.317737\n",
      "val_avg_error 4.072740666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:14:42,695]\u001b[0m Trial 269 finished with value: 4.068342666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027401408497814514, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328726\n",
      "Last estimator val2_error 3.564554\n",
      "Last estimator val3_error 4.311748\n",
      "val_avg_error 4.068342666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:14:57,045]\u001b[0m Trial 270 finished with value: 4.086218333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.02865151958394458, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.391635\n",
      "Last estimator val2_error 3.492684\n",
      "Last estimator val3_error 4.374336\n",
      "val_avg_error 4.086218333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:15:18,454]\u001b[0m Trial 271 finished with value: 4.069109999999999 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.020124481945934147, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329285\n",
      "Last estimator val2_error 3.566096\n",
      "Last estimator val3_error 4.311949\n",
      "val_avg_error 4.069109999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:15:34,830]\u001b[0m Trial 272 finished with value: 4.456228 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.023628164418121614, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 4, 'reg_lambda': 2, 'min_child_weight': 3}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.690486\n",
      "Last estimator val2_error 3.997622\n",
      "Last estimator val3_error 4.680576\n",
      "val_avg_error 4.456228\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:15:50,587]\u001b[0m Trial 273 finished with value: 4.0676060000000005 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030639152611449803, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324093\n",
      "Last estimator val2_error 3.56145\n",
      "Last estimator val3_error 4.317275\n",
      "val_avg_error 4.0676060000000005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:16:10,393]\u001b[0m Trial 274 finished with value: 5.624516333333333 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 4, 'learning_rate': 0.018084843991802883, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 2, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.855856\n",
      "Last estimator val2_error 5.159368\n",
      "Last estimator val3_error 5.858325\n",
      "val_avg_error 5.624516333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:16:29,731]\u001b[0m Trial 275 finished with value: 4.066416 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03018976852199801, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.320108\n",
      "Last estimator val2_error 3.558306\n",
      "Last estimator val3_error 4.320834\n",
      "val_avg_error 4.066416\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:16:46,292]\u001b[0m Trial 276 finished with value: 4.087945666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.025403233758645463, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.390907\n",
      "Last estimator val2_error 3.496303\n",
      "Last estimator val3_error 4.376627\n",
      "val_avg_error 4.087945666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:17:01,184]\u001b[0m Trial 277 finished with value: 4.066721 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.031241182560790018, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325443\n",
      "Last estimator val2_error 3.56338\n",
      "Last estimator val3_error 4.31134\n",
      "val_avg_error 4.066721\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:17:17,100]\u001b[0m Trial 278 finished with value: 4.069355666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028729522335473132, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327277\n",
      "Last estimator val2_error 3.565491\n",
      "Last estimator val3_error 4.315299\n",
      "val_avg_error 4.069355666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:17:34,495]\u001b[0m Trial 279 finished with value: 4.072534 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 7, 'learning_rate': 0.03120765884913205, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322544\n",
      "Last estimator val2_error 3.54966\n",
      "Last estimator val3_error 4.345398\n",
      "val_avg_error 4.072534\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:17:54,444]\u001b[0m Trial 280 finished with value: 4.071238666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022022140241238053, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335166\n",
      "Last estimator val2_error 3.564359\n",
      "Last estimator val3_error 4.314191\n",
      "val_avg_error 4.071238666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:18:08,624]\u001b[0m Trial 281 finished with value: 4.068472333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026169607943853736, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 247 with value: 4.066033333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326361\n",
      "Last estimator val2_error 3.566761\n",
      "Last estimator val3_error 4.312295\n",
      "val_avg_error 4.068472333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:18:21,269]\u001b[0m Trial 282 finished with value: 4.065639333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.03154135575677926, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324774\n",
      "Last estimator val2_error 3.555566\n",
      "Last estimator val3_error 4.316578\n",
      "val_avg_error 4.065639333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:18:36,507]\u001b[0m Trial 283 finished with value: 4.069144666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.03163355475902977, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.3292\n",
      "Last estimator val2_error 3.55588\n",
      "Last estimator val3_error 4.322354\n",
      "val_avg_error 4.069144666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:18:58,809]\u001b[0m Trial 284 finished with value: 4.072129333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.02492975248732179, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332163\n",
      "Last estimator val2_error 3.554459\n",
      "Last estimator val3_error 4.329766\n",
      "val_avg_error 4.072129333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:19:21,770]\u001b[0m Trial 285 finished with value: 4.070752333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.021830865759221833, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33709\n",
      "Last estimator val2_error 3.557731\n",
      "Last estimator val3_error 4.317436\n",
      "val_avg_error 4.070752333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:19:36,487]\u001b[0m Trial 286 finished with value: 4.068134333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028168649200058977, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325406\n",
      "Last estimator val2_error 3.565722\n",
      "Last estimator val3_error 4.313275\n",
      "val_avg_error 4.068134333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:19:52,897]\u001b[0m Trial 287 finished with value: 4.4557649999999995 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 6, 'learning_rate': 0.03322850404965638, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.684506\n",
      "Last estimator val2_error 3.983693\n",
      "Last estimator val3_error 4.699096\n",
      "val_avg_error 4.4557649999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:20:15,399]\u001b[0m Trial 288 finished with value: 4.066105333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026084914002458694, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325618\n",
      "Last estimator val2_error 3.561856\n",
      "Last estimator val3_error 4.310842\n",
      "val_avg_error 4.066105333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:20:41,304]\u001b[0m Trial 289 finished with value: 4.069430333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0187056236268911, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332437\n",
      "Last estimator val2_error 3.562501\n",
      "Last estimator val3_error 4.313353\n",
      "val_avg_error 4.069430333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:21:00,673]\u001b[0m Trial 290 finished with value: 4.086610666666666 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.023518991115946852, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.390199\n",
      "Last estimator val2_error 3.496509\n",
      "Last estimator val3_error 4.373124\n",
      "val_avg_error 4.086610666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:21:29,508]\u001b[0m Trial 291 finished with value: 4.070375333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.013967592091073757, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334281\n",
      "Last estimator val2_error 3.555126\n",
      "Last estimator val3_error 4.321719\n",
      "val_avg_error 4.070375333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:21:48,512]\u001b[0m Trial 292 finished with value: 4.067635 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0332426078908364, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324553\n",
      "Last estimator val2_error 3.55984\n",
      "Last estimator val3_error 4.318512\n",
      "val_avg_error 4.067635\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:22:06,056]\u001b[0m Trial 293 finished with value: 4.068840000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026169408882941638, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324627\n",
      "Last estimator val2_error 3.562356\n",
      "Last estimator val3_error 4.319537\n",
      "val_avg_error 4.068840000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:22:23,454]\u001b[0m Trial 294 finished with value: 4.074186 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.031363888193384856, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.338003\n",
      "Last estimator val2_error 3.562538\n",
      "Last estimator val3_error 4.322017\n",
      "val_avg_error 4.074186\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:22:42,667]\u001b[0m Trial 295 finished with value: 4.066934 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.025889974742150806, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325661\n",
      "Last estimator val2_error 3.563467\n",
      "Last estimator val3_error 4.311674\n",
      "val_avg_error 4.066934\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:23:09,550]\u001b[0m Trial 296 finished with value: 4.068200999999999 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022050258497779043, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329662\n",
      "Last estimator val2_error 3.562421\n",
      "Last estimator val3_error 4.31252\n",
      "val_avg_error 4.068200999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:23:29,252]\u001b[0m Trial 297 finished with value: 4.458339333333334 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.016818684343856808, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.691803\n",
      "Last estimator val2_error 3.999662\n",
      "Last estimator val3_error 4.683553\n",
      "val_avg_error 4.458339333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:23:47,010]\u001b[0m Trial 298 finished with value: 4.068364666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.033033626003869526, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331253\n",
      "Last estimator val2_error 3.555201\n",
      "Last estimator val3_error 4.31864\n",
      "val_avg_error 4.068364666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:24:01,687]\u001b[0m Trial 299 finished with value: 4.068200666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03614312825614391, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326266\n",
      "Last estimator val2_error 3.563978\n",
      "Last estimator val3_error 4.314358\n",
      "val_avg_error 4.068200666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:24:14,759]\u001b[0m Trial 300 finished with value: 4.069994333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.029287899870368426, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326498\n",
      "Last estimator val2_error 3.56611\n",
      "Last estimator val3_error 4.317375\n",
      "val_avg_error 4.069994333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:24:29,484]\u001b[0m Trial 301 finished with value: 4.070021333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.024222175321843235, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327525\n",
      "Last estimator val2_error 3.567321\n",
      "Last estimator val3_error 4.315218\n",
      "val_avg_error 4.070021333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:24:39,795]\u001b[0m Trial 302 finished with value: 4.071339333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.036105194496911706, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330544\n",
      "Last estimator val2_error 3.566308\n",
      "Last estimator val3_error 4.317166\n",
      "val_avg_error 4.071339333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:25:05,628]\u001b[0m Trial 303 finished with value: 4.098061666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02094917416482088, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.1, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.37578\n",
      "Last estimator val2_error 3.57705\n",
      "Last estimator val3_error 4.341355\n",
      "val_avg_error 4.098061666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:25:26,122]\u001b[0m Trial 304 finished with value: 4.094301000000001 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 8, 'learning_rate': 0.027739132168372052, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.405087\n",
      "Last estimator val2_error 3.478668\n",
      "Last estimator val3_error 4.399148\n",
      "val_avg_error 4.094301000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:25:42,665]\u001b[0m Trial 305 finished with value: 4.067229666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.029756986439767243, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324571\n",
      "Last estimator val2_error 3.562325\n",
      "Last estimator val3_error 4.314793\n",
      "val_avg_error 4.067229666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:25:58,733]\u001b[0m Trial 306 finished with value: 4.067069333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030372416589633286, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323513\n",
      "Last estimator val2_error 3.56261\n",
      "Last estimator val3_error 4.315085\n",
      "val_avg_error 4.067069333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:26:17,716]\u001b[0m Trial 307 finished with value: 4.067382666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.029938490453215748, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322472\n",
      "Last estimator val2_error 3.559875\n",
      "Last estimator val3_error 4.319801\n",
      "val_avg_error 4.067382666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:26:35,584]\u001b[0m Trial 308 finished with value: 4.067816 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030447906938347667, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.321074\n",
      "Last estimator val2_error 3.559765\n",
      "Last estimator val3_error 4.322609\n",
      "val_avg_error 4.067816\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:26:59,158]\u001b[0m Trial 309 finished with value: 4.068025666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.025260503738615957, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325799\n",
      "Last estimator val2_error 3.561814\n",
      "Last estimator val3_error 4.316464\n",
      "val_avg_error 4.068025666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:27:14,222]\u001b[0m Trial 310 finished with value: 4.068339333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03219102994754458, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327554\n",
      "Last estimator val2_error 3.562682\n",
      "Last estimator val3_error 4.314782\n",
      "val_avg_error 4.068339333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:27:26,723]\u001b[0m Trial 311 finished with value: 4.0666813333333325 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.036635539458860014, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325575\n",
      "Last estimator val2_error 3.56404\n",
      "Last estimator val3_error 4.310429\n",
      "val_avg_error 4.0666813333333325\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:27:41,176]\u001b[0m Trial 312 finished with value: 4.067433666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026911503011259535, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324462\n",
      "Last estimator val2_error 3.564748\n",
      "Last estimator val3_error 4.313091\n",
      "val_avg_error 4.067433666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:27:57,759]\u001b[0m Trial 313 finished with value: 4.09232 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022817382039772002, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.2, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.370415\n",
      "Last estimator val2_error 3.567605\n",
      "Last estimator val3_error 4.33894\n",
      "val_avg_error 4.09232\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:28:11,736]\u001b[0m Trial 314 finished with value: 4.456171666666666 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.03365671499562343, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.688125\n",
      "Last estimator val2_error 3.999036\n",
      "Last estimator val3_error 4.681354\n",
      "val_avg_error 4.456171666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:28:35,267]\u001b[0m Trial 315 finished with value: 4.069722666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.019765714072335204, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329228\n",
      "Last estimator val2_error 3.563396\n",
      "Last estimator val3_error 4.316544\n",
      "val_avg_error 4.069722666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:28:54,519]\u001b[0m Trial 316 finished with value: 4.072026 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028979713565526727, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334672\n",
      "Last estimator val2_error 3.564042\n",
      "Last estimator val3_error 4.317364\n",
      "val_avg_error 4.072026\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:29:07,244]\u001b[0m Trial 317 finished with value: 4.069576666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03584776846088655, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326723\n",
      "Last estimator val2_error 3.565225\n",
      "Last estimator val3_error 4.316782\n",
      "val_avg_error 4.069576666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:29:28,958]\u001b[0m Trial 318 finished with value: 4.068978333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02521486600891578, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328131\n",
      "Last estimator val2_error 3.560769\n",
      "Last estimator val3_error 4.318035\n",
      "val_avg_error 4.068978333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:29:43,693]\u001b[0m Trial 319 finished with value: 4.088065333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.030471401559119975, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.395694\n",
      "Last estimator val2_error 3.494773\n",
      "Last estimator val3_error 4.373729\n",
      "val_avg_error 4.088065333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:30:03,651]\u001b[0m Trial 320 finished with value: 4.067908 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023079512371673248, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326622\n",
      "Last estimator val2_error 3.561576\n",
      "Last estimator val3_error 4.315526\n",
      "val_avg_error 4.067908\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:30:21,501]\u001b[0m Trial 321 finished with value: 4.069356 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028727793280556933, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327278\n",
      "Last estimator val2_error 3.565492\n",
      "Last estimator val3_error 4.315298\n",
      "val_avg_error 4.069356\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:32:15,326]\u001b[0m Trial 322 finished with value: 4.6806676666666664 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.00024269584576421958, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.281237\n",
      "Last estimator val2_error 3.982065\n",
      "Last estimator val3_error 4.778701\n",
      "val_avg_error 4.6806676666666664\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:32:26,939]\u001b[0m Trial 323 finished with value: 4.067927 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.035723331539896645, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 2, 'min_child_weight': 2}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325874\n",
      "Last estimator val2_error 3.5645\n",
      "Last estimator val3_error 4.313407\n",
      "val_avg_error 4.067927\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:33:05,569]\u001b[0m Trial 324 finished with value: 4.066147 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026472985831947956, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324969\n",
      "Last estimator val2_error 3.560233\n",
      "Last estimator val3_error 4.313239\n",
      "val_avg_error 4.066147\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:33:46,478]\u001b[0m Trial 325 finished with value: 4.06835 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0191387129019324, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330407\n",
      "Last estimator val2_error 3.563968\n",
      "Last estimator val3_error 4.310675\n",
      "val_avg_error 4.06835\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:34:04,802]\u001b[0m Trial 326 finished with value: 13.988521666666665 and parameters: {'tweedie_variance_power': 1.1, 'max_depth': 4, 'learning_rate': 0.02548694626644729, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 6}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 15.619921\n",
      "Last estimator val2_error 10.780272\n",
      "Last estimator val3_error 15.565372\n",
      "val_avg_error 13.988521666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:34:33,859]\u001b[0m Trial 327 finished with value: 9.661821333333334 and parameters: {'tweedie_variance_power': 1.9, 'max_depth': 4, 'learning_rate': 0.021437403115256506, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 9.947932\n",
      "Last estimator val2_error 9.078998\n",
      "Last estimator val3_error 9.958534\n",
      "val_avg_error 9.661821333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:35:15,424]\u001b[0m Trial 328 finished with value: 4.066895 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03308266667275996, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326159\n",
      "Last estimator val2_error 3.559546\n",
      "Last estimator val3_error 4.31498\n",
      "val_avg_error 4.066895\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:35:36,758]\u001b[0m Trial 329 finished with value: 4.453372666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.0373693123220022, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.682694\n",
      "Last estimator val2_error 3.993286\n",
      "Last estimator val3_error 4.684138\n",
      "val_avg_error 4.453372666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:35:52,551]\u001b[0m Trial 330 finished with value: 4.068653333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03215198564781778, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326034\n",
      "Last estimator val2_error 3.567617\n",
      "Last estimator val3_error 4.312309\n",
      "val_avg_error 4.068653333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:36:07,098]\u001b[0m Trial 331 finished with value: 4.070576333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.038511787662737156, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.332206\n",
      "Last estimator val2_error 3.564007\n",
      "Last estimator val3_error 4.315516\n",
      "val_avg_error 4.070576333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:36:25,617]\u001b[0m Trial 332 finished with value: 4.069154666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03389215397541598, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33001\n",
      "Last estimator val2_error 3.563789\n",
      "Last estimator val3_error 4.313665\n",
      "val_avg_error 4.069154666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:36:51,012]\u001b[0m Trial 333 finished with value: 4.066180666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027157420916684556, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325081\n",
      "Last estimator val2_error 3.561985\n",
      "Last estimator val3_error 4.311476\n",
      "val_avg_error 4.066180666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:37:17,624]\u001b[0m Trial 334 finished with value: 4.065873333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02729585311244984, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323828\n",
      "Last estimator val2_error 3.561269\n",
      "Last estimator val3_error 4.312523\n",
      "val_avg_error 4.065873333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:37:41,087]\u001b[0m Trial 335 finished with value: 4.068615666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026848257358128208, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326912\n",
      "Last estimator val2_error 3.560676\n",
      "Last estimator val3_error 4.318259\n",
      "val_avg_error 4.068615666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:37:59,122]\u001b[0m Trial 336 finished with value: 4.065794333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030049516656498874, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322186\n",
      "Last estimator val2_error 3.561279\n",
      "Last estimator val3_error 4.313918\n",
      "val_avg_error 4.065794333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:38:12,251]\u001b[0m Trial 337 finished with value: 4.089444 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.02457763940005055, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 282 with value: 4.065639333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.392749\n",
      "Last estimator val2_error 3.500126\n",
      "Last estimator val3_error 4.375457\n",
      "val_avg_error 4.089444\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:38:32,841]\u001b[0m Trial 338 finished with value: 4.065369333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03279681325679455, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32198\n",
      "Last estimator val2_error 3.559425\n",
      "Last estimator val3_error 4.314703\n",
      "val_avg_error 4.065369333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:38:55,596]\u001b[0m Trial 339 finished with value: 4.066506666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03235455186178194, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32129\n",
      "Last estimator val2_error 3.559575\n",
      "Last estimator val3_error 4.318655\n",
      "val_avg_error 4.066506666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:39:12,701]\u001b[0m Trial 340 finished with value: 4.067915 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03540686736760506, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324815\n",
      "Last estimator val2_error 3.560378\n",
      "Last estimator val3_error 4.318552\n",
      "val_avg_error 4.067915\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:40:43,962]\u001b[0m Trial 341 finished with value: 4.315801 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0006681246535722837, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.84684\n",
      "Last estimator val2_error 3.703495\n",
      "Last estimator val3_error 4.397068\n",
      "val_avg_error 4.315801\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:40:56,201]\u001b[0m Trial 342 finished with value: 4.073887 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03968166860143123, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329951\n",
      "Last estimator val2_error 3.565229\n",
      "Last estimator val3_error 4.326481\n",
      "val_avg_error 4.073887\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:42:29,770]\u001b[0m Trial 343 finished with value: 4.949645333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.00010557060530288565, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.491163\n",
      "Last estimator val2_error 4.187613\n",
      "Last estimator val3_error 5.17016\n",
      "val_avg_error 4.949645333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:42:47,302]\u001b[0m Trial 344 finished with value: 4.454962666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.0316314361568217, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.685829\n",
      "Last estimator val2_error 3.99442\n",
      "Last estimator val3_error 4.684639\n",
      "val_avg_error 4.454962666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:43:01,221]\u001b[0m Trial 345 finished with value: 4.067209666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0328470849342693, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322495\n",
      "Last estimator val2_error 3.565924\n",
      "Last estimator val3_error 4.31321\n",
      "val_avg_error 4.067209666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:43:18,002]\u001b[0m Trial 346 finished with value: 5.3760650000000005 and parameters: {'tweedie_variance_power': 1.3, 'max_depth': 4, 'learning_rate': 0.017290390430892078, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 338 with value: 4.065369333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.896209\n",
      "Last estimator val2_error 4.368947\n",
      "Last estimator val3_error 5.863039\n",
      "val_avg_error 5.3760650000000005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:43:43,603]\u001b[0m Trial 347 finished with value: 4.065304 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026182496885388377, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324766\n",
      "Last estimator val2_error 3.55855\n",
      "Last estimator val3_error 4.312596\n",
      "val_avg_error 4.065304\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:44:08,305]\u001b[0m Trial 348 finished with value: 4.0708036666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.023159320913483758, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.33069\n",
      "Last estimator val2_error 3.555707\n",
      "Last estimator val3_error 4.326014\n",
      "val_avg_error 4.0708036666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:44:23,562]\u001b[0m Trial 349 finished with value: 4.455582 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.027370029845016908, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.686513\n",
      "Last estimator val2_error 4.000525\n",
      "Last estimator val3_error 4.679708\n",
      "val_avg_error 4.455582\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:44:43,750]\u001b[0m Trial 350 finished with value: 4.068402333333332 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.020598703990969885, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327291\n",
      "Last estimator val2_error 3.567446\n",
      "Last estimator val3_error 4.31047\n",
      "val_avg_error 4.068402333333332\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:44:56,871]\u001b[0m Trial 351 finished with value: 4.068685666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.024696212325472422, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32615\n",
      "Last estimator val2_error 3.566586\n",
      "Last estimator val3_error 4.313321\n",
      "val_avg_error 4.068685666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:45:14,163]\u001b[0m Trial 352 finished with value: 4.067780666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030770859287539143, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325029\n",
      "Last estimator val2_error 3.564531\n",
      "Last estimator val3_error 4.313782\n",
      "val_avg_error 4.067780666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:45:26,541]\u001b[0m Trial 353 finished with value: 4.091335999999999 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.026975750560708344, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.400435\n",
      "Last estimator val2_error 3.497387\n",
      "Last estimator val3_error 4.376186\n",
      "val_avg_error 4.091335999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:45:41,346]\u001b[0m Trial 354 finished with value: 4.0671539999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03565365457653906, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323043\n",
      "Last estimator val2_error 3.563596\n",
      "Last estimator val3_error 4.314823\n",
      "val_avg_error 4.0671539999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:45:53,961]\u001b[0m Trial 355 finished with value: 4.074663666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023367532468136994, 'subsample': 0.30000000000000004, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335003\n",
      "Last estimator val2_error 3.566988\n",
      "Last estimator val3_error 4.322\n",
      "val_avg_error 4.074663666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:46:11,275]\u001b[0m Trial 356 finished with value: 4.0700639999999995 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.019381015514090195, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329927\n",
      "Last estimator val2_error 3.568791\n",
      "Last estimator val3_error 4.311474\n",
      "val_avg_error 4.0700639999999995\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:46:27,347]\u001b[0m Trial 357 finished with value: 4.068776333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.030360742549000355, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326966\n",
      "Last estimator val2_error 3.556306\n",
      "Last estimator val3_error 4.323057\n",
      "val_avg_error 4.068776333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:46:45,124]\u001b[0m Trial 358 finished with value: 5.635857333333334 and parameters: {'tweedie_variance_power': 1.8000000000000003, 'max_depth': 7, 'learning_rate': 0.028179901016141994, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.869693\n",
      "Last estimator val2_error 5.153481\n",
      "Last estimator val3_error 5.884398\n",
      "val_avg_error 5.635857333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 15:47:01,418]\u001b[0m Trial 359 finished with value: 4.068601666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03439502720433322, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328779\n",
      "Last estimator val2_error 3.565524\n",
      "Last estimator val3_error 4.311502\n",
      "val_avg_error 4.068601666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:01:59,526]\u001b[0m Trial 360 finished with value: 4.0689296666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.024756248679118756, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326303\n",
      "Last estimator val2_error 3.564643\n",
      "Last estimator val3_error 4.315843\n",
      "val_avg_error 4.0689296666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:02:17,446]\u001b[0m Trial 361 finished with value: 4.070598 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03823256412170204, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328767\n",
      "Last estimator val2_error 3.565207\n",
      "Last estimator val3_error 4.31782\n",
      "val_avg_error 4.070598\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:02:36,246]\u001b[0m Trial 362 finished with value: 4.066771 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02710281461901233, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.3254\n",
      "Last estimator val2_error 3.564198\n",
      "Last estimator val3_error 4.310715\n",
      "val_avg_error 4.066771\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:02:50,470]\u001b[0m Trial 363 finished with value: 4.067567333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.033035355530639646, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325625\n",
      "Last estimator val2_error 3.562361\n",
      "Last estimator val3_error 4.314716\n",
      "val_avg_error 4.067567333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:03:02,282]\u001b[0m Trial 364 finished with value: 7.440157333333334 and parameters: {'tweedie_variance_power': 1.2000000000000002, 'max_depth': 4, 'learning_rate': 0.02869307309787401, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 8.226612\n",
      "Last estimator val2_error 5.892796\n",
      "Last estimator val3_error 8.201064\n",
      "val_avg_error 7.440157333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:03:26,283]\u001b[0m Trial 365 finished with value: 4.068698666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02241282717992809, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330606\n",
      "Last estimator val2_error 3.562407\n",
      "Last estimator val3_error 4.313083\n",
      "val_avg_error 4.068698666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:03:43,586]\u001b[0m Trial 366 finished with value: 4.0693746666666675 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03202716829095825, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323178\n",
      "Last estimator val2_error 3.562035\n",
      "Last estimator val3_error 4.322911\n",
      "val_avg_error 4.0693746666666675\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:03:55,050]\u001b[0m Trial 367 finished with value: 4.085524 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 5, 'learning_rate': 0.03810831610860241, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.391899\n",
      "Last estimator val2_error 3.486044\n",
      "Last estimator val3_error 4.378629\n",
      "val_avg_error 4.085524\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:04:14,395]\u001b[0m Trial 368 finished with value: 4.069774 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.01584891647527412, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328979\n",
      "Last estimator val2_error 3.566852\n",
      "Last estimator val3_error 4.313491\n",
      "val_avg_error 4.069774\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:04:37,018]\u001b[0m Trial 369 finished with value: 4.068225666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.025970978237332954, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331123\n",
      "Last estimator val2_error 3.561507\n",
      "Last estimator val3_error 4.312047\n",
      "val_avg_error 4.068225666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:05:04,539]\u001b[0m Trial 370 finished with value: 4.069421 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02041484490227975, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328424\n",
      "Last estimator val2_error 3.562603\n",
      "Last estimator val3_error 4.317236\n",
      "val_avg_error 4.069421\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:05:21,326]\u001b[0m Trial 371 finished with value: 4.068454666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.029289690312536778, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326753\n",
      "Last estimator val2_error 3.564869\n",
      "Last estimator val3_error 4.313742\n",
      "val_avg_error 4.068454666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:05:38,287]\u001b[0m Trial 372 finished with value: 4.068015 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03454724935863995, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323283\n",
      "Last estimator val2_error 3.559327\n",
      "Last estimator val3_error 4.321435\n",
      "val_avg_error 4.068015\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:05:56,315]\u001b[0m Trial 373 finished with value: 4.457323333333334 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.022360496654813114, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.691211\n",
      "Last estimator val2_error 4.00078\n",
      "Last estimator val3_error 4.679979\n",
      "val_avg_error 4.457323333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:06:11,471]\u001b[0m Trial 374 finished with value: 4.069418 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027633478753329763, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 1, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330612\n",
      "Last estimator val2_error 3.563156\n",
      "Last estimator val3_error 4.314486\n",
      "val_avg_error 4.069418\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:06:22,486]\u001b[0m Trial 375 finished with value: 4.070246666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04095704265548787, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32435\n",
      "Last estimator val2_error 3.564214\n",
      "Last estimator val3_error 4.322176\n",
      "val_avg_error 4.070246666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:06:37,176]\u001b[0m Trial 376 finished with value: 4.067884666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03247023584459491, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327995\n",
      "Last estimator val2_error 3.563971\n",
      "Last estimator val3_error 4.311688\n",
      "val_avg_error 4.067884666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:06:56,398]\u001b[0m Trial 377 finished with value: 4.086629666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.02452942868439968, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.387855\n",
      "Last estimator val2_error 3.497175\n",
      "Last estimator val3_error 4.374859\n",
      "val_avg_error 4.086629666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:07:15,106]\u001b[0m Trial 378 finished with value: 4.06768 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02974065122292765, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324971\n",
      "Last estimator val2_error 3.561036\n",
      "Last estimator val3_error 4.317033\n",
      "val_avg_error 4.06768\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:07:24,663]\u001b[0m Trial 379 finished with value: 4.092844333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03788915411831915, 'subsample': 0.6, 'colsample_bytree': 0.30000000000000004, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.376707\n",
      "Last estimator val2_error 3.574342\n",
      "Last estimator val3_error 4.327484\n",
      "val_avg_error 4.092844333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:07:47,913]\u001b[0m Trial 380 finished with value: 4.068103 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.025376358830303664, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326604\n",
      "Last estimator val2_error 3.561139\n",
      "Last estimator val3_error 4.316566\n",
      "val_avg_error 4.068103\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:08:07,100]\u001b[0m Trial 381 finished with value: 4.0695456666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.018073338674567195, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329693\n",
      "Last estimator val2_error 3.568819\n",
      "Last estimator val3_error 4.310125\n",
      "val_avg_error 4.0695456666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:08:21,880]\u001b[0m Trial 382 finished with value: 4.0685883333333335 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.032976478701687344, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 2, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324904\n",
      "Last estimator val2_error 3.56525\n",
      "Last estimator val3_error 4.315611\n",
      "val_avg_error 4.0685883333333335\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:08:37,282]\u001b[0m Trial 383 finished with value: 4.067406666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028380778453255786, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325249\n",
      "Last estimator val2_error 3.564961\n",
      "Last estimator val3_error 4.31201\n",
      "val_avg_error 4.067406666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:09:05,896]\u001b[0m Trial 384 finished with value: 4.068065666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022240290864451694, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328222\n",
      "Last estimator val2_error 3.562235\n",
      "Last estimator val3_error 4.31374\n",
      "val_avg_error 4.068065666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:09:25,257]\u001b[0m Trial 385 finished with value: 4.077914333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 8, 'learning_rate': 0.039510800353891935, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.337729\n",
      "Last estimator val2_error 3.552756\n",
      "Last estimator val3_error 4.343258\n",
      "val_avg_error 4.077914333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:09:41,638]\u001b[0m Trial 386 finished with value: 4.0683576666666665 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03223925335475347, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329081\n",
      "Last estimator val2_error 3.563285\n",
      "Last estimator val3_error 4.312707\n",
      "val_avg_error 4.0683576666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:09:55,111]\u001b[0m Trial 387 finished with value: 4.073859666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02702610984663239, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.6, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333791\n",
      "Last estimator val2_error 3.564231\n",
      "Last estimator val3_error 4.323557\n",
      "val_avg_error 4.073859666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:10:13,861]\u001b[0m Trial 388 finished with value: 4.070524333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.036540142983050125, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330676\n",
      "Last estimator val2_error 3.561202\n",
      "Last estimator val3_error 4.319695\n",
      "val_avg_error 4.070524333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:10:38,676]\u001b[0m Trial 389 finished with value: 4.072548666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.020184546737926506, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.331954\n",
      "Last estimator val2_error 3.555197\n",
      "Last estimator val3_error 4.330495\n",
      "val_avg_error 4.072548666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:11:05,690]\u001b[0m Trial 390 finished with value: 4.066690333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02415773192890391, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326129\n",
      "Last estimator val2_error 3.560981\n",
      "Last estimator val3_error 4.312961\n",
      "val_avg_error 4.066690333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:11:23,700]\u001b[0m Trial 391 finished with value: 4.459581666666666 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.023802549302447643, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.7000000000000001, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.695726\n",
      "Last estimator val2_error 3.997937\n",
      "Last estimator val3_error 4.685082\n",
      "val_avg_error 4.459581666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:11:43,639]\u001b[0m Trial 392 finished with value: 4.0868150000000005 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.025265472077890427, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.393255\n",
      "Last estimator val2_error 3.493105\n",
      "Last estimator val3_error 4.374085\n",
      "val_avg_error 4.0868150000000005\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:18:41,692]\u001b[0m Trial 393 finished with value: 4.460134 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.021169698918859548, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.696705\n",
      "Last estimator val2_error 3.9974\n",
      "Last estimator val3_error 4.686297\n",
      "val_avg_error 4.460134\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:18:55,766]\u001b[0m Trial 394 finished with value: 4.067767333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028937344151098568, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327051\n",
      "Last estimator val2_error 3.564713\n",
      "Last estimator val3_error 4.311538\n",
      "val_avg_error 4.067767333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:19:17,614]\u001b[0m Trial 395 finished with value: 4.070903333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.01887317897780708, 'subsample': 0.5, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.334751\n",
      "Last estimator val2_error 3.562572\n",
      "Last estimator val3_error 4.315387\n",
      "val_avg_error 4.070903333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:19:32,379]\u001b[0m Trial 396 finished with value: 4.068199666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.028138419971647167, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325334\n",
      "Last estimator val2_error 3.565316\n",
      "Last estimator val3_error 4.313949\n",
      "val_avg_error 4.068199666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:19:54,055]\u001b[0m Trial 397 finished with value: 4.068331333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023939397265747633, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326056\n",
      "Last estimator val2_error 3.561424\n",
      "Last estimator val3_error 4.317514\n",
      "val_avg_error 4.068331333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:20:05,332]\u001b[0m Trial 398 finished with value: 4.069571 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04303484531425294, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32553\n",
      "Last estimator val2_error 3.562299\n",
      "Last estimator val3_error 4.320884\n",
      "val_avg_error 4.069571\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:20:45,438]\u001b[0m Trial 399 finished with value: 4.068460333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.008864709557911861, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 3, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328519\n",
      "Last estimator val2_error 3.563476\n",
      "Last estimator val3_error 4.313386\n",
      "val_avg_error 4.068460333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:21:02,045]\u001b[0m Trial 400 finished with value: 4.069646666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.03076038853221638, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329333\n",
      "Last estimator val2_error 3.555215\n",
      "Last estimator val3_error 4.324392\n",
      "val_avg_error 4.069646666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:21:16,957]\u001b[0m Trial 401 finished with value: 4.067849333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.026025620126056557, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325951\n",
      "Last estimator val2_error 3.566354\n",
      "Last estimator val3_error 4.311243\n",
      "val_avg_error 4.067849333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:21:33,055]\u001b[0m Trial 402 finished with value: 4.069439333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03463573289492096, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.333679\n",
      "Last estimator val2_error 3.560548\n",
      "Last estimator val3_error 4.314091\n",
      "val_avg_error 4.069439333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:21:50,376]\u001b[0m Trial 403 finished with value: 4.069905666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023685104730928393, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327777\n",
      "Last estimator val2_error 3.564745\n",
      "Last estimator val3_error 4.317195\n",
      "val_avg_error 4.069905666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:22:19,778]\u001b[0m Trial 404 finished with value: 4.068645 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.011856350437822611, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 2, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330553\n",
      "Last estimator val2_error 3.561155\n",
      "Last estimator val3_error 4.314227\n",
      "val_avg_error 4.068645\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:22:39,739]\u001b[0m Trial 405 finished with value: 4.470504333333333 and parameters: {'tweedie_variance_power': 1.4000000000000001, 'max_depth': 4, 'learning_rate': 0.02871659479938389, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 0, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.847809\n",
      "Last estimator val2_error 3.721446\n",
      "Last estimator val3_error 4.842258\n",
      "val_avg_error 4.470504333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:22:58,839]\u001b[0m Trial 406 finished with value: 4.070861000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.02091806379430389, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326819\n",
      "Last estimator val2_error 3.578212\n",
      "Last estimator val3_error 4.307552\n",
      "val_avg_error 4.070861000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:23:10,839]\u001b[0m Trial 407 finished with value: 4.069050666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03615032810003709, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 3, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330506\n",
      "Last estimator val2_error 3.564104\n",
      "Last estimator val3_error 4.312542\n",
      "val_avg_error 4.069050666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:23:34,378]\u001b[0m Trial 408 finished with value: 4.075488 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.01631571825828317, 'subsample': 0.4, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.344197\n",
      "Last estimator val2_error 3.555631\n",
      "Last estimator val3_error 4.326636\n",
      "val_avg_error 4.075488\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:24:57,617]\u001b[0m Trial 409 finished with value: 4.4938226666666665 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.0021293682619969254, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 0, 'min_child_weight': 4}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.78827\n",
      "Last estimator val2_error 4.012751\n",
      "Last estimator val3_error 4.680447\n",
      "val_avg_error 4.4938226666666665\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:26:04,023]\u001b[0m Trial 410 finished with value: 4.090124666666667 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.004085281163714034, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.399168\n",
      "Last estimator val2_error 3.49763\n",
      "Last estimator val3_error 4.373576\n",
      "val_avg_error 4.090124666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:26:19,964]\u001b[0m Trial 411 finished with value: 4.067603666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030644990034950373, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324093\n",
      "Last estimator val2_error 3.561449\n",
      "Last estimator val3_error 4.317269\n",
      "val_avg_error 4.067603666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:26:34,004]\u001b[0m Trial 412 finished with value: 4.070681 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.041176526750700104, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 347 with value: 4.065304.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328215\n",
      "Last estimator val2_error 3.555245\n",
      "Last estimator val3_error 4.328583\n",
      "val_avg_error 4.070681\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:26:58,212]\u001b[0m Trial 413 finished with value: 4.065239666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02632114605475799, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323798\n",
      "Last estimator val2_error 3.56154\n",
      "Last estimator val3_error 4.310381\n",
      "val_avg_error 4.065239666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:27:22,043]\u001b[0m Trial 414 finished with value: 4.067373666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02573442924394885, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325065\n",
      "Last estimator val2_error 3.560422\n",
      "Last estimator val3_error 4.316634\n",
      "val_avg_error 4.067373666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:27:39,396]\u001b[0m Trial 415 finished with value: 4.069116333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.032495677619913205, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 5}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326195\n",
      "Last estimator val2_error 3.561984\n",
      "Last estimator val3_error 4.31917\n",
      "val_avg_error 4.069116333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:27:54,818]\u001b[0m Trial 416 finished with value: 4.068847333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.022428667064084997, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.329021\n",
      "Last estimator val2_error 3.565025\n",
      "Last estimator val3_error 4.312496\n",
      "val_avg_error 4.068847333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:28:12,311]\u001b[0m Trial 417 finished with value: 4.067401 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02785451847262078, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324735\n",
      "Last estimator val2_error 3.561674\n",
      "Last estimator val3_error 4.315794\n",
      "val_avg_error 4.067401\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:28:26,404]\u001b[0m Trial 418 finished with value: 4.089253333333333 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.0372684663817867, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.397252\n",
      "Last estimator val2_error 3.493157\n",
      "Last estimator val3_error 4.377351\n",
      "val_avg_error 4.089253333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:28:38,802]\u001b[0m Trial 419 finished with value: 4.068288666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.044756094552309875, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326249\n",
      "Last estimator val2_error 3.561224\n",
      "Last estimator val3_error 4.317393\n",
      "val_avg_error 4.068288666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:28:53,168]\u001b[0m Trial 420 finished with value: 4.067389666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03085308738488519, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324852\n",
      "Last estimator val2_error 3.565949\n",
      "Last estimator val3_error 4.311368\n",
      "val_avg_error 4.067389666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:29:18,224]\u001b[0m Trial 421 finished with value: 4.067055 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.025496147089500813, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325234\n",
      "Last estimator val2_error 3.559954\n",
      "Last estimator val3_error 4.315977\n",
      "val_avg_error 4.067055\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:32:41,509]\u001b[0m Trial 422 finished with value: 4.067597666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.035838554976556795, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.327468\n",
      "Last estimator val2_error 3.561227\n",
      "Last estimator val3_error 4.314098\n",
      "val_avg_error 4.067597666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:33:27,408]\u001b[0m Trial 423 finished with value: 4.071429333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.01880359700425137, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32487\n",
      "Last estimator val2_error 3.576418\n",
      "Last estimator val3_error 4.313\n",
      "val_avg_error 4.071429333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:35:17,907]\u001b[0m Trial 424 finished with value: 4.226528000000001 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0009422152236142553, 'subsample': 0.6, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.689217\n",
      "Last estimator val2_error 3.642963\n",
      "Last estimator val3_error 4.347404\n",
      "val_avg_error 4.226528000000001\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:35:43,320]\u001b[0m Trial 425 finished with value: 4.068693666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.02259619743862823, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.330364\n",
      "Last estimator val2_error 3.560891\n",
      "Last estimator val3_error 4.314826\n",
      "val_avg_error 4.068693666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:36:07,419]\u001b[0m Trial 426 finished with value: 4.454910666666667 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.02805439739688625, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.689504\n",
      "Last estimator val2_error 3.994345\n",
      "Last estimator val3_error 4.680883\n",
      "val_avg_error 4.454910666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:36:24,003]\u001b[0m Trial 427 finished with value: 4.068852333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03262646975694982, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 4, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326349\n",
      "Last estimator val2_error 3.563626\n",
      "Last estimator val3_error 4.316582\n",
      "val_avg_error 4.068852333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:36:36,222]\u001b[0m Trial 428 finished with value: 4.067875666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.039352156248716325, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.322618\n",
      "Last estimator val2_error 3.564546\n",
      "Last estimator val3_error 4.316463\n",
      "val_avg_error 4.067875666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:36:52,893]\u001b[0m Trial 429 finished with value: 4.072396 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 5, 'learning_rate': 0.025555717235570565, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 3, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 2}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.335238\n",
      "Last estimator val2_error 3.555266\n",
      "Last estimator val3_error 4.326684\n",
      "val_avg_error 4.072396\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:37:16,358]\u001b[0m Trial 430 finished with value: 4.066689 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030115797974105685, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.324105\n",
      "Last estimator val2_error 3.560271\n",
      "Last estimator val3_error 4.315691\n",
      "val_avg_error 4.066689\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:37:41,707]\u001b[0m Trial 431 finished with value: 4.081170333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 10, 'learning_rate': 0.028904648613090465, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.350903\n",
      "Last estimator val2_error 3.548835\n",
      "Last estimator val3_error 4.343773\n",
      "val_avg_error 4.081170333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:38:10,740]\u001b[0m Trial 432 finished with value: 4.073924333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 6, 'learning_rate': 0.021605413008874436, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.336256\n",
      "Last estimator val2_error 3.551964\n",
      "Last estimator val3_error 4.333553\n",
      "val_avg_error 4.073924333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:38:28,866]\u001b[0m Trial 433 finished with value: 4.069769 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.024620880585902245, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.328865\n",
      "Last estimator val2_error 3.565694\n",
      "Last estimator val3_error 4.314748\n",
      "val_avg_error 4.069769\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:38:45,704]\u001b[0m Trial 434 finished with value: 4.089268666666666 and parameters: {'tweedie_variance_power': 1.5, 'max_depth': 4, 'learning_rate': 0.03098623447443302, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.396598\n",
      "Last estimator val2_error 3.492962\n",
      "Last estimator val3_error 4.378246\n",
      "val_avg_error 4.089268666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:39:06,732]\u001b[0m Trial 435 finished with value: 4.088464 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.027289966136569324, 'subsample': 0.7000000000000001, 'colsample_bytree': 0.2, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.37324\n",
      "Last estimator val2_error 3.562555\n",
      "Last estimator val3_error 4.329597\n",
      "val_avg_error 4.088464\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:40:57,660]\u001b[0m Trial 436 finished with value: 4.509804666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.0003802501411358505, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 5.110323\n",
      "Last estimator val2_error 3.84919\n",
      "Last estimator val3_error 4.569901\n",
      "val_avg_error 4.509804666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:41:19,112]\u001b[0m Trial 437 finished with value: 4.065934333333334 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.034553300941808605, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.323282\n",
      "Last estimator val2_error 3.558569\n",
      "Last estimator val3_error 4.315952\n",
      "val_avg_error 4.065934333333334\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:41:29,196]\u001b[0m Trial 438 finished with value: 4.088062333333333 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.03216658325386683, 'subsample': 0.2, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 1, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.365558\n",
      "Last estimator val2_error 3.570784\n",
      "Last estimator val3_error 4.327845\n",
      "val_avg_error 4.088062333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:41:48,249]\u001b[0m Trial 439 finished with value: 4.473897333333333 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 9, 'learning_rate': 0.035973773060857174, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.694976\n",
      "Last estimator val2_error 3.992669\n",
      "Last estimator val3_error 4.734047\n",
      "val_avg_error 4.473897333333333\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:42:06,570]\u001b[0m Trial 440 finished with value: 4.068026666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.034035040411609006, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 4}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.32746\n",
      "Last estimator val2_error 3.562587\n",
      "Last estimator val3_error 4.314033\n",
      "val_avg_error 4.068026666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:42:24,619]\u001b[0m Trial 441 finished with value: 4.068908666666666 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.023384965695852085, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 1, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326197\n",
      "Last estimator val2_error 3.564126\n",
      "Last estimator val3_error 4.316403\n",
      "val_avg_error 4.068908666666666\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:42:47,991]\u001b[0m Trial 442 finished with value: 4.069972666666667 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 3, 'learning_rate': 0.019882912271687255, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325082\n",
      "Last estimator val2_error 3.573039\n",
      "Last estimator val3_error 4.311797\n",
      "val_avg_error 4.069972666666667\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:43:05,118]\u001b[0m Trial 443 finished with value: 4.069332 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.04204792611733706, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.325729\n",
      "Last estimator val2_error 3.561903\n",
      "Last estimator val3_error 4.320364\n",
      "val_avg_error 4.069332\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:43:30,557]\u001b[0m Trial 444 finished with value: 4.067267999999999 and parameters: {'tweedie_variance_power': 1.6, 'max_depth': 4, 'learning_rate': 0.030003451443303866, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 5, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.326033\n",
      "Last estimator val2_error 3.559142\n",
      "Last estimator val3_error 4.316629\n",
      "val_avg_error 4.067267999999999\n",
      "##################################################################################################\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n",
      "\n",
      " False \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-13 16:43:52,680]\u001b[0m Trial 445 finished with value: 4.456298 and parameters: {'tweedie_variance_power': 1.7000000000000002, 'max_depth': 4, 'learning_rate': 0.027035325628275448, 'subsample': 0.7000000000000001, 'colsample_bytree': 1.0, 'gamma': 0, 'reg_alpha': 5, 'reg_lambda': 5, 'min_child_weight': 3}. Best is trial 413 with value: 4.065239666666667.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###################################### VALIDATION Loss ###########################################\n",
      "Last estimator val1_error 4.686883\n",
      "Last estimator val2_error 3.992983\n",
      "Last estimator val3_error 4.689028\n",
      "val_avg_error 4.456298\n",
      "##################################################################################################\n",
      "Study statistics: \n",
      "  Number of finished trials:  446\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  446\n",
      "Best trial:\n",
      "  Value:  4.065239666666667\n",
      "  Params: \n",
      "    tweedie_variance_power: 1.6\n",
      "    max_depth: 4\n",
      "    learning_rate: 0.02632114605475799\n",
      "    subsample: 0.7000000000000001\n",
      "    colsample_bytree: 1.0\n",
      "    gamma: 5\n",
      "    reg_alpha: 5\n",
      "    reg_lambda: 5\n",
      "    min_child_weight: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            4.065239666666667,
            14.083874999999999
           ],
           "values": [
            4.698616666666667,
            4.529419666666667,
            4.484123,
            4.891925333333333,
            5.629361,
            4.907066333333333,
            8.142830333333334,
            4.675372,
            5.686279,
            4.596403666666666,
            14.083874999999999,
            9.718005,
            5.390986333333333,
            4.162259333333333,
            4.250552666666667,
            4.246308,
            4.375980333333334,
            4.111476333333333,
            4.507167666666667,
            10.235527666666668,
            4.1687639999999995,
            4.129764000000001,
            4.122221,
            4.165924333333334,
            5.405981999999999,
            4.517424,
            5.687100333333333,
            4.143971,
            5.4569806666666665,
            4.098597333333333,
            4.484554666666667,
            4.1022,
            4.479205,
            4.552414,
            4.099261,
            4.493991,
            4.137225666666667,
            5.708537,
            4.113708333333333,
            4.480361333333334,
            4.475141666666667,
            4.490892333333334,
            4.134535333333333,
            4.096131333333333,
            4.071516333333332,
            4.0907116666666665,
            4.476628,
            4.092084666666667,
            4.089996999999999,
            4.088994666666667,
            5.142186,
            4.088658,
            4.089912333333333,
            4.469779333333334,
            4.089976333333333,
            5.378818333333334,
            4.4701976666666665,
            4.0930523333333335,
            4.093675,
            13.985302666666668,
            4.096526,
            4.089882,
            4.470149333333333,
            4.085809333333334,
            4.089357666666667,
            4.072710333333333,
            4.076485333333333,
            4.069543666666667,
            4.0750443333333335,
            4.469779,
            4.074683666666666,
            4.074247333333333,
            4.067977333333334,
            4.075503,
            4.072949333333334,
            4.458478666666667,
            4.070968333333333,
            4.458266666666667,
            4.067475333333333,
            4.0779749999999995,
            4.460929333333333,
            4.070731333333334,
            4.073409,
            4.0731633333333335,
            4.073756333333333,
            4.467149,
            4.078147333333334,
            4.457837333333333,
            4.071631,
            5.730411,
            4.071095333333333,
            4.079974,
            4.077289,
            4.07861,
            4.462472333333333,
            4.066834,
            4.463488333333333,
            4.073118,
            4.081809,
            4.457236666666667,
            4.071967333333333,
            4.072442,
            4.071829,
            4.071766333333334,
            4.073298,
            4.071086333333334,
            4.073871,
            4.460986,
            4.075258666666667,
            4.083212333333333,
            4.402158333333333,
            4.074976333333333,
            4.067860333333333,
            4.073541333333334,
            4.502844,
            4.071719666666667,
            4.090704666666666,
            4.070059666666666,
            4.0763506666666665,
            4.093697333333334,
            4.465408,
            4.068421333333333,
            4.070299666666666,
            7.444328333333334,
            4.067528666666667,
            4.069398666666667,
            4.0677449999999995,
            4.068613333333333,
            4.070232333333333,
            4.457474333333333,
            4.67383,
            4.070739666666667,
            4.070394,
            4.068184333333334,
            4.072148666666667,
            4.066863000000001,
            4.105512333333333,
            4.4626280000000005,
            4.0713593333333336,
            4.095272333333334,
            4.072355333333333,
            4.072936333333334,
            4.077054333333334,
            4.0718776666666665,
            4.067004,
            4.0703293333333335,
            4.067968333333334,
            4.088225666666666,
            4.073559333333333,
            4.068256000000001,
            4.069527666666667,
            4.069096333333333,
            4.069994333333333,
            4.07012,
            4.074176666666667,
            4.0727839999999995,
            4.072206666666666,
            4.0727736666666665,
            4.213536666666666,
            4.471213666666666,
            4.069652666666666,
            4.079228333333333,
            4.074811333333334,
            4.074245333333334,
            4.0832006666666665,
            4.076877666666666,
            4.069998333333333,
            9.660130666666667,
            4.0934843333333335,
            4.4579173333333335,
            4.070577,
            4.069932333333333,
            4.070726666666666,
            4.072860666666666,
            4.072372333333333,
            4.068939333333334,
            4.074708333333333,
            4.0682583333333335,
            4.069516,
            4.069285333333333,
            4.073483333333333,
            4.069508333333333,
            4.0725620000000005,
            4.071453333333333,
            4.074102,
            4.071186,
            4.068803666666667,
            4.074237,
            4.068755666666666,
            4.071222,
            4.087925333333334,
            4.0738883333333336,
            4.076549666666667,
            4.075304666666667,
            4.092667333333334,
            4.067420666666667,
            4.071698,
            4.070767333333333,
            4.125525,
            4.068494666666666,
            4.073098333333333,
            4.074614,
            4.067235666666667,
            4.07223,
            4.083485666666667,
            4.074585,
            4.0705946666666675,
            4.0762453333333335,
            4.069685,
            4.086050333333334,
            4.466237333333334,
            4.071212,
            4.070579333333334,
            4.069756,
            4.0691999999999995,
            4.06907,
            4.073708333333333,
            4.067969000000001,
            4.070293,
            4.1018273333333335,
            7.437712,
            4.070443666666667,
            4.070270333333333,
            4.0701496666666666,
            4.071000000000001,
            4.072090666666667,
            4.0690273333333336,
            4.068214666666667,
            4.067797666666666,
            4.088124333333333,
            4.074686333333333,
            4.067980333333334,
            4.0667393333333335,
            4.068994666666667,
            4.070668,
            4.068904666666667,
            4.069079666666667,
            4.0742606666666665,
            4.069377,
            4.074154333333333,
            4.071959,
            4.067412,
            4.069099333333333,
            4.067670333333333,
            4.066742333333333,
            4.067716333333333,
            4.067531,
            4.066033333333333,
            4.070635666666667,
            4.066388666666667,
            4.069709333333333,
            4.08771,
            4.066620333333333,
            4.066198,
            4.066810333333334,
            4.068776,
            4.066674666666667,
            4.0675859999999995,
            4.0685986666666665,
            4.067131,
            4.066264666666666,
            4.067319666666666,
            4.06928,
            4.0673319999999995,
            4.455328333333333,
            4.069990333333333,
            4.068262666666667,
            4.069815333333334,
            4.072740666666667,
            4.068342666666666,
            4.086218333333333,
            4.069109999999999,
            4.456228,
            4.0676060000000005,
            5.624516333333333,
            4.066416,
            4.087945666666667,
            4.066721,
            4.069355666666667,
            4.072534,
            4.071238666666667,
            4.068472333333333,
            4.065639333333333,
            4.069144666666666,
            4.072129333333334,
            4.070752333333334,
            4.068134333333333,
            4.4557649999999995,
            4.066105333333334,
            4.069430333333333,
            4.086610666666666,
            4.070375333333334,
            4.067635,
            4.068840000000001,
            4.074186,
            4.066934,
            4.068200999999999,
            4.458339333333334,
            4.068364666666667,
            4.068200666666667,
            4.069994333333334,
            4.070021333333333,
            4.071339333333333,
            4.098061666666666,
            4.094301000000001,
            4.067229666666667,
            4.067069333333333,
            4.067382666666667,
            4.067816,
            4.068025666666666,
            4.068339333333333,
            4.0666813333333325,
            4.067433666666666,
            4.09232,
            4.456171666666666,
            4.069722666666666,
            4.072026,
            4.069576666666666,
            4.068978333333333,
            4.088065333333333,
            4.067908,
            4.069356,
            4.6806676666666664,
            4.067927,
            4.066147,
            4.06835,
            13.988521666666665,
            9.661821333333334,
            4.066895,
            4.453372666666667,
            4.068653333333334,
            4.070576333333333,
            4.069154666666667,
            4.066180666666667,
            4.065873333333333,
            4.068615666666667,
            4.065794333333334,
            4.089444,
            4.065369333333333,
            4.066506666666666,
            4.067915,
            4.315801,
            4.073887,
            4.949645333333333,
            4.454962666666667,
            4.067209666666667,
            5.3760650000000005,
            4.065304,
            4.0708036666666665,
            4.455582,
            4.068402333333332,
            4.068685666666667,
            4.067780666666667,
            4.091335999999999,
            4.0671539999999995,
            4.074663666666667,
            4.0700639999999995,
            4.068776333333333,
            5.635857333333334,
            4.068601666666667,
            4.0689296666666666,
            4.070598,
            4.066771,
            4.067567333333333,
            7.440157333333334,
            4.068698666666666,
            4.0693746666666675,
            4.085524,
            4.069774,
            4.068225666666667,
            4.069421,
            4.068454666666667,
            4.068015,
            4.457323333333334,
            4.069418,
            4.070246666666667,
            4.067884666666667,
            4.086629666666667,
            4.06768,
            4.092844333333333,
            4.068103,
            4.0695456666666665,
            4.0685883333333335,
            4.067406666666667,
            4.068065666666667,
            4.077914333333333,
            4.0683576666666665,
            4.073859666666666,
            4.070524333333334,
            4.072548666666666,
            4.066690333333333,
            4.459581666666666,
            4.0868150000000005,
            4.460134,
            4.067767333333333,
            4.070903333333334,
            4.068199666666667,
            4.068331333333333,
            4.069571,
            4.068460333333333,
            4.069646666666666,
            4.067849333333334,
            4.069439333333333,
            4.069905666666666,
            4.068645,
            4.470504333333333,
            4.070861000000001,
            4.069050666666667,
            4.075488,
            4.4938226666666665,
            4.090124666666667,
            4.067603666666667,
            4.070681,
            4.065239666666667,
            4.067373666666667,
            4.069116333333334,
            4.068847333333333,
            4.067401,
            4.089253333333333,
            4.068288666666667,
            4.067389666666666,
            4.067055,
            4.067597666666667,
            4.071429333333334,
            4.226528000000001,
            4.068693666666667,
            4.454910666666667,
            4.068852333333333,
            4.067875666666667,
            4.072396,
            4.066689,
            4.081170333333333,
            4.073924333333333,
            4.069769,
            4.089268666666666,
            4.088464,
            4.509804666666667,
            4.065934333333334,
            4.088062333333333,
            4.473897333333333,
            4.068026666666667,
            4.068908666666666,
            4.069972666666667,
            4.069332,
            4.067267999999999,
            4.456298
           ]
          },
          {
           "label": "colsample_bytree",
           "range": [
            0.1,
            1
           ],
           "values": [
            0.2,
            0.4,
            0.8,
            0.8,
            0.9,
            0.6,
            0.8,
            0.30000000000000004,
            0.6,
            0.2,
            1,
            0.4,
            0.5,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            1,
            1,
            0.9,
            0.1,
            0.5,
            0.5,
            0.5,
            0.4,
            0.5,
            0.30000000000000004,
            0.6,
            0.30000000000000004,
            0.4,
            0.2,
            0.4,
            0.4,
            0.30000000000000004,
            0.4,
            0.4,
            0.1,
            0.2,
            0.30000000000000004,
            0.4,
            0.6,
            0.30000000000000004,
            0.30000000000000004,
            0.4,
            0.4,
            0.4,
            0.4,
            0.5,
            0.5,
            0.6,
            0.6,
            0.5,
            0.5,
            0.6,
            0.5,
            0.5,
            0.7000000000000001,
            0.6,
            0.5,
            0.6,
            0.5,
            0.5,
            0.5,
            0.6,
            0.8,
            0.8,
            0.8,
            0.8,
            0.9,
            0.8,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            1,
            0.9,
            1,
            0.9,
            0.9,
            1,
            1,
            0.8,
            1,
            1,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.9,
            0.9,
            0.8,
            0.8,
            0.9,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            0.9,
            1,
            0.8,
            0.8,
            0.8,
            0.9,
            0.9,
            0.8,
            0.9,
            1,
            0.8,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            0.9,
            0.9,
            1,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            0.9,
            0.9,
            0.8,
            0.8,
            0.8,
            0.9,
            0.8,
            0.9,
            0.9,
            0.8,
            0.9,
            0.9,
            1,
            0.8,
            0.8,
            0.8,
            0.9,
            0.9,
            0.8,
            0.9,
            0.9,
            0.8,
            0.9,
            1,
            1,
            1,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            1,
            1,
            1,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.30000000000000004,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.6,
            1,
            1,
            1,
            0.7000000000000001,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
           ]
          },
          {
           "label": "gamma",
           "range": [
            0,
            5
           ],
           "values": [
            1,
            5,
            4,
            3,
            4,
            4,
            1,
            4,
            4,
            1,
            2,
            5,
            5,
            3,
            3,
            2,
            0,
            2,
            2,
            3,
            0,
            0,
            0,
            0,
            1,
            0,
            1,
            0,
            2,
            1,
            1,
            0,
            1,
            0,
            2,
            2,
            2,
            1,
            1,
            3,
            2,
            1,
            1,
            2,
            2,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            5,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            0,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            2,
            5,
            1,
            4,
            3,
            3,
            5,
            4,
            5,
            4,
            3,
            5,
            3,
            5,
            4,
            5,
            4,
            4,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            1,
            5,
            5,
            5,
            0
           ]
          },
          {
           "label": "learning_rate",
           "range": [
            -3.9926210942239018,
            -1.0018822413028934
           ],
           "ticktext": [
            "0.000102",
            "0.001",
            "0.01",
            "0.0996"
           ],
           "tickvals": [
            -3.9926210942239018,
            -3,
            -2,
            -1.0018822413028934
           ],
           "values": [
            -3.4243444949047372,
            -2.52291933877064,
            -1.1947387227582795,
            -3.482860180862748,
            -1.4556898241121787,
            -3.491213749242771,
            -3.9926210942239018,
            -3.5121330087084703,
            -2.532352112042536,
            -1.4182624251945872,
            -1.1059649780025875,
            -2.295573976417353,
            -2.1544160144354065,
            -2.709292651274503,
            -2.911747053547428,
            -2.8725915073414807,
            -2.961952270369448,
            -1.986181743624684,
            -1.932522005440126,
            -1.7577025983182328,
            -1.8083953215388353,
            -1.9023642559294436,
            -2.04367081515854,
            -2.1521989680439537,
            -1.598299854040568,
            -1.9934969281017971,
            -2.2453871487125947,
            -1.6395126698446798,
            -2.3728339087566015,
            -2.0142141299417236,
            -3.1812907745534162,
            -2.074666299014556,
            -2.0738428806661986,
            -2.568363659724845,
            -1.3841178878341303,
            -1.3413973022862529,
            -1.2946286790428667,
            -1.02651242167967,
            -1.6208089178204999,
            -1.5581333183575372,
            -1.7800248715811977,
            -1.5155968780096698,
            -1.2462620677217198,
            -1.7101667242178786,
            -1.7532831902978445,
            -1.7438289890686516,
            -1.158113084826946,
            -1.459161791141656,
            -1.7029370389654663,
            -1.7546134611251616,
            -3.8900674571556912,
            -1.7957266895646042,
            -1.462033551964842,
            -1.8909087539221507,
            -1.698620473993096,
            -1.473103279470564,
            -1.8681254993764467,
            -1.634909035054227,
            -1.2149645436247625,
            -2.3028967376823375,
            -1.8330074777544092,
            -1.7597924482586573,
            -1.7009874432586232,
            -1.3984262898871194,
            -1.3767956783560338,
            -1.3423622375422752,
            -1.0965946774903834,
            -1.0360511586436683,
            -1.0574442654356482,
            -1.0068564033506096,
            -1.1424043238098915,
            -1.1256056217479307,
            -1.1058452778864547,
            -1.0850896122534672,
            -1.1125205492314603,
            -1.1897958599536296,
            -1.2958952092897378,
            -1.2818335536672933,
            -1.1489687430124143,
            -1.2985498290405424,
            -1.2101482123573986,
            -1.1353450483086132,
            -1.1311158443035454,
            -1.3307392155974458,
            -1.3335832151983191,
            -1.0191612390590266,
            -1.2643238838166186,
            -1.5191298432311695,
            -1.2307369605205445,
            -1.1996694729809259,
            -1.0018822413028934,
            -1.003506449572512,
            -1.086680778521813,
            -1.237890381343877,
            -1.1522887478270962,
            -1.3667058165639399,
            -1.411018182333268,
            -1.534814235745065,
            -1.2418224787346626,
            -1.342122905222385,
            -1.4360124007370727,
            -1.4377954151249477,
            -1.4419791933283257,
            -1.5668108470103022,
            -1.581521326367796,
            -1.1717859317327213,
            -1.0567968529790785,
            -1.1751821766838684,
            -1.287563329056876,
            -1.0545704945109364,
            -3.279182632521379,
            -1.2010655059777307,
            -1.5086818830802233,
            -1.1579921840469103,
            -2.702973139947282,
            -1.4942891358338357,
            -1.3741334961359686,
            -1.4840806554746324,
            -1.2743032605078453,
            -1.1022685348139765,
            -1.0029866494451871,
            -1.244390865360762,
            -1.247675691820454,
            -1.3138137635339762,
            -1.0755551346599987,
            -1.071019326764625,
            -1.1250522395953957,
            -1.087381345970589,
            -1.0822510478825704,
            -1.0554551689283338,
            -3.6751357661241664,
            -1.094599560343342,
            -1.138660084925387,
            -1.090359596544144,
            -1.2128834235867563,
            -1.0732381442998342,
            -1.0671124703009822,
            -1.0897418799824148,
            -1.176731323755878,
            -1.0499681051834464,
            -1.1155571917096139,
            -1.242291882212306,
            -1.0053503544611275,
            -1.2513966650148318,
            -1.3754513708300142,
            -1.1610815179102705,
            -1.3787799536068173,
            -1.3876779879330996,
            -1.3184040261600443,
            -1.367256764917301,
            -1.3826478082597669,
            -1.3449792415889381,
            -1.382864580372228,
            -1.3708280527190038,
            -1.4169093389918541,
            -1.3153239281406917,
            -1.1988542018503003,
            -1.2943566173253496,
            -2.999812874935143,
            -2.4571541346830323,
            -1.5066225753879854,
            -1.132306234007723,
            -1.214866135105722,
            -1.147494135168801,
            -1.3567447340674657,
            -1.0541858076012502,
            -1.272170757132216,
            -1.0031466510626514,
            -1.1982539692903482,
            -1.4567156279593794,
            -1.114928723060715,
            -1.6164819080654196,
            -1.4879226106295758,
            -1.559844320130067,
            -1.53024188219778,
            -1.4199376655315405,
            -1.4097405832558374,
            -1.3386413242774975,
            -1.3348654048932036,
            -1.3283982370752665,
            -1.2763432868085194,
            -1.3402507685091785,
            -1.2531775311382038,
            -1.3161257841117013,
            -1.4334864569616956,
            -1.181005215348123,
            -1.3474592969358743,
            -1.216206152206768,
            -1.1041258936301501,
            -1.3972908693562924,
            -1.2726933580611224,
            -1.1149010703776898,
            -1.0762842930365362,
            -1.1710578066320725,
            -1.2291020555054435,
            -2.179687610822066,
            -1.4641064709369174,
            -1.3315822900974166,
            -2.777098050807069,
            -1.3889622920330098,
            -2.2046091660510756,
            -1.4064390681186054,
            -1.3479790303277852,
            -1.460007797876378,
            -1.3604326199618595,
            -1.1392464190375289,
            -1.2597453227323776,
            -1.4223247234513483,
            -1.9606134758582818,
            -2.571457084052238,
            -1.1965737191489847,
            -1.3144790001297215,
            -2.1231866539668625,
            -1.3578265828766656,
            -1.2869875085148708,
            -1.5124290875816548,
            -1.6367085705756472,
            -1.5533108045040296,
            -1.5666196369499723,
            -1.5311243276287787,
            -1.4938960144407036,
            -1.4590338200897373,
            -1.3928095138225272,
            -1.6913358282592321,
            -1.1001472827649845,
            -1.520261837601236,
            -1.4420844374551738,
            -1.6116264772731315,
            -1.4531745039249833,
            -1.5959318370654423,
            -1.0500425862378608,
            -1.4546933223663758,
            -1.4223819376405535,
            -1.645790169287335,
            -1.4732279544821063,
            -1.3955780359401757,
            -1.5733883188599458,
            -1.1417604644829917,
            -2.3181853168369844,
            -1.3801895518432423,
            -1.2353462102152615,
            -1.4188670477842271,
            -1.46942540170639,
            -1.4115716951643658,
            -1.5120473723460452,
            -1.5061846989478074,
            -1.5801242065794288,
            -1.5763569240074373,
            -1.6735860823092141,
            -1.5827369229328123,
            -1.6045241966067099,
            -1.6086098263535336,
            -1.5363497925541953,
            -1.5473205116419517,
            -1.5450050039737953,
            -1.543192887610274,
            -1.552554764109452,
            -1.5513225423821728,
            -1.723834320890428,
            -1.5647956171637787,
            -1.5456960709029848,
            -1.6536501879449061,
            -1.657622745170458,
            -1.5721933623622548,
            -1.575662494750219,
            -1.6734178605824657,
            -1.8072159325705934,
            -1.5377154225762677,
            -1.620162520068268,
            -1.5622271128326466,
            -1.5428523395108709,
            -1.696275290633037,
            -1.626570015737293,
            -1.513723250177177,
            -1.7426852333105105,
            -1.5201402168876126,
            -1.5951109954216576,
            -1.5052725352971275,
            -1.5416715946412842,
            -1.5057388102209146,
            -1.6571404760186146,
            -1.5822027836305177,
            -1.501119643123997,
            -1.499852002346483,
            -1.6032820333263094,
            -1.6609290408828403,
            -1.5502339786807622,
            -1.4784892102591647,
            -1.5836105907345606,
            -1.7280278082782439,
            -1.6285813119400596,
            -1.8548784565696723,
            -1.4783049130415846,
            -1.5822060871337522,
            -1.5035701029946849,
            -1.5868683732557376,
            -1.6565863148809057,
            -1.7742079802712174,
            -1.4810437524653914,
            -1.4419742611390727,
            -1.533311768892327,
            -1.6157868567400393,
            -1.4424303111399166,
            -1.6788330926370856,
            -1.556907130154689,
            -1.5264110529261916,
            -1.5175206519477435,
            -1.5237701012663865,
            -1.516442556442231,
            -1.5975579931029413,
            -1.4922651279002974,
            -1.436097409085227,
            -1.5700620461504842,
            -1.6417341859871926,
            -1.4729282748395411,
            -1.7040874913603221,
            -1.5379059113950697,
            -1.4455378741743496,
            -1.5983433353272993,
            -1.5161075695583226,
            -1.6367733712757826,
            -1.5416977329667938,
            -3.6149376574427534,
            -1.4470480458102521,
            -1.5771970727822027,
            -1.7180872723263634,
            -1.5936821966640737,
            -1.6688278253702182,
            -1.4803994908187812,
            -1.4274848940558402,
            -1.4927922006787653,
            -1.4144063215735057,
            -1.4699008292177804,
            -1.5661114764694626,
            -1.5639033275811576,
            -1.5710838978344368,
            -1.522162509188816,
            -1.6094598319769753,
            -1.4841683530025132,
            -1.4900646111501674,
            -1.4509124958667357,
            -3.1751425026320814,
            -1.4014100741902906,
            -3.976456988353742,
            -1.4998810894366836,
            -1.4835031665345202,
            -1.762195199897416,
            -1.581988939456824,
            -1.6352741793077545,
            -1.562724729023231,
            -1.6861601032850366,
            -1.6073696496668484,
            -1.5118603757503992,
            -1.5690264628697344,
            -1.4478959474088045,
            -1.631387145205144,
            -1.7126234708037775,
            -1.5176876108730732,
            -1.550060536713491,
            -1.4635043427142453,
            -1.6063151634236168,
            -1.4175665744224253,
            -1.566985605434378,
            -1.4810210148988272,
            -1.5422229352682766,
            -1.6495033576015297,
            -1.4944814581509236,
            -1.4189802409654064,
            -1.800000423344937,
            -1.5855116916847363,
            -1.6900539151943237,
            -1.5332852202018912,
            -1.4615865253062656,
            -1.6505185544506722,
            -1.558564438707296,
            -1.3876714095705749,
            -1.4885145569042058,
            -1.610312566840581,
            -1.526649526082138,
            -1.4214850903134737,
            -1.5955706932480902,
            -1.742961613127646,
            -1.481795721101243,
            -1.546975696499517,
            -1.6528595372338506,
            -1.4032841729062955,
            -1.4916150247970144,
            -1.568216462393293,
            -1.4372297575683692,
            -1.6949809986156965,
            -1.6169438422777052,
            -1.623376526611779,
            -1.5974725826856973,
            -1.6742853185893616,
            -1.5385413306271782,
            -1.7241549415818231,
            -1.550700292717201,
            -1.6208867882426872,
            -1.3661797537367104,
            -2.0523354889928482,
            -1.512008183294145,
            -1.5845989135324756,
            -1.4604756182234058,
            -1.625524690566013,
            -1.9260489727450267,
            -1.5418670598167548,
            -1.679478516858546,
            -1.4418877566989388,
            -1.78739380273772,
            -2.6717492233326894,
            -2.388778048397791,
            -1.5136405155344774,
            -1.3853502890103846,
            -1.579695204935688,
            -1.5894854593917518,
            -1.4881744024260748,
            -1.6491965357756546,
            -1.5551043448868669,
            -1.4286584783390284,
            -1.3491478173264644,
            -1.5107013707837351,
            -1.593525444044275,
            -1.4456495095668118,
            -1.7257590651154238,
            -3.0258498830331986,
            -1.64596463918743,
            -1.5519990554231071,
            -1.486429915118625,
            -1.4050314660682466,
            -1.5925119258189226,
            -1.5212056249005255,
            -1.539032305871063,
            -1.665437427304117,
            -1.6086964182300851,
            -1.5088311971178299,
            -1.563997003234838,
            -3.419930616079672,
            -1.4615104573394486,
            -1.4925950675654758,
            -1.4440140093993108,
            -1.4680737293981994,
            -1.6310632628353605,
            -1.7015200036966558,
            -1.3762554195570982,
            -1.5228287833949103,
            -1.5680683951761496
           ]
          },
          {
           "label": "max_depth",
           "range": [
            3,
            10
           ],
           "values": [
            8,
            10,
            5,
            5,
            3,
            6,
            4,
            9,
            9,
            10,
            7,
            6,
            5,
            7,
            7,
            7,
            8,
            8,
            8,
            9,
            6,
            6,
            7,
            8,
            6,
            7,
            4,
            8,
            9,
            5,
            4,
            5,
            5,
            3,
            5,
            5,
            4,
            5,
            4,
            3,
            5,
            4,
            5,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            4,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            6,
            5,
            4,
            5,
            5,
            5,
            5,
            6,
            4,
            4,
            10,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            5,
            5,
            6,
            5,
            5,
            6,
            5,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            4,
            7,
            3,
            4,
            4,
            3,
            4,
            4,
            3,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            9,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            10,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            7,
            4,
            4,
            5,
            5,
            6,
            5,
            4,
            6,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            8,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            7,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            8,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            6,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            10,
            6,
            4,
            4,
            4,
            4,
            4,
            4,
            9,
            4,
            4,
            3,
            4,
            4,
            4
           ]
          },
          {
           "label": "min_child_weight",
           "range": [
            1,
            10
           ],
           "values": [
            7,
            2,
            5,
            2,
            4,
            6,
            2,
            6,
            4,
            9,
            9,
            1,
            4,
            3,
            4,
            3,
            3,
            1,
            1,
            1,
            3,
            3,
            2,
            2,
            1,
            2,
            10,
            5,
            1,
            7,
            7,
            7,
            8,
            7,
            8,
            8,
            8,
            6,
            7,
            9,
            6,
            7,
            8,
            7,
            6,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            4,
            4,
            4,
            6,
            4,
            4,
            6,
            5,
            5,
            5,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            1,
            1,
            1,
            2,
            2,
            2,
            1,
            2,
            1,
            3,
            2,
            1,
            3,
            3,
            2,
            3,
            2,
            2,
            3,
            1,
            3,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            2,
            6,
            2,
            1,
            1,
            1,
            1,
            1,
            2,
            2,
            2,
            2,
            2,
            1,
            2,
            1,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            1,
            2,
            2,
            2,
            3,
            2,
            2,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            10,
            1,
            1,
            1,
            1,
            2,
            1,
            2,
            1,
            3,
            2,
            2,
            1,
            1,
            2,
            10,
            10,
            9,
            9,
            9,
            10,
            9,
            9,
            9,
            9,
            9,
            10,
            10,
            8,
            10,
            8,
            10,
            10,
            10,
            10,
            8,
            8,
            8,
            7,
            9,
            7,
            9,
            8,
            8,
            8,
            8,
            7,
            8,
            8,
            10,
            9,
            9,
            8,
            9,
            9,
            9,
            10,
            9,
            9,
            9,
            9,
            9,
            8,
            2,
            2,
            9,
            1,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            3,
            3,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            2,
            2,
            2,
            2,
            2,
            2,
            3,
            3,
            6,
            4,
            3,
            3,
            3,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            4,
            3,
            4,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            5,
            3,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            3,
            3,
            2,
            4,
            2,
            2,
            3,
            2,
            3,
            2,
            3,
            2,
            2,
            2,
            3,
            2,
            4,
            3,
            3,
            2,
            2,
            2,
            3,
            2,
            3,
            2,
            2,
            4,
            3,
            2,
            3,
            2,
            2,
            5,
            2,
            3,
            2,
            2,
            3,
            2,
            2,
            3,
            3,
            2,
            4,
            2,
            3,
            2,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            3,
            4,
            3,
            3,
            3,
            3,
            3
           ]
          },
          {
           "label": "reg_alpha",
           "range": [
            0,
            5
           ],
           "values": [
            2,
            5,
            4,
            2,
            1,
            0,
            0,
            4,
            5,
            1,
            4,
            5,
            4,
            3,
            3,
            3,
            3,
            3,
            2,
            3,
            1,
            1,
            2,
            1,
            2,
            2,
            0,
            1,
            2,
            1,
            2,
            1,
            1,
            0,
            2,
            1,
            3,
            0,
            2,
            1,
            2,
            2,
            2,
            4,
            4,
            4,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            3,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            2,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            0,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            1,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            2,
            0,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5
           ]
          },
          {
           "label": "reg_lambda",
           "range": [
            0,
            5
           ],
           "values": [
            4,
            1,
            4,
            3,
            4,
            1,
            5,
            0,
            1,
            1,
            5,
            2,
            3,
            2,
            4,
            2,
            2,
            2,
            3,
            0,
            2,
            2,
            2,
            3,
            1,
            2,
            3,
            1,
            2,
            0,
            0,
            0,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            2,
            1,
            1,
            5,
            1,
            1,
            2,
            2,
            2,
            3,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            4,
            4,
            5,
            4,
            4,
            4,
            5,
            3,
            3,
            3,
            3,
            4,
            4,
            3,
            4,
            4,
            5,
            3,
            3,
            3,
            3,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            3,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            4,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            2,
            2,
            5,
            5,
            2,
            2,
            2,
            5,
            5,
            2,
            2,
            2,
            5,
            2,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            2,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            3,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            0,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            5,
            1,
            5,
            5,
            5,
            5,
            5,
            5,
            5
           ]
          },
          {
           "label": "subsample",
           "range": [
            0.1,
            1
           ],
           "values": [
            0.8,
            0.9,
            0.4,
            0.5,
            1,
            1,
            0.1,
            0.9,
            0.8,
            1,
            0.30000000000000004,
            0.6,
            0.5,
            0.30000000000000004,
            0.30000000000000004,
            0.2,
            0.1,
            0.2,
            0.30000000000000004,
            0.2,
            0.6,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.4,
            0.6,
            0.5,
            0.8,
            0.8,
            0.7000000000000001,
            0.9,
            0.8,
            0.7000000000000001,
            0.9,
            0.8,
            0.7000000000000001,
            0.8,
            0.5,
            0.9,
            0.8,
            0.7000000000000001,
            0.9,
            0.9,
            1,
            1,
            0.9,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0.9,
            1,
            0.9,
            1,
            1,
            1,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.9,
            0.8,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.6,
            0.8,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.8,
            0.6,
            0.7000000000000001,
            0.8,
            0.9,
            0.4,
            0.6,
            0.7000000000000001,
            0.9,
            0.9,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.8,
            0.8,
            0.9,
            0.8,
            0.9,
            0.8,
            0.9,
            0.8,
            0.7000000000000001,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.1,
            0.9,
            0.8,
            0.8,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.9,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.5,
            0.8,
            0.8,
            0.8,
            0.9,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.8,
            0.8,
            0.8,
            0.4,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.9,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.2,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.8,
            0.8,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.6,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.8,
            0.7000000000000001,
            0.8,
            0.6,
            0.7000000000000001,
            0.8,
            0.8,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.5,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.30000000000000004,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.5,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.4,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.6,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.2,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001,
            0.7000000000000001
           ]
          },
          {
           "label": "tweedie_variance_...",
           "range": [
            1.1,
            1.9
           ],
           "values": [
            1.6,
            1.7000000000000002,
            1.4000000000000001,
            1.4000000000000001,
            1.8000000000000003,
            1.4000000000000001,
            1.2000000000000002,
            1.5,
            1.8000000000000003,
            1.7000000000000002,
            1.1,
            1.9,
            1.3,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.9,
            1.5,
            1.5,
            1.6,
            1.5,
            1.3,
            1.7000000000000002,
            1.8000000000000003,
            1.6,
            1.3,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.7000000000000002,
            1.6,
            1.4000000000000001,
            1.6,
            1.8000000000000003,
            1.5,
            1.4000000000000001,
            1.7000000000000002,
            1.4000000000000001,
            1.5,
            1.5,
            1.6,
            1.5,
            1.4000000000000001,
            1.5,
            1.5,
            1.5,
            1.4000000000000001,
            1.5,
            1.5,
            1.4000000000000001,
            1.5,
            1.3,
            1.4000000000000001,
            1.5,
            1.5,
            1.1,
            1.5,
            1.5,
            1.4000000000000001,
            1.5,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.7000000000000002,
            1.6,
            1.8000000000000003,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.5,
            1.6,
            1.6,
            1.5,
            1.7000000000000002,
            1.6,
            1.6,
            1.2000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.9,
            1.5,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.2000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.7000000000000002,
            1.6,
            1.8000000000000003,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.1,
            1.9,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.3,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.8000000000000003,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.2000000000000002,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.5,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.4000000000000001,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.5,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002,
            1.6,
            1.6,
            1.6,
            1.6,
            1.6,
            1.7000000000000002
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           4.698616666666667,
           4.529419666666667,
           4.484123,
           4.891925333333333,
           5.629361,
           4.907066333333333,
           8.142830333333334,
           4.675372,
           5.686279,
           4.596403666666666,
           14.083874999999999,
           9.718005,
           5.390986333333333,
           4.162259333333333,
           4.250552666666667,
           4.246308,
           4.375980333333334,
           4.111476333333333,
           4.507167666666667,
           10.235527666666668,
           4.1687639999999995,
           4.129764000000001,
           4.122221,
           4.165924333333334,
           5.405981999999999,
           4.517424,
           5.687100333333333,
           4.143971,
           5.4569806666666665,
           4.098597333333333,
           4.484554666666667,
           4.1022,
           4.479205,
           4.552414,
           4.099261,
           4.493991,
           4.137225666666667,
           5.708537,
           4.113708333333333,
           4.480361333333334,
           4.475141666666667,
           4.490892333333334,
           4.134535333333333,
           4.096131333333333,
           4.071516333333332,
           4.0907116666666665,
           4.476628,
           4.092084666666667,
           4.089996999999999,
           4.088994666666667,
           5.142186,
           4.088658,
           4.089912333333333,
           4.469779333333334,
           4.089976333333333,
           5.378818333333334,
           4.4701976666666665,
           4.0930523333333335,
           4.093675,
           13.985302666666668,
           4.096526,
           4.089882,
           4.470149333333333,
           4.085809333333334,
           4.089357666666667,
           4.072710333333333,
           4.076485333333333,
           4.069543666666667,
           4.0750443333333335,
           4.469779,
           4.074683666666666,
           4.074247333333333,
           4.067977333333334,
           4.075503,
           4.072949333333334,
           4.458478666666667,
           4.070968333333333,
           4.458266666666667,
           4.067475333333333,
           4.0779749999999995,
           4.460929333333333,
           4.070731333333334,
           4.073409,
           4.0731633333333335,
           4.073756333333333,
           4.467149,
           4.078147333333334,
           4.457837333333333,
           4.071631,
           5.730411,
           4.071095333333333,
           4.079974,
           4.077289,
           4.07861,
           4.462472333333333,
           4.066834,
           4.463488333333333,
           4.073118,
           4.081809,
           4.457236666666667,
           4.071967333333333,
           4.072442,
           4.071829,
           4.071766333333334,
           4.073298,
           4.071086333333334,
           4.073871,
           4.460986,
           4.075258666666667,
           4.083212333333333,
           4.402158333333333,
           4.074976333333333,
           4.067860333333333,
           4.073541333333334,
           4.502844,
           4.071719666666667,
           4.090704666666666,
           4.070059666666666,
           4.0763506666666665,
           4.093697333333334,
           4.465408,
           4.068421333333333,
           4.070299666666666,
           7.444328333333334,
           4.067528666666667,
           4.069398666666667,
           4.0677449999999995,
           4.068613333333333,
           4.070232333333333,
           4.457474333333333,
           4.67383,
           4.070739666666667,
           4.070394,
           4.068184333333334,
           4.072148666666667,
           4.066863000000001,
           4.105512333333333,
           4.4626280000000005,
           4.0713593333333336,
           4.095272333333334,
           4.072355333333333,
           4.072936333333334,
           4.077054333333334,
           4.0718776666666665,
           4.067004,
           4.0703293333333335,
           4.067968333333334,
           4.088225666666666,
           4.073559333333333,
           4.068256000000001,
           4.069527666666667,
           4.069096333333333,
           4.069994333333333,
           4.07012,
           4.074176666666667,
           4.0727839999999995,
           4.072206666666666,
           4.0727736666666665,
           4.213536666666666,
           4.471213666666666,
           4.069652666666666,
           4.079228333333333,
           4.074811333333334,
           4.074245333333334,
           4.0832006666666665,
           4.076877666666666,
           4.069998333333333,
           9.660130666666667,
           4.0934843333333335,
           4.4579173333333335,
           4.070577,
           4.069932333333333,
           4.070726666666666,
           4.072860666666666,
           4.072372333333333,
           4.068939333333334,
           4.074708333333333,
           4.0682583333333335,
           4.069516,
           4.069285333333333,
           4.073483333333333,
           4.069508333333333,
           4.0725620000000005,
           4.071453333333333,
           4.074102,
           4.071186,
           4.068803666666667,
           4.074237,
           4.068755666666666,
           4.071222,
           4.087925333333334,
           4.0738883333333336,
           4.076549666666667,
           4.075304666666667,
           4.092667333333334,
           4.067420666666667,
           4.071698,
           4.070767333333333,
           4.125525,
           4.068494666666666,
           4.073098333333333,
           4.074614,
           4.067235666666667,
           4.07223,
           4.083485666666667,
           4.074585,
           4.0705946666666675,
           4.0762453333333335,
           4.069685,
           4.086050333333334,
           4.466237333333334,
           4.071212,
           4.070579333333334,
           4.069756,
           4.0691999999999995,
           4.06907,
           4.073708333333333,
           4.067969000000001,
           4.070293,
           4.1018273333333335,
           7.437712,
           4.070443666666667,
           4.070270333333333,
           4.0701496666666666,
           4.071000000000001,
           4.072090666666667,
           4.0690273333333336,
           4.068214666666667,
           4.067797666666666,
           4.088124333333333,
           4.074686333333333,
           4.067980333333334,
           4.0667393333333335,
           4.068994666666667,
           4.070668,
           4.068904666666667,
           4.069079666666667,
           4.0742606666666665,
           4.069377,
           4.074154333333333,
           4.071959,
           4.067412,
           4.069099333333333,
           4.067670333333333,
           4.066742333333333,
           4.067716333333333,
           4.067531,
           4.066033333333333,
           4.070635666666667,
           4.066388666666667,
           4.069709333333333,
           4.08771,
           4.066620333333333,
           4.066198,
           4.066810333333334,
           4.068776,
           4.066674666666667,
           4.0675859999999995,
           4.0685986666666665,
           4.067131,
           4.066264666666666,
           4.067319666666666,
           4.06928,
           4.0673319999999995,
           4.455328333333333,
           4.069990333333333,
           4.068262666666667,
           4.069815333333334,
           4.072740666666667,
           4.068342666666666,
           4.086218333333333,
           4.069109999999999,
           4.456228,
           4.0676060000000005,
           5.624516333333333,
           4.066416,
           4.087945666666667,
           4.066721,
           4.069355666666667,
           4.072534,
           4.071238666666667,
           4.068472333333333,
           4.065639333333333,
           4.069144666666666,
           4.072129333333334,
           4.070752333333334,
           4.068134333333333,
           4.4557649999999995,
           4.066105333333334,
           4.069430333333333,
           4.086610666666666,
           4.070375333333334,
           4.067635,
           4.068840000000001,
           4.074186,
           4.066934,
           4.068200999999999,
           4.458339333333334,
           4.068364666666667,
           4.068200666666667,
           4.069994333333334,
           4.070021333333333,
           4.071339333333333,
           4.098061666666666,
           4.094301000000001,
           4.067229666666667,
           4.067069333333333,
           4.067382666666667,
           4.067816,
           4.068025666666666,
           4.068339333333333,
           4.0666813333333325,
           4.067433666666666,
           4.09232,
           4.456171666666666,
           4.069722666666666,
           4.072026,
           4.069576666666666,
           4.068978333333333,
           4.088065333333333,
           4.067908,
           4.069356,
           4.6806676666666664,
           4.067927,
           4.066147,
           4.06835,
           13.988521666666665,
           9.661821333333334,
           4.066895,
           4.453372666666667,
           4.068653333333334,
           4.070576333333333,
           4.069154666666667,
           4.066180666666667,
           4.065873333333333,
           4.068615666666667,
           4.065794333333334,
           4.089444,
           4.065369333333333,
           4.066506666666666,
           4.067915,
           4.315801,
           4.073887,
           4.949645333333333,
           4.454962666666667,
           4.067209666666667,
           5.3760650000000005,
           4.065304,
           4.0708036666666665,
           4.455582,
           4.068402333333332,
           4.068685666666667,
           4.067780666666667,
           4.091335999999999,
           4.0671539999999995,
           4.074663666666667,
           4.0700639999999995,
           4.068776333333333,
           5.635857333333334,
           4.068601666666667,
           4.0689296666666666,
           4.070598,
           4.066771,
           4.067567333333333,
           7.440157333333334,
           4.068698666666666,
           4.0693746666666675,
           4.085524,
           4.069774,
           4.068225666666667,
           4.069421,
           4.068454666666667,
           4.068015,
           4.457323333333334,
           4.069418,
           4.070246666666667,
           4.067884666666667,
           4.086629666666667,
           4.06768,
           4.092844333333333,
           4.068103,
           4.0695456666666665,
           4.0685883333333335,
           4.067406666666667,
           4.068065666666667,
           4.077914333333333,
           4.0683576666666665,
           4.073859666666666,
           4.070524333333334,
           4.072548666666666,
           4.066690333333333,
           4.459581666666666,
           4.0868150000000005,
           4.460134,
           4.067767333333333,
           4.070903333333334,
           4.068199666666667,
           4.068331333333333,
           4.069571,
           4.068460333333333,
           4.069646666666666,
           4.067849333333334,
           4.069439333333333,
           4.069905666666666,
           4.068645,
           4.470504333333333,
           4.070861000000001,
           4.069050666666667,
           4.075488,
           4.4938226666666665,
           4.090124666666667,
           4.067603666666667,
           4.070681,
           4.065239666666667,
           4.067373666666667,
           4.069116333333334,
           4.068847333333333,
           4.067401,
           4.089253333333333,
           4.068288666666667,
           4.067389666666666,
           4.067055,
           4.067597666666667,
           4.071429333333334,
           4.226528000000001,
           4.068693666666667,
           4.454910666666667,
           4.068852333333333,
           4.067875666666667,
           4.072396,
           4.066689,
           4.081170333333333,
           4.073924333333333,
           4.069769,
           4.089268666666666,
           4.088464,
           4.509804666666667,
           4.065934333333334,
           4.088062333333333,
           4.473897333333333,
           4.068026666666667,
           4.068908666666666,
           4.069972666666667,
           4.069332,
           4.067267999999999,
           4.456298
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445
         ],
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ]
        },
        {
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445
         ],
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.484123,
          4.162259333333333,
          4.162259333333333,
          4.162259333333333,
          4.162259333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.111476333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.098597333333333,
          4.096131333333333,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.071516333333332,
          4.069543666666667,
          4.069543666666667,
          4.069543666666667,
          4.069543666666667,
          4.069543666666667,
          4.067977333333334,
          4.067977333333334,
          4.067977333333334,
          4.067977333333334,
          4.067977333333334,
          4.067977333333334,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.067475333333333,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.066834,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.0667393333333335,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.066033333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065639333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065369333333333,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065304,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667,
          4.065239666666667
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.2,
          0.4,
          0.8,
          0.8,
          0.9,
          0.6,
          0.8,
          0.30000000000000004,
          0.6,
          0.2,
          1,
          0.4,
          0.5,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          1,
          1,
          0.9,
          0.1,
          0.5,
          0.5,
          0.5,
          0.4,
          0.5,
          0.30000000000000004,
          0.6,
          0.30000000000000004,
          0.4,
          0.2,
          0.4,
          0.4,
          0.30000000000000004,
          0.4,
          0.4,
          0.1,
          0.2,
          0.30000000000000004,
          0.4,
          0.6,
          0.30000000000000004,
          0.30000000000000004,
          0.4,
          0.4,
          0.4,
          0.4,
          0.5,
          0.5,
          0.6,
          0.6,
          0.5,
          0.5,
          0.6,
          0.5,
          0.5,
          0.7000000000000001,
          0.6,
          0.5,
          0.6,
          0.5,
          0.5,
          0.5,
          0.6,
          0.8,
          0.8,
          0.8,
          0.8,
          0.9,
          0.8,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          1,
          0.9,
          1,
          0.9,
          0.9,
          1,
          1,
          0.8,
          1,
          1,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.9,
          0.9,
          0.8,
          0.8,
          0.9,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          0.9,
          1,
          0.8,
          0.8,
          0.8,
          0.9,
          0.9,
          0.8,
          0.9,
          1,
          0.8,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          0.9,
          0.9,
          1,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          0.9,
          0.9,
          0.8,
          0.8,
          0.8,
          0.9,
          0.8,
          0.9,
          0.9,
          0.8,
          0.9,
          0.9,
          1,
          0.8,
          0.8,
          0.8,
          0.9,
          0.9,
          0.8,
          0.9,
          0.9,
          0.8,
          0.9,
          1,
          1,
          1,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          1,
          1,
          1,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.30000000000000004,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.6,
          1,
          1,
          1,
          0.7000000000000001,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "xaxis": "x",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          5,
          4,
          3,
          4,
          4,
          1,
          4,
          4,
          1,
          2,
          5,
          5,
          3,
          3,
          2,
          0,
          2,
          2,
          3,
          0,
          0,
          0,
          0,
          1,
          0,
          1,
          0,
          2,
          1,
          1,
          0,
          1,
          0,
          2,
          2,
          2,
          1,
          1,
          3,
          2,
          1,
          1,
          2,
          2,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          5,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          0,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          2,
          5,
          1,
          4,
          3,
          3,
          5,
          4,
          5,
          4,
          3,
          5,
          3,
          5,
          4,
          5,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          1,
          5,
          5,
          5,
          0
         ],
         "xaxis": "x2",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.0003764051051512748,
          0.0029997196032076137,
          0.0638647589382723,
          0.00032895752021031656,
          0.035019518937087324,
          0.0003226905525937058,
          0.00010171357189346834,
          0.0003075154861678151,
          0.0029352688650674187,
          0.03817135483072482,
          0.07834928219646153,
          0.005063210969634764,
          0.0070078369005192225,
          0.0019530229590260513,
          0.0012253296611240908,
          0.0013409373655209262,
          0.0010915602940096097,
          0.01032329306020988,
          0.011680945417141216,
          0.017470180885870382,
          0.015545499404452186,
          0.01252090568150884,
          0.009043346780855626,
          0.007043702942279315,
          0.025217390631609646,
          0.010150865465660828,
          0.0056834605692157505,
          0.022934397220475782,
          0.004238050147204214,
          0.009678005622041122,
          0.0006587327041809475,
          0.008420418970087806,
          0.008436399151458463,
          0.0027016951320968235,
          0.04129353967960751,
          0.04556199139714894,
          0.05074243697307494,
          0.09407789215171077,
          0.023943690062883327,
          0.027660923887037128,
          0.016594918673890836,
          0.030507254283361433,
          0.05672022334441835,
          0.019490962045155873,
          0.017648866162048905,
          0.018037278499449385,
          0.06948433655480885,
          0.03474067151748575,
          0.019818143148232385,
          0.017594889304134765,
          0.00012880494687873825,
          0.01600564980142287,
          0.03451170758534077,
          0.012855567294298247,
          0.020016102946287705,
          0.03364315531514966,
          0.013547978557873049,
          0.023178800896083502,
          0.060958666266913285,
          0.0049785544613249605,
          0.014689009856453656,
          0.017386315318856604,
          0.0199073089608885,
          0.039955236910305295,
          0.041995651361079155,
          0.04546087206730641,
          0.08005810804217295,
          0.09203411518209473,
          0.08761041439975839,
          0.09843365164359016,
          0.07204364477573864,
          0.07488492139405792,
          0.07837087977857655,
          0.08220730060338266,
          0.07717549980883655,
          0.06459577900325465,
          0.05059467269226239,
          0.05225964392852761,
          0.07096288394426943,
          0.050286356618442885,
          0.06163846114225631,
          0.07322425330126613,
          0.0739408018046006,
          0.046693968328480204,
          0.04638918951049332,
          0.09568387630161702,
          0.05440967304540634,
          0.030260085916597224,
          0.05878452854448729,
          0.0631437727811533,
          0.09956753575490426,
          0.0991958607860392,
          0.08190666092394712,
          0.057824198089704154,
          0.07042246979128165,
          0.042982748574615016,
          0.038813411588415794,
          0.02918675175333595,
          0.057303021370108044,
          0.04548593168685629,
          0.03664271116294638,
          0.03649258135346505,
          0.036142717788721614,
          0.027113722881630692,
          0.026210703257811913,
          0.06733084552447723,
          0.08774111459035928,
          0.06680636212486135,
          0.051574695308831575,
          0.08819206375038255,
          0.0005257961084738489,
          0.06294112396563006,
          0.030996889629883954,
          0.06950368259824587,
          0.001981649582200613,
          0.03204135429495806,
          0.04225387117272038,
          0.03280343661946973,
          0.05317368267464799,
          0.07901898833394877,
          0.09931465780605796,
          0.05696513548539849,
          0.05653589974574841,
          0.04854966487803635,
          0.08403203197758452,
          0.0849142686055157,
          0.07498040128971857,
          0.08177464247443103,
          0.0827463702503117,
          0.08801259600751914,
          0.0002112828438835698,
          0.08042673522127984,
          0.0726674490964686,
          0.08121577697180332,
          0.061251478523439616,
          0.08448154656643588,
          0.08568159247866293,
          0.08133137601314162,
          0.06656848547184778,
          0.08913163944777835,
          0.07663776101860924,
          0.05724111934854996,
          0.09877559297439983,
          0.05605357740330609,
          0.04212584536026867,
          0.06901102566588568,
          0.041804212471702636,
          0.04095642227405268,
          0.04803922293963171,
          0.04292825499758596,
          0.0414335544625359,
          0.04518775427050801,
          0.04141287863462671,
          0.04257669508007531,
          0.0382904668117906,
          0.04838113715648413,
          0.0632624195673599,
          0.05077423429054989,
          0.001000430964223274,
          0.003490164246957094,
          0.03114421756705422,
          0.07373840952246451,
          0.06097248069933935,
          0.0712042415549367,
          0.04398000414263492,
          0.08827021662556778,
          0.053435421918531185,
          0.09927807530331065,
          0.06334991415485886,
          0.034936900421608345,
          0.07674874399993044,
          0.024183440797390054,
          0.03251452316765861,
          0.027552161780691344,
          0.029495659955157197,
          0.038024396897980345,
          0.03892776024113669,
          0.04585204138521771,
          0.04625243432010743,
          0.04694634250641924,
          0.052924493838987494,
          0.04568243358420197,
          0.055824194963640134,
          0.048291891464397316,
          0.03685645349890413,
          0.06591659794156875,
          0.04493044325277917,
          0.06078463984358561,
          0.07868176732999038,
          0.04005983264521185,
          0.05337115997818532,
          0.07675363095186466,
          0.08389106483547817,
          0.0674438250829374,
          0.059006240423774566,
          0.006611688575262171,
          0.03434737321092715,
          0.046603411551377115,
          0.0016707133742231593,
          0.040835484053030696,
          0.0062429640483851415,
          0.039224817522143324,
          0.044876705788266864,
          0.03467306247533011,
          0.043608121599906485,
          0.0725694081192752,
          0.054986322797022515,
          0.0378159727677722,
          0.010949304260035774,
          0.002682519674725694,
          0.06359548457652733,
          0.048475355182522516,
          0.007530318511446711,
          0.043870584141763876,
          0.05164312230186377,
          0.03073059099163347,
          0.023082956302472698,
          0.027969789345597,
          0.02712566307028695,
          0.02943578840299538,
          0.03207037111434938,
          0.03475090985929584,
          0.040475338190696444,
          0.02035467496643904,
          0.07940588989896301,
          0.030181315301251756,
          0.036133960256503166,
          0.02445532972769655,
          0.03522293132963262,
          0.025355265525889105,
          0.08911635477450065,
          0.03509996453327621,
          0.03781099119927495,
          0.02260527687312473,
          0.03363349859845728,
          0.040218138378813564,
          0.02670617442339745,
          0.07215053163734067,
          0.004806342143250523,
          0.04166874766728017,
          0.058163936252439145,
          0.038118249837673965,
          0.03392927644877105,
          0.03876397500234606,
          0.030757612959129387,
          0.03117563449012902,
          0.02629515852756331,
          0.026524247762319743,
          0.02120381066797723,
          0.026137441696477467,
          0.024858550615868134,
          0.02462579011364593,
          0.029083736914147326,
          0.028358254017244726,
          0.02850985418045522,
          0.028629061559660978,
          0.02801852288556205,
          0.02809813259583872,
          0.018887117367858346,
          0.027239829370184765,
          0.0284645242234113,
          0.022199838347185114,
          0.021997698981644206,
          0.02677975735393568,
          0.02656669349509269,
          0.02121202544550791,
          0.015587772811969205,
          0.028992427340312828,
          0.02397935404615313,
          0.027401408497814514,
          0.02865151958394458,
          0.020124481945934147,
          0.023628164418121614,
          0.030639152611449803,
          0.018084843991802883,
          0.03018976852199801,
          0.025403233758645463,
          0.031241182560790018,
          0.028729522335473132,
          0.03120765884913205,
          0.022022140241238053,
          0.026169607943853736,
          0.03154135575677926,
          0.03163355475902977,
          0.02492975248732179,
          0.021830865759221833,
          0.028168649200058977,
          0.03322850404965638,
          0.026084914002458694,
          0.0187056236268911,
          0.023518991115946852,
          0.013967592091073757,
          0.0332426078908364,
          0.026169408882941638,
          0.031363888193384856,
          0.025889974742150806,
          0.022050258497779043,
          0.016818684343856808,
          0.033033626003869526,
          0.03614312825614391,
          0.029287899870368426,
          0.024222175321843235,
          0.036105194496911706,
          0.02094917416482088,
          0.027739132168372052,
          0.029756986439767243,
          0.030372416589633286,
          0.029938490453215748,
          0.030447906938347667,
          0.025260503738615957,
          0.03219102994754458,
          0.036635539458860014,
          0.026911503011259535,
          0.022817382039772002,
          0.03365671499562343,
          0.019765714072335204,
          0.028979713565526727,
          0.03584776846088655,
          0.02521486600891578,
          0.030471401559119975,
          0.023079512371673248,
          0.028727793280556933,
          0.00024269584576421958,
          0.035723331539896645,
          0.026472985831947956,
          0.0191387129019324,
          0.02548694626644729,
          0.021437403115256506,
          0.03308266667275996,
          0.0373693123220022,
          0.03215198564781778,
          0.038511787662737156,
          0.03389215397541598,
          0.027157420916684556,
          0.02729585311244984,
          0.026848257358128208,
          0.030049516656498874,
          0.02457763940005055,
          0.03279681325679455,
          0.03235455186178194,
          0.03540686736760506,
          0.0006681246535722837,
          0.03968166860143123,
          0.00010557060530288565,
          0.0316314361568217,
          0.0328470849342693,
          0.017290390430892078,
          0.026182496885388377,
          0.023159320913483758,
          0.027370029845016908,
          0.020598703990969885,
          0.024696212325472422,
          0.030770859287539143,
          0.026975750560708344,
          0.03565365457653906,
          0.023367532468136994,
          0.019381015514090195,
          0.030360742549000355,
          0.028179901016141994,
          0.03439502720433322,
          0.024756248679118756,
          0.03823256412170204,
          0.02710281461901233,
          0.033035355530639646,
          0.02869307309787401,
          0.02241282717992809,
          0.03202716829095825,
          0.03810831610860241,
          0.01584891647527412,
          0.025970978237332954,
          0.02041484490227975,
          0.029289690312536778,
          0.03454724935863995,
          0.022360496654813114,
          0.027633478753329763,
          0.04095704265548787,
          0.03247023584459491,
          0.02452942868439968,
          0.02974065122292765,
          0.03788915411831915,
          0.025376358830303664,
          0.018073338674567195,
          0.032976478701687344,
          0.028380778453255786,
          0.022240290864451694,
          0.039510800353891935,
          0.03223925335475347,
          0.02702610984663239,
          0.036540142983050125,
          0.020184546737926506,
          0.02415773192890391,
          0.023802549302447643,
          0.025265472077890427,
          0.021169698918859548,
          0.028937344151098568,
          0.01887317897780708,
          0.028138419971647167,
          0.023939397265747633,
          0.04303484531425294,
          0.008864709557911861,
          0.03076038853221638,
          0.026025620126056557,
          0.03463573289492096,
          0.023685104730928393,
          0.011856350437822611,
          0.02871659479938389,
          0.02091806379430389,
          0.03615032810003709,
          0.01631571825828317,
          0.0021293682619969254,
          0.004085281163714034,
          0.030644990034950373,
          0.041176526750700104,
          0.02632114605475799,
          0.02573442924394885,
          0.032495677619913205,
          0.022428667064084997,
          0.02785451847262078,
          0.0372684663817867,
          0.044756094552309875,
          0.03085308738488519,
          0.025496147089500813,
          0.035838554976556795,
          0.01880359700425137,
          0.0009422152236142553,
          0.02259619743862823,
          0.02805439739688625,
          0.03262646975694982,
          0.039352156248716325,
          0.025555717235570565,
          0.030115797974105685,
          0.028904648613090465,
          0.021605413008874436,
          0.024620880585902245,
          0.03098623447443302,
          0.027289966136569324,
          0.0003802501411358505,
          0.034553300941808605,
          0.03216658325386683,
          0.035973773060857174,
          0.034035040411609006,
          0.023384965695852085,
          0.019882912271687255,
          0.04204792611733706,
          0.030003451443303866,
          0.027035325628275448
         ],
         "xaxis": "x3",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          8,
          10,
          5,
          5,
          3,
          6,
          4,
          9,
          9,
          10,
          7,
          6,
          5,
          7,
          7,
          7,
          8,
          8,
          8,
          9,
          6,
          6,
          7,
          8,
          6,
          7,
          4,
          8,
          9,
          5,
          4,
          5,
          5,
          3,
          5,
          5,
          4,
          5,
          4,
          3,
          5,
          4,
          5,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          4,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          6,
          5,
          4,
          5,
          5,
          5,
          5,
          6,
          4,
          4,
          10,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          7,
          3,
          4,
          4,
          3,
          4,
          4,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          9,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          10,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          7,
          4,
          4,
          5,
          5,
          6,
          5,
          4,
          6,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          8,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          7,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          8,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          6,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          10,
          6,
          4,
          4,
          4,
          4,
          4,
          4,
          9,
          4,
          4,
          3,
          4,
          4,
          4
         ],
         "xaxis": "x4",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          7,
          2,
          5,
          2,
          4,
          6,
          2,
          6,
          4,
          9,
          9,
          1,
          4,
          3,
          4,
          3,
          3,
          1,
          1,
          1,
          3,
          3,
          2,
          2,
          1,
          2,
          10,
          5,
          1,
          7,
          7,
          7,
          8,
          7,
          8,
          8,
          8,
          6,
          7,
          9,
          6,
          7,
          8,
          7,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          4,
          4,
          4,
          6,
          4,
          4,
          6,
          5,
          5,
          5,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          1,
          1,
          1,
          2,
          2,
          2,
          1,
          2,
          1,
          3,
          2,
          1,
          3,
          3,
          2,
          3,
          2,
          2,
          3,
          1,
          3,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          6,
          2,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          1,
          2,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          1,
          2,
          2,
          2,
          3,
          2,
          2,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          10,
          1,
          1,
          1,
          1,
          2,
          1,
          2,
          1,
          3,
          2,
          2,
          1,
          1,
          2,
          10,
          10,
          9,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          8,
          10,
          8,
          10,
          10,
          10,
          10,
          8,
          8,
          8,
          7,
          9,
          7,
          9,
          8,
          8,
          8,
          8,
          7,
          8,
          8,
          10,
          9,
          9,
          8,
          9,
          9,
          9,
          10,
          9,
          9,
          9,
          9,
          9,
          8,
          2,
          2,
          9,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          6,
          4,
          3,
          3,
          3,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          3,
          4,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          5,
          3,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          3,
          3,
          2,
          4,
          2,
          2,
          3,
          2,
          3,
          2,
          3,
          2,
          2,
          2,
          3,
          2,
          4,
          3,
          3,
          2,
          2,
          2,
          3,
          2,
          3,
          2,
          2,
          4,
          3,
          2,
          3,
          2,
          2,
          5,
          2,
          3,
          2,
          2,
          3,
          2,
          2,
          3,
          3,
          2,
          4,
          2,
          3,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          3,
          3,
          3,
          3,
          3
         ],
         "xaxis": "x5",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          2,
          5,
          4,
          2,
          1,
          0,
          0,
          4,
          5,
          1,
          4,
          5,
          4,
          3,
          3,
          3,
          3,
          3,
          2,
          3,
          1,
          1,
          2,
          1,
          2,
          2,
          0,
          1,
          2,
          1,
          2,
          1,
          1,
          0,
          2,
          1,
          3,
          0,
          2,
          1,
          2,
          2,
          2,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          2,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          0,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          1,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          2,
          0,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5
         ],
         "xaxis": "x6",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4,
          1,
          4,
          3,
          4,
          1,
          5,
          0,
          1,
          1,
          5,
          2,
          3,
          2,
          4,
          2,
          2,
          2,
          3,
          0,
          2,
          2,
          2,
          3,
          1,
          2,
          3,
          1,
          2,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          0,
          1,
          0,
          1,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          1,
          1,
          5,
          1,
          1,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          4,
          4,
          5,
          4,
          4,
          4,
          5,
          3,
          3,
          3,
          3,
          4,
          4,
          3,
          4,
          4,
          5,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          3,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          2,
          2,
          5,
          5,
          2,
          2,
          2,
          5,
          5,
          2,
          2,
          2,
          5,
          2,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          2,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          3,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          0,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          1,
          5,
          5,
          5,
          5,
          5,
          5,
          5
         ],
         "xaxis": "x7",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8,
          0.9,
          0.4,
          0.5,
          1,
          1,
          0.1,
          0.9,
          0.8,
          1,
          0.30000000000000004,
          0.6,
          0.5,
          0.30000000000000004,
          0.30000000000000004,
          0.2,
          0.1,
          0.2,
          0.30000000000000004,
          0.2,
          0.6,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.4,
          0.6,
          0.5,
          0.8,
          0.8,
          0.7000000000000001,
          0.9,
          0.8,
          0.7000000000000001,
          0.9,
          0.8,
          0.7000000000000001,
          0.8,
          0.5,
          0.9,
          0.8,
          0.7000000000000001,
          0.9,
          0.9,
          1,
          1,
          0.9,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          0.9,
          1,
          0.9,
          1,
          1,
          1,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.8,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.6,
          0.8,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.8,
          0.6,
          0.7000000000000001,
          0.8,
          0.9,
          0.4,
          0.6,
          0.7000000000000001,
          0.9,
          0.9,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.8,
          0.8,
          0.9,
          0.8,
          0.9,
          0.8,
          0.9,
          0.8,
          0.7000000000000001,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.1,
          0.9,
          0.8,
          0.8,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.9,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.5,
          0.8,
          0.8,
          0.8,
          0.9,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.8,
          0.8,
          0.8,
          0.4,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.9,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.2,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.8,
          0.8,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.6,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.8,
          0.7000000000000001,
          0.8,
          0.6,
          0.7000000000000001,
          0.8,
          0.8,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.5,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.30000000000000004,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.5,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.4,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.6,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.2,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001,
          0.7000000000000001
         ],
         "xaxis": "x8",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y8"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184,
           185,
           186,
           187,
           188,
           189,
           190,
           191,
           192,
           193,
           194,
           195,
           196,
           197,
           198,
           199,
           200,
           201,
           202,
           203,
           204,
           205,
           206,
           207,
           208,
           209,
           210,
           211,
           212,
           213,
           214,
           215,
           216,
           217,
           218,
           219,
           220,
           221,
           222,
           223,
           224,
           225,
           226,
           227,
           228,
           229,
           230,
           231,
           232,
           233,
           234,
           235,
           236,
           237,
           238,
           239,
           240,
           241,
           242,
           243,
           244,
           245,
           246,
           247,
           248,
           249,
           250,
           251,
           252,
           253,
           254,
           255,
           256,
           257,
           258,
           259,
           260,
           261,
           262,
           263,
           264,
           265,
           266,
           267,
           268,
           269,
           270,
           271,
           272,
           273,
           274,
           275,
           276,
           277,
           278,
           279,
           280,
           281,
           282,
           283,
           284,
           285,
           286,
           287,
           288,
           289,
           290,
           291,
           292,
           293,
           294,
           295,
           296,
           297,
           298,
           299,
           300,
           301,
           302,
           303,
           304,
           305,
           306,
           307,
           308,
           309,
           310,
           311,
           312,
           313,
           314,
           315,
           316,
           317,
           318,
           319,
           320,
           321,
           322,
           323,
           324,
           325,
           326,
           327,
           328,
           329,
           330,
           331,
           332,
           333,
           334,
           335,
           336,
           337,
           338,
           339,
           340,
           341,
           342,
           343,
           344,
           345,
           346,
           347,
           348,
           349,
           350,
           351,
           352,
           353,
           354,
           355,
           356,
           357,
           358,
           359,
           360,
           361,
           362,
           363,
           364,
           365,
           366,
           367,
           368,
           369,
           370,
           371,
           372,
           373,
           374,
           375,
           376,
           377,
           378,
           379,
           380,
           381,
           382,
           383,
           384,
           385,
           386,
           387,
           388,
           389,
           390,
           391,
           392,
           393,
           394,
           395,
           396,
           397,
           398,
           399,
           400,
           401,
           402,
           403,
           404,
           405,
           406,
           407,
           408,
           409,
           410,
           411,
           412,
           413,
           414,
           415,
           416,
           417,
           418,
           419,
           420,
           421,
           422,
           423,
           424,
           425,
           426,
           427,
           428,
           429,
           430,
           431,
           432,
           433,
           434,
           435,
           436,
           437,
           438,
           439,
           440,
           441,
           442,
           443,
           444,
           445
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1.6,
          1.7000000000000002,
          1.4000000000000001,
          1.4000000000000001,
          1.8000000000000003,
          1.4000000000000001,
          1.2000000000000002,
          1.5,
          1.8000000000000003,
          1.7000000000000002,
          1.1,
          1.9,
          1.3,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.9,
          1.5,
          1.5,
          1.6,
          1.5,
          1.3,
          1.7000000000000002,
          1.8000000000000003,
          1.6,
          1.3,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.7000000000000002,
          1.6,
          1.4000000000000001,
          1.6,
          1.8000000000000003,
          1.5,
          1.4000000000000001,
          1.7000000000000002,
          1.4000000000000001,
          1.5,
          1.5,
          1.6,
          1.5,
          1.4000000000000001,
          1.5,
          1.5,
          1.5,
          1.4000000000000001,
          1.5,
          1.5,
          1.4000000000000001,
          1.5,
          1.3,
          1.4000000000000001,
          1.5,
          1.5,
          1.1,
          1.5,
          1.5,
          1.4000000000000001,
          1.5,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.7000000000000002,
          1.6,
          1.8000000000000003,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.5,
          1.6,
          1.6,
          1.5,
          1.7000000000000002,
          1.6,
          1.6,
          1.2000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.9,
          1.5,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.2000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.7000000000000002,
          1.6,
          1.8000000000000003,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.1,
          1.9,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.3,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.8000000000000003,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.2000000000000002,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.5,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.4000000000000001,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.5,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002,
          1.6,
          1.6,
          1.6,
          1.6,
          1.6,
          1.7000000000000002
         ],
         "xaxis": "x9",
         "y": [
          4.698616666666667,
          4.529419666666667,
          4.484123,
          4.891925333333333,
          5.629361,
          4.907066333333333,
          8.142830333333334,
          4.675372,
          5.686279,
          4.596403666666666,
          14.083874999999999,
          9.718005,
          5.390986333333333,
          4.162259333333333,
          4.250552666666667,
          4.246308,
          4.375980333333334,
          4.111476333333333,
          4.507167666666667,
          10.235527666666668,
          4.1687639999999995,
          4.129764000000001,
          4.122221,
          4.165924333333334,
          5.405981999999999,
          4.517424,
          5.687100333333333,
          4.143971,
          5.4569806666666665,
          4.098597333333333,
          4.484554666666667,
          4.1022,
          4.479205,
          4.552414,
          4.099261,
          4.493991,
          4.137225666666667,
          5.708537,
          4.113708333333333,
          4.480361333333334,
          4.475141666666667,
          4.490892333333334,
          4.134535333333333,
          4.096131333333333,
          4.071516333333332,
          4.0907116666666665,
          4.476628,
          4.092084666666667,
          4.089996999999999,
          4.088994666666667,
          5.142186,
          4.088658,
          4.089912333333333,
          4.469779333333334,
          4.089976333333333,
          5.378818333333334,
          4.4701976666666665,
          4.0930523333333335,
          4.093675,
          13.985302666666668,
          4.096526,
          4.089882,
          4.470149333333333,
          4.085809333333334,
          4.089357666666667,
          4.072710333333333,
          4.076485333333333,
          4.069543666666667,
          4.0750443333333335,
          4.469779,
          4.074683666666666,
          4.074247333333333,
          4.067977333333334,
          4.075503,
          4.072949333333334,
          4.458478666666667,
          4.070968333333333,
          4.458266666666667,
          4.067475333333333,
          4.0779749999999995,
          4.460929333333333,
          4.070731333333334,
          4.073409,
          4.0731633333333335,
          4.073756333333333,
          4.467149,
          4.078147333333334,
          4.457837333333333,
          4.071631,
          5.730411,
          4.071095333333333,
          4.079974,
          4.077289,
          4.07861,
          4.462472333333333,
          4.066834,
          4.463488333333333,
          4.073118,
          4.081809,
          4.457236666666667,
          4.071967333333333,
          4.072442,
          4.071829,
          4.071766333333334,
          4.073298,
          4.071086333333334,
          4.073871,
          4.460986,
          4.075258666666667,
          4.083212333333333,
          4.402158333333333,
          4.074976333333333,
          4.067860333333333,
          4.073541333333334,
          4.502844,
          4.071719666666667,
          4.090704666666666,
          4.070059666666666,
          4.0763506666666665,
          4.093697333333334,
          4.465408,
          4.068421333333333,
          4.070299666666666,
          7.444328333333334,
          4.067528666666667,
          4.069398666666667,
          4.0677449999999995,
          4.068613333333333,
          4.070232333333333,
          4.457474333333333,
          4.67383,
          4.070739666666667,
          4.070394,
          4.068184333333334,
          4.072148666666667,
          4.066863000000001,
          4.105512333333333,
          4.4626280000000005,
          4.0713593333333336,
          4.095272333333334,
          4.072355333333333,
          4.072936333333334,
          4.077054333333334,
          4.0718776666666665,
          4.067004,
          4.0703293333333335,
          4.067968333333334,
          4.088225666666666,
          4.073559333333333,
          4.068256000000001,
          4.069527666666667,
          4.069096333333333,
          4.069994333333333,
          4.07012,
          4.074176666666667,
          4.0727839999999995,
          4.072206666666666,
          4.0727736666666665,
          4.213536666666666,
          4.471213666666666,
          4.069652666666666,
          4.079228333333333,
          4.074811333333334,
          4.074245333333334,
          4.0832006666666665,
          4.076877666666666,
          4.069998333333333,
          9.660130666666667,
          4.0934843333333335,
          4.4579173333333335,
          4.070577,
          4.069932333333333,
          4.070726666666666,
          4.072860666666666,
          4.072372333333333,
          4.068939333333334,
          4.074708333333333,
          4.0682583333333335,
          4.069516,
          4.069285333333333,
          4.073483333333333,
          4.069508333333333,
          4.0725620000000005,
          4.071453333333333,
          4.074102,
          4.071186,
          4.068803666666667,
          4.074237,
          4.068755666666666,
          4.071222,
          4.087925333333334,
          4.0738883333333336,
          4.076549666666667,
          4.075304666666667,
          4.092667333333334,
          4.067420666666667,
          4.071698,
          4.070767333333333,
          4.125525,
          4.068494666666666,
          4.073098333333333,
          4.074614,
          4.067235666666667,
          4.07223,
          4.083485666666667,
          4.074585,
          4.0705946666666675,
          4.0762453333333335,
          4.069685,
          4.086050333333334,
          4.466237333333334,
          4.071212,
          4.070579333333334,
          4.069756,
          4.0691999999999995,
          4.06907,
          4.073708333333333,
          4.067969000000001,
          4.070293,
          4.1018273333333335,
          7.437712,
          4.070443666666667,
          4.070270333333333,
          4.0701496666666666,
          4.071000000000001,
          4.072090666666667,
          4.0690273333333336,
          4.068214666666667,
          4.067797666666666,
          4.088124333333333,
          4.074686333333333,
          4.067980333333334,
          4.0667393333333335,
          4.068994666666667,
          4.070668,
          4.068904666666667,
          4.069079666666667,
          4.0742606666666665,
          4.069377,
          4.074154333333333,
          4.071959,
          4.067412,
          4.069099333333333,
          4.067670333333333,
          4.066742333333333,
          4.067716333333333,
          4.067531,
          4.066033333333333,
          4.070635666666667,
          4.066388666666667,
          4.069709333333333,
          4.08771,
          4.066620333333333,
          4.066198,
          4.066810333333334,
          4.068776,
          4.066674666666667,
          4.0675859999999995,
          4.0685986666666665,
          4.067131,
          4.066264666666666,
          4.067319666666666,
          4.06928,
          4.0673319999999995,
          4.455328333333333,
          4.069990333333333,
          4.068262666666667,
          4.069815333333334,
          4.072740666666667,
          4.068342666666666,
          4.086218333333333,
          4.069109999999999,
          4.456228,
          4.0676060000000005,
          5.624516333333333,
          4.066416,
          4.087945666666667,
          4.066721,
          4.069355666666667,
          4.072534,
          4.071238666666667,
          4.068472333333333,
          4.065639333333333,
          4.069144666666666,
          4.072129333333334,
          4.070752333333334,
          4.068134333333333,
          4.4557649999999995,
          4.066105333333334,
          4.069430333333333,
          4.086610666666666,
          4.070375333333334,
          4.067635,
          4.068840000000001,
          4.074186,
          4.066934,
          4.068200999999999,
          4.458339333333334,
          4.068364666666667,
          4.068200666666667,
          4.069994333333334,
          4.070021333333333,
          4.071339333333333,
          4.098061666666666,
          4.094301000000001,
          4.067229666666667,
          4.067069333333333,
          4.067382666666667,
          4.067816,
          4.068025666666666,
          4.068339333333333,
          4.0666813333333325,
          4.067433666666666,
          4.09232,
          4.456171666666666,
          4.069722666666666,
          4.072026,
          4.069576666666666,
          4.068978333333333,
          4.088065333333333,
          4.067908,
          4.069356,
          4.6806676666666664,
          4.067927,
          4.066147,
          4.06835,
          13.988521666666665,
          9.661821333333334,
          4.066895,
          4.453372666666667,
          4.068653333333334,
          4.070576333333333,
          4.069154666666667,
          4.066180666666667,
          4.065873333333333,
          4.068615666666667,
          4.065794333333334,
          4.089444,
          4.065369333333333,
          4.066506666666666,
          4.067915,
          4.315801,
          4.073887,
          4.949645333333333,
          4.454962666666667,
          4.067209666666667,
          5.3760650000000005,
          4.065304,
          4.0708036666666665,
          4.455582,
          4.068402333333332,
          4.068685666666667,
          4.067780666666667,
          4.091335999999999,
          4.0671539999999995,
          4.074663666666667,
          4.0700639999999995,
          4.068776333333333,
          5.635857333333334,
          4.068601666666667,
          4.0689296666666666,
          4.070598,
          4.066771,
          4.067567333333333,
          7.440157333333334,
          4.068698666666666,
          4.0693746666666675,
          4.085524,
          4.069774,
          4.068225666666667,
          4.069421,
          4.068454666666667,
          4.068015,
          4.457323333333334,
          4.069418,
          4.070246666666667,
          4.067884666666667,
          4.086629666666667,
          4.06768,
          4.092844333333333,
          4.068103,
          4.0695456666666665,
          4.0685883333333335,
          4.067406666666667,
          4.068065666666667,
          4.077914333333333,
          4.0683576666666665,
          4.073859666666666,
          4.070524333333334,
          4.072548666666666,
          4.066690333333333,
          4.459581666666666,
          4.0868150000000005,
          4.460134,
          4.067767333333333,
          4.070903333333334,
          4.068199666666667,
          4.068331333333333,
          4.069571,
          4.068460333333333,
          4.069646666666666,
          4.067849333333334,
          4.069439333333333,
          4.069905666666666,
          4.068645,
          4.470504333333333,
          4.070861000000001,
          4.069050666666667,
          4.075488,
          4.4938226666666665,
          4.090124666666667,
          4.067603666666667,
          4.070681,
          4.065239666666667,
          4.067373666666667,
          4.069116333333334,
          4.068847333333333,
          4.067401,
          4.089253333333333,
          4.068288666666667,
          4.067389666666666,
          4.067055,
          4.067597666666667,
          4.071429333333334,
          4.226528000000001,
          4.068693666666667,
          4.454910666666667,
          4.068852333333333,
          4.067875666666667,
          4.072396,
          4.066689,
          4.081170333333333,
          4.073924333333333,
          4.069769,
          4.089268666666666,
          4.088464,
          4.509804666666667,
          4.065934333333334,
          4.088062333333333,
          4.473897333333333,
          4.068026666666667,
          4.068908666666666,
          4.069972666666667,
          4.069332,
          4.067267999999999,
          4.456298
         ],
         "yaxis": "y9"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 2700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.09135802469135802
         ],
         "title": {
          "text": "colsample_bytree"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.11358024691358025,
          0.20493827160493827
         ],
         "title": {
          "text": "gamma"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.2271604938271605,
          0.31851851851851853
         ],
         "title": {
          "text": "learning_rate"
         },
         "type": "log"
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.34074074074074073,
          0.43209876543209874
         ],
         "title": {
          "text": "max_depth"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.454320987654321,
          0.5456790123456791
         ],
         "title": {
          "text": "min_child_weight"
         }
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.5679012345679012,
          0.6592592592592592
         ],
         "title": {
          "text": "reg_alpha"
         }
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.6814814814814815,
          0.7728395061728395
         ],
         "title": {
          "text": "reg_lambda"
         }
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.7950617283950617,
          0.8864197530864197
         ],
         "title": {
          "text": "subsample"
         }
        },
        "xaxis9": {
         "anchor": "y9",
         "domain": [
          0.908641975308642,
          1
         ],
         "title": {
          "text": "tweedie_variance_power"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis9": {
         "anchor": "x9",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "max_depth (IntDistribution): 4.824864923096744e-05<extra></extra>",
          "reg_alpha (IntDistribution): 7.020548982996207e-05<extra></extra>",
          "gamma (IntDistribution): 8.337598807289724e-05<extra></extra>",
          "reg_lambda (IntDistribution): 0.00010575539854086815<extra></extra>",
          "colsample_bytree (FloatDistribution): 0.0006638953746196201<extra></extra>",
          "min_child_weight (IntDistribution): 0.0010638404901373484<extra></extra>",
          "learning_rate (FloatDistribution): 0.0012794142790057575<extra></extra>",
          "subsample (FloatDistribution): 0.003849675411357393<extra></extra>",
          "tweedie_variance_power (FloatDistribution): 0.9928355889192053<extra></extra>"
         ],
         "marker": {
          "color": "rgb(66,146,198)"
         },
         "orientation": "h",
         "text": [
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "<0.01",
          "0.99"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.00004824864923096744,
          0.00007020548982996207,
          0.00008337598807289724,
          0.00010575539854086815,
          0.0006638953746196201,
          0.0010638404901373484,
          0.0012794142790057575,
          0.003849675411357393,
          0.9928355889192053
         ],
         "y": [
          "max_depth",
          "reg_alpha",
          "gamma",
          "reg_lambda",
          "colsample_bytree",
          "min_child_weight",
          "learning_rate",
          "subsample",
          "tweedie_variance_power"
         ]
        }
       ],
       "layout": {
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Importance for Objective Value"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'eta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Work\\WORK_PACKAGE\\Demand_forecasting\\BLUESG_Demand_data\\Data-preprocessing_data_generation\\xgboost-regressor\\xgb_all_stns_CLSTR_regressor.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m fig\u001b[39m.\u001b[39mshow()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m best_tweedie_variance_power \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mtweedie_variance_power\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m best_params \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meta\u001b[39m\u001b[39m\"\u001b[39m: study\u001b[39m.\u001b[39;49mbest_params[\u001b[39m\"\u001b[39;49m\u001b[39meta\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m\"\u001b[39m : study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m\"\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39meval_metric\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mtweedie-nloglik@\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(best_tweedie_variance_power), \u001b[39m## try using AUC as well.. \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtweedie_variance_power\u001b[39m\u001b[39m'\u001b[39m: best_tweedie_variance_power,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreg_alpha\u001b[39m\u001b[39m'\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mreg_alpha\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreg_lambda\u001b[39m\u001b[39m'\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mreg_lambda\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m'\u001b[39m: study\u001b[39m.\u001b[39mbest_params[\u001b[39m\"\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mreg:tweedie\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m early_stopping_rounds \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/BLUESG_Demand_data/Data-preprocessing_data_generation/xgboost-regressor/xgb_all_stns_CLSTR_regressor.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m eval_metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtweedie-nloglik@\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(best_tweedie_variance_power)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'eta'"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, timeout=12000, n_trials=500)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    #print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "    fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_slice(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()\n",
    "\n",
    "    best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "    best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "            \"eta\": study.best_params[\"eta\"],\n",
    "            \"subsample\" : study.best_params[\"subsample\"],\n",
    "            \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "            'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "            'tweedie_variance_power': best_tweedie_variance_power,\n",
    "            'gamma': study.best_params[\"gamma\"],\n",
    "            'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "            'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "            'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "            \"objective\": 'reg:tweedie',\n",
    "            }\n",
    "    early_stopping_rounds = 30\n",
    "    eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "    num_round= 1000\n",
    "\n",
    "    t_v_t = train_validate_n_test()\n",
    "    best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "    t_v_t.evaluate_predictions(best_model)\n",
    "\n",
    "    # t_v_t.display_tweedie_plot() # compare the graphs from target histogram and this function to choose tweedie_variance_power \n",
    "    # X_test,label_test, preds = t_v_t.evaluate_predictions()\n",
    "    # t_v_t.visualize_tree()\n",
    "    # # print('\\n',\"tweedie_variance_power \",tweedie_variance_power,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "####################################### PREDICTION #################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi3UlEQVR4nO3deZwdVZ338c+3lyyQsKbZshCWiLJGaBMQRogKhkUijs88rCKikRlQGGd0goOKz6MzOI7OGIGBiAwoAqPDIpqw6bCqQDoQlrAlQoQQJM2WRbJ18ps/qjq56a57u7rT1bfT9/t+ve4rt845VfXrc2/611Wnqo4iAjMzs47qqh2AmZn1T04QZmaWyQnCzMwyOUGYmVkmJwgzM8vUUO0AetOIESNi7Nix1Q7DzGyLMWfOnNcjoimrbkAliLFjx9LS0lLtMMzMthiS/liuzqeYzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDIVliAkjZZ0j6RnJM2TdH5GG0maLmmBpCckHVxSN1nSc2ndtKLi7G1Llq3ir678PUuWr6p2KH1uybJVHPNv97HHtJlM/vf7O/XBg/Nb2XPaTD783Xv50HfvYey0mYydNpNfPfFKp3Z7XTiTL//33A1tstq1u+6hhYydNpN3/eMsTvjBA532u2TZKj522W854QcPcNLlvy372bTv9zt3PsPYaTN591dv5+lXl2Zu60PfvYc9L5zJgwtaK/bJ04uXcsDX7+y0nbz1pd+n3v5u1fJ3taeq0WfV/JyKPIJoA/4uIt4DHAqcK2nfDm2OBcalr6nAfwBIqgcuS+v3BU7JWLdfmv6b+cxe+CbTfz2/2qH0uem/mc/zr60ggGf/tLxTH/zNTx9lPbCg9c/8ofWdDeV/+1+Pd2q3LuBnLZsmhI7t2n311nkArFkXPPXKsk77nf6b+cx9+W2eemUZj730dtnPpn2/l93zAgCr1q7n/BvmZm7rD63vsD7gb657NHNb7c6/cS7LV7d12k7e+tLvU29/t2r5u9pT1eizan5O6qvHfUv6BXBpRNxdUnYlcG9E3JAuPwccBYwFLo6Ij6TlFwJExD9X2kdzc3NU6z6IfS66ndVt6zuVD26o47lvHluFiPpOuZ+9SAsvOZ6x02Zu1jbaP5vN3U5pTO0qbbOr2BdecnyuPu3pd6uWv6s9VY0+66t9SpoTEc1ZdX0yBiFpLPBe4OEOVSOBl0uWF6Vl5cqztj1VUoukltbWyof7RXrgy5M4cfxuDGlMunRIYx1Txu/GA/8wqWox9ZUHvjyJQ/fcIbPu/XvtyA9OGc+QhspfNQnOnbQnQxvrK7cDLj11PADf/Nh+ZdsdtU8Ts75wBMfstzPqUFcnmLzfzhs+m+vOnlBxvzts3ch1n5nAMfvtnFk/pLGO6z4zYZOyWV84gpHbDd2kbNR2Q5l1/hG56jt+n+oE9dq4v835btXyd7WnqtFn/eFzKjxBSBoG3ARcEBHLOlZnrBIVyjsXRsyIiOaIaG5qyrxbvE/stM0Qhg9uYHXbegY31LG6bT3DBzew0/AhVYupr+y0zRD2ahqWWbfniK356EEjGdRFgmioE1/6yHtorM/66Eva1YsTDkz+Vjj90LGZXxRIftnuu9u2NA0b3OmLsz5gxLDBGz6bI8Y1VdzvjlsP5oi9m2gaNjizflB9HUfsvel3b9/dtmWrQZsmnaGD6tl3121z1Xf8Pq0PWBf0ynerlr+rPVWNPusPn1Ohj9qQ1EiSHH4aETdnNFkEjC5ZHgUsBgaVKe/XXl+xmtMm7s6pE8Zw/SMv0VpDg3+vr1hNnZIjge2GDuLtd9YQQOuK1QCsaltPQ53YenA9S1e2dVq/bX1saLft0IbMNqXt2rUv1dfBuvRofEhj3Yb9vr5iNaO3H8qadesZ0lDPqrXrGNSwsb5d1n7rlfxSXrpy7SbbeuXtldQJthrUwDtr2lhV5lTQ0pVredfOw/jCB8cx/X/m8/Y7a7tVX/p9+txPklOnV57R3CvfrVr+rvZUNfqs2p9TYWMQkgRcC7wZEReUaXM8cB5wHDARmB4REyQ1AM8DHwJeAWYDp0bEvEr7rOYYhJnZlqjSGESRRxCHA2cAT0qam5Z9BRgDEBFXALNIksMC4B3grLSuTdJ5wJ1APXB1V8nBzMx6V2EJIiIeJHssobRNAOeWqZtFkkDMzKwKfCe1mZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwsU2ETBkm6GjgBWBIR+2fUfwk4rSSO9wBNEfGmpIXAcmAd0FZuOjwzMytOkUcQ1wCTy1VGxHciYnxEjAcuBO6LiDdLmkxK650czMyqoLAEERH3A2922TBxCnBDUbGYmVn3VX0MQtJWJEcaN5UUB3CXpDmSpnax/lRJLZJaWltbiwzVzKymVD1BAB8Fftvh9NLhEXEwcCxwrqQPlFs5ImZERHNENDc1NRUdq5lZzegPCeJkOpxeiojF6b9LgFuACVWIy8ysplU1QUjaFjgS+EVJ2daShre/B44BnqpOhGZmtavIy1xvAI4CRkhaBHwdaASIiCvSZicBd0XEn0tW3Rm4RVJ7fNdHxB1FxWlmZtkKSxARcUqONteQXA5bWvYCcFAxUZmZWV79YQzCzMz6IScIMzPL5ARhZmaZcieI9Oqi+iKDMTOz/qNsgpBUJ+lUSTMlLQGeBV6VNE/SdySN67swzcysr1U6grgH2IvkQXq7RMToiNgJ+AvgIeASSaf3QYxmZlYFlS5z/XBErO1YmD4S4ybgJkmNhUVmZmZVVTZBlCaHdOxh59L2EfFSVgIxM7OBocsb5SR9nuQu6NeA9WlxAAcWGJeZmVVZnjupzwf2iYg3ig7GzMz6jzyXub4MLC06EDMz61/yHEG8ANwraSawur0wIr5XWFRmZlZ1eRLES+lrUPoyM7Ma0GWCiIhvAKRzNERErCg8KjMzq7ouxyAk7S/pMZJJe+al80TvV3xoZmZWTXkGqWcAX4yI3SNid+DvgB8WG5aZmVVbngSxdUTc074QEfcCW3e1kqSrJS2RlDldqKSjJC2VNDd9fa2kbrKk5yQtkDQtR4xmZtbLcl3FJOmrwE/S5dOBF3Osdw1wKfDjCm0eiIgTSgvSu7YvA44GFgGzJd0WEU/n2KeZmfWSPEcQnwaagJuBW9L3Z3W1UkTcD7zZg5gmAAsi4oWIWAPcCEzpwXbMzGwz5LmK6S3gCwXt/zBJjwOLgb+PiHnASJKb89otAiaW24CkqcBUgDFjxhQUpplZ7SmbICT9e0RcIOmXJM9e2kREnLiZ+34U2D0iVkg6DrgVGAcoo22n/ZfEMYNkIJ3m5uay7czMrHsqHUG0jzn8axE7johlJe9nSbpc0giSI4bRJU1HkRxhmJlZH6r0uO856dvxEfH90jpJ5wP3bc6OJe0CvBYRIWkCyXjIG8DbwDhJewCvACcDp27OvszMrPvyDFKfmVH2qa5WknQD8HtgH0mLJJ0t6RxJ56RNPgE8lY5BTAdOjkQbcB5wJ/AM8LN0bMLMzPpQpTGIU0j+ct9D0m0lVcNJ/tKvKCJO6aL+UpLLYLPqZgGzutqHmZkVp9IYxO+AV4ERwHdLypcDTxQZlJmZVV+lMYg/An+UdBqwOCJWAUgaSjJwvLBPIjQzs6rIMwbxMzZONQqwDvh5MeGYmVl/kSdBNKR3NAOQvve8EGZmA1yeBNEqacNNcZKmAK8XF5KZmfUHeR7Wdw7wU0mXktzl/DLwyUKjMjOzqsvzLKY/AIdKGgYoIpYXH5aZmVVbpfsgTo+I6yR9sUM5ABHxvYJjMzOzKqp0BNE+KdDwvgjEzMz6l0r3QVyZ/vuNvgvHzMz6i0qnmKZXWjEiipojwszM+oFKl7nOSV9DgIOB+elrPMnNcmZmNoBVOsV0LYCkTwGTImJtunwFcFefRGdmZlWT50a53dh0oHpYWmZmZgNYnhvlLgEek3RPunwkcHFhEZmZWb+Q50a5/5R0OzAxLZoWEX/qaj1JVwMnAEsiYv+M+tOAf0gXVwB/HRGPp3ULSR4rvg5oi4jmHD+LmZn1oi5PMSm5M+7DwEER8QtgUDpFaFeuASZXqH8RODIiDgT+PzCjQ/2kiBjv5GBmVh15xiAuBw4D2meIWw5c1tVKEXE/8GaF+t9FxFvp4kMkc0yYmVk/kSdBTIyIc4FVAOkv9d5+3PfZwO0lywHcJWmOpKmVVpQ0VVKLpJbW1tZeDsvMrHblGaReK6me5Jc2kprYdAKhzSJpEkmCOKKk+PCIWCxpJ+BuSc+mRySdRMQM0tNTzc3N0VtxmZnVujxHENOBW4CdJH0LeBD4p97YuaQDgauAKRHxRnt5RCxO/12S7jvPmIeZmfWiikcQkupIBpO/DHyIZD6Ij0XEM5u7Y0ljgJuBMyLi+ZLyrYG6iFievj8G+H+buz8zM+ueigkiItZL+m5EHAY8250NS7oBOAoYIWkR8HWgMd3uFcDXgB2By9NHiLdfzrozcEta1gBcHxF3dGffZma2+fKMQdwl6S+BmyMi9zn+iDili/rPAJ/JKH8BOCjvfszMrBh5EsQXSeaGWCdpVVoWEbFNcWGZmVm15bmT2hMGmZnVoDxHEEj6OMllqAE8EBG3FhmUmZlVX55HbVwOnAM8CTwFnCOpyzupzcxsy5bnCOJIYP/2AWpJ15IkCzMzG8Dy3Cj3HDCmZHk08EQx4ZiZWX+R5whiR+AZSY+ky+8Dfi/pNoCIOLGo4MzMrHryJIivFR6FmZn1O2UThCRF4r5KbYoJy8zMqq3SGMQ9kj6fPjNpA0mDJH0wHaw+s9jwzMysWiqdYpoMfBq4QdIewNvAEKAeuAv4t4iYW3SAZmZWHWUTRESsIplN7nJJjcAIYGVEvN1HsZmZWRXlupM6ItYCrxYci5mZ9SN57oMwM7Ma5ARhZmaZciUISbtL+nD6fqgkP+HVzGyA63IMQtJnganADsBewCjgCpIpSCutdzVwArAkIvbPqBfwfeA44B3gUxHxaFo3Oa2rB66KiEu68TP12NOLl/Lxy3/LqragAWgr0+7k5pHc2PJKl9trrIP162FdhTb/dNJ+jB+9Pf/3yof4y0N245rfvZTZbtdtBvPqstVlt9NQB3vtNIzG+joa6+u48oxDuGnOy3z7juc3abfj1o3cfsEH2Gn4EB6c38rpP3pkk/rthzbw1so26knibqyDtes772/sDkMZPKieRW+t5MLj3s1Ft8wrG9u3TtqPHz3wIi+8/k7ZNgDv3mU4H3p3E5fd+0LZNv900n6cOnEsAJ+99hHufqa1U5sGwbt324bjD9il089f6uT3jeSSvxy/YfniXzzJNb/v3P+XnjqeEw4cyZJlqzjp8t/yyturOrVpN7hetK2LTp/58CH1/NfUw7j4l09zxqFj+PwNczepF8mjkoc21vPDMw/hKzc/yUtvrtxQv/3QRt5aubZTTN+545mK/QVJv/747AncNe9PXHRr58+padggZp7/F7y+fDUfu/RB1qSf96B6WLsuiQs27XuA6x5ayEW3zmP44HqWr974E7fHBnT6jh0yehvmvLxsw3K571djnfjPT7+P6b9ZwKWnvpfXl6/mxOkPbvg/WQe0rzZ2h6G8tmI1u207hJfeeGfD9krbCPjJZybw5KK3+fYdzzO4XlxwzDi+ffum34+9m7bm+qmHQsBZ18xm/mvLWLNu4zbOfP8YrvndS0w79l3c8dQSXnnrHVpXrKGxDvbZdRumTX43Z139CGsDLjz2XXzuyHEbtv304qVM+cGDrO0w7Vrp9/DB+a188kePMGaHoSxeunLDvj+ybxN3Pt3KuZP25LJ7ks97SEMdQxrreHtlW6d+7y3qapI4SXOBCcDDEfHetOzJiDigi/U+AKwAflwmQRwHfJ4kQUwEvh8REyXVA88DRwOLgNnAKRHxdFc/THNzc7S0tHTVrKyjv3cf85es6PH6PSFg752G9fp+T584husezk42p08cwzdPOoADL76TZavKpcH82n+59bS+u/t68ZLjARg7beZmb29huq1K22usF/O/dRwX3fJk2T7NY9xOw1jQuoKGOrF2Xfke2WZIQ5efS3tMefvg9Ilj+OnDL5X9HE6fOIaHX3yz4vewtO8B9pg2M3N77bEBm/Ud22ZIA8tXt3HahK5jy7u9PLGcPjG59asnn3XHfZR+vyr9fmlvtzn9Vdrv3SFpTjrdc+e6HAni4fQX92MR8V5JDcCjEXFgjh2PBX5VJkFcCdwbETeky8+RzGE9Frg4Ij6Sll8IEBH/3NX+epogeuMXjZlZf1GamLpSKUHkGYO4T9JXgKGSjgZ+Dvwy997LGwm8XLK8KC0rV55J0lRJLZJaWls7n27IY9YXjmCHrQb1aF3b8u09Ymi1Q9iinHjgLrna1Rccx5bi0+8fw7DBXfdGb10xdOmp43tpS/limga0kswB8TlgFnBRL+w76zlOUaE8U0TMiIjmiGhuamrqUSD77rYtOw6rrQTRWL/lPkartyP/9d9/sM/3uaUSMP3UQ7rsj8Z6sfWQXLdZdbm/Ld3XTjyAXbft+o+QYb3QX4316tVxiDxzUq8Hfpi+etMikrkl2o0CFgODypQXamnJAOCWrE7QNGwwry0vP6AN0La+t0YF+l41Iu/NMZQtt+c3xt7Vz9C2PljVljH63E3bbdXIqrXrWJk1kt1DWw2q4501lbdXJ9ic/yJbNdTxTsnPn+f3y6q29TTUJSmxp/8/e/v/dZ4xiBfJ+D5ExJ5dbrzyGMTxwHlsHKSeHhET0jGO50muknqFZJD61Igof5lManMHqc3Mak2lMYg8xzSlKw4B/g/JJa9d7fQGkkHnEZIWAV8HGgEi4gqSU1XHAQtILnM9K61rk3QecCfJacyr8yQHMzPrXV0eQWSuJD0YEUcUEM9m8RGEmVn3bNYRhKSDSxbrSI4ofCe1mdkAl+cU03dL3rcBC4G/KiQaMzPrN/JcxTSpLwIxM7P+pdKc1F+stGJEfK/3wzEzs/6i0hGExxnMzGpYpSlHv9GXgZiZWf+S5yqmIcDZwH4k90EAEBGfLjAuMzOrsjzPYvoJsAvwEeA+kkdfLC8yKDMzq748CWLviPgq8OeIuBY4Hqg4F4SZmW358iSI9qdMvS1pf2BbkjkbzMxsAMtzo9wMSdsDXwVuA4al783MbADLkyD+MyLWkYw/dPkEVzMzGxjynGJ6UdIMSR+SNBDm7zAzsxzyJIh9gF8D5wILJV0qqd89ydXMzHpXlwkiIlZGxM8i4uPAeGAbktNNZmY2gOWaJ1vSkZIuBx4luVnOT3M1Mxvg8txJ/SIwF/gZ8KWI+HPejUuaDHyfZGa4qyLikg71XwJOK4nlPUBTRLwpaSHJDXnrgLZyE1qYmVkx8lzFdFBELOvuhiXVA5cBRwOLgNmSbouIp9vbRMR3gO+k7T8K/G1EvFmymUkR8Xp3921mZpsvzxhEt5NDagKwICJeiIg1wI3AlArtTwFu6OG+zMysl+Uag+ihkcDLJcuL0rJOJG0FTAZuKikO4C5JcyRNLbcTSVMltUhqaW1t7YWwzcwMik0QWfdMRJm2HwV+2+H00uERcTBwLHCupA9krRgRMyKiOSKam5qaNi9iMzPboMgZ5RYBo0uWRwGLy7Q9mQ6nlyJicfrvEkm3kJyyur+LfZqZWS+pdAQxPH01A39NcnpoJHAOsG+Obc8GxknaQ9IgkiRwW8dGkrYFjgR+UVK2taTh7e+BY4Cn8vxAZmbWO7qcUU7SXcDBEbE8Xb4Y+HlXG46INknnAXeSXOZ6dUTMk3ROWn9F2vQk4K4Ol8/uDNySPtmjAbg+Iu7o5s9mZmabIc9lrmOANSXLa8j5uO+ImAXM6lB2RYfla4BrOpS9AByUZx9mZlaMPAniJ8Aj6ThAkPzF/+NCozIzs6rrMkFExLck3QG0P6DvrIh4rNiwzMys2vIcQUDyqI1X29tLGhMRLxUVlJmZVV+eZzF9Hvg68BrJc5FEcqrpwGJDMzOzaspzBHE+sE9EvFF0MGZm1n/kuZP6ZWBp0YGYmVn/kucI4gXgXkkzgdXthTnupDYzsy1YngTxUvoalL7MzKwG5LnM9Rt9EYiZmfUvea5iagK+DOxHMt0oABHxwQLjMjOzKsszSP1T4FlgD+AbwEKSB/GZmdkAlidB7BgRPwLWRsR9EfFp4NCC4zIzsyrLM0i9Nv33VUnHk8zpMKq4kMzMrD/IkyC+mc7Z8HfAD4BtgL8tNCozM6u6PFcx/Sp9uxSYVGw4ZmbWX3Q5BpHOCPc9STdLuq39lWfjkiZLek7SAknTMuqPkrRU0tz09bW865qZWbHynGK6FfgR8Etgfd4NS6oHLgOOJpmferak2yLi6Q5NH4iIE3q4rpmZFSRPglgVEdN7sO0JwIJ0djgk3QhMAfL8kt+cdc3MrBfkucz1+5K+LukwSQe3v3KsN5LkQX/tFqVlHR0m6XFJt0var5vrImmqpBZJLa2trTnCMjOzPPIcQRwAnAF8kI2nmCJdrkQZZdFh+VFg94hYIek4ktNZ43KumxRGzABmADQ3N2e2MTOz7suTIE4C9oyINd3c9iJgdMnyKJJ7KDaIiGUl72dJulzSiDzrmplZsfKcYnoc2K4H254NjEuvghoEnAxscvWTpF0kKX0/IY3njTzrmplZsfIcQewMPCtpNpvOB3FipZUiok3SecCdQD1wdUTMk3ROWn8F8AngryW1ASuBkyMigMx1u//jmZlZTyn5fVyhgXRkVnlE3FdIRJuhubk5Wlpaqh2GmdkWQ9KciGjOqstzJ/V9knYHxkXEryVtRfJXvZmZDWB57qT+LPDfwJVp0UiSq43MzGwAyzNIfS5wOLAMICLmAzsVGZSZmVVfngSxuvQSV0kNlLknwczMBo48CeI+SV8Bhko6Gvg5yXOZzMxsAMuTIKYBrcCTwOeAWcBFRQZlZmbVl+cqpvWSbgVujQg/7MjMrEaUPYJQ4mJJrwPPAs9Jai2ds8HMzAauSqeYLiC5eul9EbFjROwATAQOl+QpR83MBrhKCeKTwCkR8WJ7QTo/w+lpnZmZDWCVEkRjRLzesTAdh2gsLiQzM+sPKiWISo/37u6jv83MbAtT6SqmgyQtyygXMKSgeMzMrJ8omyAiwg/kMzOrYXlulDMzsxrkBGFmZpkKTRCSJkt6TtICSdMy6k+T9ET6+p2kg0rqFkp6UtJcSZ4FyMysj+WZcrRHJNUDlwFHA4uA2ZJui4inS5q9CBwZEW9JOhaYQXIzXrtJWZfamplZ8Yo8gpgALIiIF9LHhd8ITCltEBG/i4i30sWHgFEFxmNmZt1QZIIYCbxcsrwoLSvnbOD2kuUA7pI0R9LUcitJmiqpRVJLa6ufJWhm1lsKO8VEcr9ER5kTDUmaRJIgjigpPjwiFkvaCbhb0rMRcX+nDUbMIDk1RXNzsycyMjPrJUUeQSwCRpcsjwIWd2wk6UDgKmBKRLzRXh4Ri9N/lwC3kJyyMjOzPlJkgpgNjJO0h6RBwMnAbaUNJI0BbgbOiIjnS8q3ljS8/T1wDPBUgbGamVkHhZ1iiog2SecBdwL1wNURMU/SOWn9FcDXgB2ByyUBtEVEM7AzcEta1gBcHxF3FBWrmZl1poiBc9q+ubk5Wlp8y4SZWV6S5qR/mHfiO6nNzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZCptRDkDSZOD7JDPKXRURl3SoV1p/HPAO8KmIeDTPur3ps9c+wt3PtBa1+UwH7jqMJ15d0af77AsC/mLvHbh/wZsV2w2qgzXru97ebtsO4aozmzn1hw/x9sq2zDa7bjOYV5etpgHIbtF97dssZ2gjrFybb1vbD63nrZXreikys2wXHvsuPnfkuF7dZmFHEJLqgcuAY4F9gVMk7duh2bHAuPQ1FfiPbqzba/o6OQADMjkABHSZHCBfcgBYvHQV5984t2xyADb8Iu+t5FC6zXLyJgfAycH6xD/f/nyvb7PII4gJwIKIeAFA0o3AFODpkjZTgB9HMu/pQ5K2k7QrMDbHuptt7LSZvbk5K8j8JQMzmZr1tvbfaQsvOb5XtlfkGMRI4OWS5UVpWZ42edYFQNJUSS2SWlpbu3ckcPR7mrrV3sysv7vw2Hf12raKTBDKKIucbfKsmxRGzIiI5ohobmrq3i/8H545oVvtzcz6u94chyjyFNMiYHTJ8ihgcc42g3Ksa2ZmBSoyQcwGxknaA3gFOBk4tUOb24Dz0jGGicDSiHhVUmuOdXtFb52rMzMbaApLEBHRJuk84E6SS1Wvjoh5ks5J668AZpFc4rqA5DLXsyqtW1SsZmbWmZILiAaG5ubmaGlpqXYYZmZbDElzIqI5q853UpuZWSYnCDMzy+QEYWZmmZwgzMws04AapE4vj/1jD1cfAbzei+Fs6dwfG7kvNuX+2NSW3h+7R0TmXcYDKkFsDkkt5Ubya5H7YyP3xabcH5sayP3hU0xmZpbJCcLMzDI5QWw0o9oB9DPuj43cF5tyf2xqwPaHxyDMzCyTjyDMzCyTE4SZmWWq+QQhabKk5yQtkDSt2vEURdLVkpZIeqqkbAdJd0uan/67fUndhWmfPCfpIyXlh0h6Mq2bLilrcqd+TdJoSfdIekbSPEnnp+W12h9DJD0i6fG0P76Rltdkf7STVC/pMUm/Spdrrz8iomZfJI8S/wOwJ8kkRY8D+1Y7roJ+1g8ABwNPlZT9CzAtfT8N+Hb6ft+0LwYDe6R9VJ/WPQIcRjLr3+3AsdX+2XrQF7sCB6fvhwPPpz9zrfaHgGHp+0bgYeDQWu2Pkn75InA98Kt0ueb6o9aPICYACyLihYhYA9wITKlyTIWIiPuBNzsUTwGuTd9fC3yspPzGiFgdES+SzNcxQdKuwDYR8ftIvv0/LllnixERr0bEo+n75cAzJHOe12p/RESsSBcb01dQo/0BIGkUcDxwVUlxzfVHrSeIkcDLJcuL0rJasXNEvArJL01gp7S8XL+MTN93LN9iSRoLvJfkr+aa7Y/0dMpcYAlwd0TUdH8A/w58GVhfUlZz/VHrCSLrfKCv+y3fLwOqvyQNA24CLoiIZZWaZpQNqP6IiHURMZ5k/vcJkvav0HxA94ekE4AlETEn7yoZZQOiP2o9QSwCRpcsjwIWVymWangtPQwm/XdJWl6uXxal7zuWb3EkNZIkh59GxM1pcc32R7uIeBu4F5hM7fbH4cCJkhaSnHb+oKTrqMH+qPUEMRsYJ2kPSYOAk4HbqhxTX7oNODN9fybwi5LykyUNlrQHMA54JD2sXi7p0PRqjE+WrLPFSGP/EfBMRHyvpKpW+6NJ0nbp+6HAh4FnqdH+iIgLI2JURIwl+Z3wPxFxOrXYH9UeJa/2CziO5CqWPwD/WO14Cvw5bwBeBdaS/GVzNrAj8BtgfvrvDiXt/zHtk+coufICaAaeSusuJb0bf0t6AUeQHOo/AcxNX8fVcH8cCDyW9sdTwNfS8prsjw59cxQbr2Kquf7wozbMzCxTrZ9iMjOzMpwgzMwskxOEmZllcoIwM7NMThBmZpbJCcKsByTtKGlu+vqTpFfS9yskXV7t+Mx6gy9zNdtMki4GVkTEv1Y7FrPe5CMIs14k6aiS+QMulnStpLskLZT0cUn/ks4PcEf6uI/2OQPukzRH0p3tj3MwqzYnCLNi7UXy2OgpwHXAPRFxALASOD5NEj8APhERhwBXA9+qVrBmpRqqHYDZAHd7RKyV9CTJBFV3pOVPAmOBfYD9gbvTycbqSR6JYlZ1ThBmxVoNEBHrJa2NjYN+60n+/wmYFxGHVStAs3J8ismsup4DmiQdBsljyCXtV+WYzAAnCLOqimSq208A35b0OMmTZd9f1aDMUr7M1czMMvkIwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0z/C6QFQRZJi3C9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       rem_blk_outf  net_inflow_stn  en_route_inf  net_inflow_clstr_10_min  \\\n",
       " 8928            0.0               1           0.0                      0.0   \n",
       " 8929            0.0               1           0.0                      0.0   \n",
       " 8930            0.0               0           0.0                      0.0   \n",
       " 8931            0.0               0           0.0                      0.0   \n",
       " 8932            0.0              -1           0.0                      0.0   \n",
       " ...             ...             ...           ...                      ...   \n",
       " 40195           1.0               1           0.0                      1.0   \n",
       " 40196           0.0               1           1.0                      1.0   \n",
       " 40197           0.0               2           0.0                      1.0   \n",
       " 40198           0.0               2           2.0                      1.0   \n",
       " 40199           0.0               4           0.0                      1.0   \n",
       " \n",
       "        DeepAR_agg_outflow  p_1wk_o  p_2wk_o  p_3wk_o  p_1ts_o  p_2ts_o  ...  \\\n",
       " 8928                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8929                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8930                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8931                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8932                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " ...                   ...      ...      ...      ...      ...      ...  ...   \n",
       " 40195                 1.0      1.0      0.0      1.0      0.0      0.0  ...   \n",
       " 40196                 1.0      0.0      1.0      0.0      0.0      0.0  ...   \n",
       " 40197                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40198                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40199                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " \n",
       "        day_of_mn_4  day_of_mn_5  day_of_mn_6  day_of_mn_7  day_of_mn_8  \\\n",
       " 8928             0            0            0            0            0   \n",
       " 8929             0            0            0            0            0   \n",
       " 8930             0            0            0            0            0   \n",
       " 8931             0            0            0            0            0   \n",
       " 8932             0            0            0            0            0   \n",
       " ...            ...          ...          ...          ...          ...   \n",
       " 40195            0            0            0            0            0   \n",
       " 40196            0            0            0            0            0   \n",
       " 40197            0            0            0            0            0   \n",
       " 40198            0            0            0            0            0   \n",
       " 40199            0            0            0            0            0   \n",
       " \n",
       "        day_of_mn_9  wk_of_mon_2  wk_of_mon_3  wk_of_mon_4  wk_of_mon_5  \n",
       " 8928             0            0            1            0            0  \n",
       " 8929             0            0            1            0            0  \n",
       " 8930             0            0            1            0            0  \n",
       " 8931             0            0            1            0            0  \n",
       " 8932             0            0            1            0            0  \n",
       " ...            ...          ...          ...          ...          ...  \n",
       " 40195            0            0            0            1            0  \n",
       " 40196            0            0            0            1            0  \n",
       " 40197            0            0            0            1            0  \n",
       " 40198            0            0            0            1            0  \n",
       " 40199            0            0            0            1            0  \n",
       " \n",
       " [4488 rows x 105 columns],\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGpCAYAAABrkPeOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyXUlEQVR4nO3deZyVZfn48c81gIoiKirrYJBLiRumIKWZaAmuaLlgmmb2pQxNvy593coty0pN+aUW5lpuuAUqpIQpWsqioiKIorgAI7gDasjM3L8/5oEGHIYB5syZOc/n7et5zTn3ec55ruMwZ665rvt+nkgpIUmSVKrKih2AJElSIZnsSJKkkmayI0mSSprJjiRJKmkmO5IkqaS1LnYAK7Pk3ddcJtaC/WzXc4odgtbQ1RVPFDsErYVqV9i2aJWfzYmmPF5j/q5ts9kXmzT21WFlR5IklbRmW9mRJEkFVl1V7AiahMmOJEl5laqLHUGTsI0lSZJKmpUdSZLyqjoflR2THUmScirZxpIkSWr5rOxIkpRXtrEkSVJJs40lSZLU8lnZkSQprzypoCRJKmm2sSRJklo+KzuSJOWVq7EkSVIp86SCkiRJJcDKjiRJeWUbS5IklTTbWJIkSS2flR1JkvIqJycVtLIjSVJeperG2+oREetFxMSIeC4iXoyIC7PxDhExNiJeyb5uUus5Z0fEzIiYEREDao3vEhEvZI8Ni4hY1ds02ZEkSYW2GNg7pbQT0BsYGBH9gLOAcSmlrYFx2X0iohcwGNgOGAhcExGtste6FhgCbJ1tA1d1cJMdSZLyqrq68bZ6pBqLsrttsi0Bg4Cbs/GbgUOy24OAO1JKi1NKs4CZQN+I6AK0Tyk9mVJKwC21nrNSJjuSJOVVI7axImJIREyutQ2pfaiIaBURU4D5wNiU0gSgU0qpAiD72jHbvRvwVq2nz87GumW3VxyvlxOUJUnSWkspDQeG1/N4FdA7IjYG7ouI7et5ubrm4aR6xutlsiNJUl4V4aSCKaUPI+JRaubazIuILimliqxFNT/bbTbQvdbTyoG52Xh5HeP1so0lSVJOpVTVaFt9ImLzrKJDRLQFvgm8BIwCjst2Ow4Ymd0eBQyOiHUjoic1E5EnZq2uhRHRL1uFdWyt56yUlR1JklRoXYCbsxVVZcCIlNIDEfEkMCIiTgDeBA4HSCm9GBEjgGlAJTA0/TejOhG4CWgLjMm2epnsSJKUV010uYiU0vPAznWMvwfss5LnXAJcUsf4ZKC++T6fY7IjSVJeeSFQSZJU0rwQqCRJUstnZUeSpLzKyYVATXYkScor21iSJEktn5UdSZLyytVYkiSppNnGkiRJavms7EiSlFe2sSRJUknLSbJjG0uSJJU0KzuSJOXUfy8kXtpMdiRJyquctLFMdhpg8eLPOG7omXy2ZAlVlVV8q/8enPTD7y23zwMPPcL1t94FwPpt2/LzM07iy1t/ca2O+9lnn3H2xZczbcYrbLxRey676Gy6denE3Lfnceo5v6SqqprKykq+e9jBHHnoAWt1rFK35/H70W/w3kTAk3c8wvgbxiz3+FcG7c4+Pz4YgMWfLObu8/7M3OlvrtUxW63TmqOvGEr59j355MNF3HzSVXww+x269voCh//yBNZr15bqqmrGXv03pjzw5FodS3Vbd911eWTcPay77jq0bt2Ke+8dzUUXX86tf72GbbbZEoCNNmrPRx8toE/fAUWOVvUZsO9eXHHFRbQqK+OGG2/nt7+7utghqQUx2WmAddZpww3DLmX99duypLKSY088g6/325Wdtt922T7dunbmpj/8lo3ab8jjT07iwt8O4/brrmzQ68+pmMe5l1zOTX/47XLj9z7wMO03bMeYETcw+h+PcsU1N3D5xWez+aYd+OsfL2edddbhk08+5ZDv/Zj+e/Sj4+abNubbLhmdtymn3+C9+f2gc6laUsmPbj6baY88y7uvv71sn/ffeoc/HHkRny74mC/v1Zsjfj2EKw85r0Gvv0n55nz3shO5evBFy433O6I/n360iF/tdSo7H/RVDjrru9xy0lUs+fQzbj3tGt59/W3ad9yE0x/4FS+Nf47/LPikUd+3YPHixew74Ag+/vgTWrduzaP/vI+/P/RPjj7mJ8v2+c1vfs6CjxYWMUqtSllZGcOuuoSB+x/F7NkVPPXkaO5/4GGmT3+l2KG1fJ5nR0tFBOuv3xaAyspKKisriYjl9tl5h15s1H5DAHbc7svMm//ussfuf+gRBv/wFL5z3FAu/O0wqqoa1iN95PEnGbT/NwHYd6+vM+HpKaSUaNOmDeussw4Any1ZQnVKa/0eS1mnrbrxxrOvsOQ/n1FdVc3MCdPZcUCf5fZ5/ZmX+XTBxwC88cwrbNS5w7LHdjlkD0792y85Y/SlHP6rHxJly3/vV2b7fXdl4j3jAXhu9AS2/tp2ALwzq2JZorVg/gcsfG8B7Tq0X+v3qbp9/HFNEtmmTWvatGlNWuHn5bDvHMSdI0YWIzQ1UN8+O/Pqq68za9abLFmyhBEjRnLwQVbiGkV1deNtzVjBkp2I+HJE/F9EDIuIq7Lb2676mc1TVVUV3zluKHseeBRf7bMzO2735ZXue+8DD7FHv10BePX1N/n7uMf4yx8v556br6asrIwHHv5ng445/5336NxxMwBat25Fuw3W58OPFgBQMe8dDj32RL556LGccPThVnXqUTHjLb7Yd1vW37gdbdZbh179e7Nxl5X//9rtyP689OgUADpu2ZWdD/wqww47n8v2P4vqqmp2OWSPBh13o04d+HDuewBUV1Xzn4WfssEmGy63zxY7bUnrNq157415a/bmtEplZWVMmvgQc2Y/x7hxjzNp0rPLHttjj92YP/8dZs6cVcQItSpdu3Xmrdlzl92fPaeCrl07FzEitTQFaWNFxP8BRwF3ABOz4XLg9oi4I6V06UqeNwQYAnDN5b/kh8ceVYjw1kirVq245+arWbBwEaecfTGvvPY6W3+xx+f2m/j0c9z7wMP85drLAJgweQrTXprJ4BNOAWrK6h022RiAn559EXPmzmNJ5RIq5r3Dd44bCsAxRwzi0AP2/dxfoMCyilKXTptz3y3XMv+d9/jp2Rfxrf57sFmHTQrwzlu++a/O5ZE/juLEv57L4o//w9zpb1BdVfdfIVt9tRf9juzPsMPOB2Cb3XegfIeenDbqEgDarLsOi96rSTiP/9NpbNq9I63atGaTrptxxuiaf9bjbxzDxLseI+ooANX+nrbffGOOvmIot51xTZ3fazWO6upq+vQdwEYbteeuEX9mu15f4sVpMwA48shBVnVagBUr6YA/M40lJ22sQs3ZOQHYLqW0pPZgRFwBvAjUmeyklIYDwwGWvPtas/yX3H7DdvT5yo488dTkzyU7M2bO4heXXskfL7+YjTeqaUuklDh4v2/yvyce/7nXGvbrXwArn7PTqeNmvD3/XTp33JzKyioWffzJslbZUh0335Sten6BZ56byr79v96I77S0TBjxTyaMqKmo7X/mYD6qeO9z+3T58hYceemPGP79S/nkw0UARMCke8bz4G/v+Nz+N/7oCmDlc3Y+fPt9Nu66KR+9/T5lrcpYb8O2y1533XZt+Z8b/4/Rl9/JG8/ObNT3qrp99NECxo9/kn0H7MWL02bQqlUrDhm0H/2+un+xQ9MqzJldQffyrsvul3frQkWF1dBG0czbT42lUG2saqBrHeNdssdalPc/+JAFC2t+Sf1n8WKemvQsPb/Qfbl9Kt6ez6nnXMyvf3EmPbYoXzbeb9fejH30Cd774EMAPlqwkLlvN+yHtP8e/Rg5+h8APPzo4+y2y05EBG/Pf4f/LF687PWefWHacsfU57XbtCb53Ljrpuw4sA/PjPr3co9v3HVTjv/jadz6v1fzzqyKZeMv/2sqO+2327Lnr7/RBmzSbbMGHXPq2Kfp+509Adhp/92Y+e8XAWjVphU/+NPpTLp3PM+NnrDW700rt9lmHdgo+8NjvfXWY++992DGjJrkcp99vs6MGa8yZ05FfS+hZmDS5ClstVVPevToTps2bTjiiEHc/8DDxQ5LLUihKjunAuMi4hXgrWxsC2Ar4KQCHbNg3nnvA8795WVUVVeTqhMD9v46e+2+G3fe9yAARx56ANfeeBsfLVjILy+rWQ7ZqlUrRtwwjC17foGT/+dYhpx6LtWpmjatW3PuaT+ha+dOqzzutw8cwNkX/479jvgBG7XfkN9deBYAr73+Fr/7w3VEBCklvn/Ut9lmy56F+x9QAo6/9jTW36QdVZVV3PPzG/l0wcd87eiayd//vvUfDPjpd9hgk3Yc9ssfAFBdWcUVB5/LvJlzGH35CH78l3OIiJrn/+IGPpjzbn2HA2qqSUdfMZRzHr2STz5cxF9OHgZA7wO+ypZ9v8wGm7Sj72HfAOC2M65l7rQ3CvTu86tL505cf/3vadWqFWVlwd13P8Do0eMAOOLwg7lzxN+KG6AapKqqilNOPY/RD95Gq7Iybrr5TqZNe7nYYZWGnLSxolB9z4goA/oC3YAAZgOTUgNP19hc21hqmJ/tek6xQ9AaurriiWKHoLXg6syWrfKzOQ1b7tlIPh0zrNH+wbTd76dNGvvqKNh5dlJK1cBThXp9SZKkhvCkgpIk5VVOJiib7EiSlFc5mbPjGZQlSVJJs7IjSVJe2caSJEklzTaWJElSy2dlR5KkvLKNJUmSSpptLEmSpJbPyo4kSXllG0uSJJW0nCQ7trEkSVJJs7IjSVJepUa76HmzZrIjSVJe2caSJElq+azsSJKUVzmp7JjsSJKUV55UUJIkqeWzsiNJUl7ZxpIkSSUtJ0vPbWNJkqSSZmVHkqS8so0lSZJKWk6SHdtYkiSppFnZkSQpr3Jynh2THUmScipVuxpLkiRprUVE94j4Z0RMj4gXI+KUbPyCiJgTEVOybf9azzk7ImZGxIyIGFBrfJeIeCF7bFhExKqOb2VHkqS8aroJypXA6SmlZyJiQ+DpiBibPfb7lNJltXeOiF7AYGA7oCvwj4jYJqVUBVwLDAGeAkYDA4Ex9R3cyo4kSXmVqhtvq+8wKVWklJ7Jbi8EpgPd6nnKIOCOlNLilNIsYCbQNyK6AO1TSk+mlBJwC3DIqt6myY4kSVprETEkIibX2oasZL8ewM7AhGzopIh4PiJuiIhNsrFuwFu1njY7G+uW3V5xvF4mO5Ik5VV1arQtpTQ8pbRrrW34ioeLiHbAPcCpKaUF1LSktgR6AxXA5Ut3rSPaVM94vZyzI0lSXjXhSQUjog01ic6tKaV7AVJK82o9fh3wQHZ3NtC91tPLgbnZeHkd4/WysiNJUl5VVzfeVo9sxdT1wPSU0hW1xrvU2u1QYGp2exQwOCLWjYiewNbAxJRSBbAwIvplr3ksMHJVb9PKjiRJKrTdge8BL0TElGzsHOCoiOhNTSvqdeBHACmlFyNiBDCNmpVcQ7OVWAAnAjcBbalZhVXvSiww2ZEkKb9S05xUMKX0BHXPtxldz3MuAS6pY3wysP3qHN9kR5KkvPJCoJIkSS2flR1JkvIqJ9fGMtmRJCmvcnLVc9tYkiSppFnZkSQpr2xjFVe78m8UOwSthU7rb1zsELSGUhMtRZVUfMnVWJIkSS1fs63sSJKkArONJUmSSpqrsSRJklo+KzuSJOWVbSxJklTSXI0lSZLU8lnZkSQpr2xjSZKkkuZqLEmSpJbPyo4kSXllG0uSJJUyr40lSZJUAqzsSJKUV7axJElSSctJsmMbS5IklTQrO5Ik5VVOzrNjsiNJUl7ZxpIkSWr5rOxIkpRTKSeVHZMdSZLyKifJjm0sSZJU0qzsSJKUVzm5XITJjiRJeWUbS5IkqeWzsiNJUl7lpLJjsiNJUk6llI9kxzaWJEkqaVZ2JEnKK9tYkiSppOUk2bGNJUmSSpqVHUmScsprY0mSpNKWk2THNpYkSSppVnYkScqrfFway2RHkqS8ysucHdtYkiSppFnZkSQpr3JS2THZkSQpr3IyZ8c2liRJKmlWdiRJyqm8TFA22ZEkKa9sY0mSJLV8JjsFtu666/LE4/czaeJDPPvMP/j5z08DYMcdezH+sZFMnPB3/v2vB9l1197FDbSEdenWiTtGXs+4p0byj3/fxw9+dPRK991x5+2Y9c4U9j/4W2t93HXWacPV1/+O8ZMfZOTYWynv3hWAXtt/ifse+iv/+Pd9PPT4PRx06IC1PpbqVl7elbEP38Xzzz/KlCmPcPJJJwBwwQVn8szTY5k86WFGP3gbXbp0KnKkWpUB++7Fi1PH89K0J/jZmUOLHU7JSNWp0bbmLFJqngGuu1735hnYGthgg/X5+ONPaN26Nf985F5OP+N8zv/FGQwbdh0PPfwoAwf057TTT2TffY8odqiNptP6Gxc7hGU6dtqMjp02Z+rz09mg3fo8+Mid/M/3TuGVGa8tt19ZWRm33jucxYs/Y8St9zF61NgGvX55965cfvUvOfLgHyw3/r0fHMm2223DOadfzEHfHsjAA/Zh6Aln0nPLL5BS4vXX3qRT58158JE72bvfIBYsWNho73ltVCx6v9ghNJrOnTvSpXNHnp0ylXbtNmDChL9z2GE/YPbsChYuXATASUN/wLbbbsPQk84qcrSNo2Q+OGspKytj+ouPM3D/o5g9u4KnnhzNMd/7CdOnv1Ls0Bpd5WdzoimP9/6gbzTaP5kOIx9baewR0R24BehMTfNseErpqojoANwJ9ABeB45IKX2QPeds4ASgCvhpSumhbHwX4CagLTAaOCWtIpmxstMEPv74EwDatGlNmzatSSmRUmLD9hsC0H6j9lRUzCtmiCVt/rx3mfr8dAA+XvQJM1+eRec6/pI/fsh3GXP/P3jvneV/2R96+IGMGnsbYx67i19f8QvKyhr2Y7Pv/v25+45RAIweOZbd99wNgFmvvsHrr70JwLy33+Hdd9+nw2abrPH708q9/fZ8np0yFYBFiz7mpZdeoWvXzssSHYD1N1if5vpHn2r07bMzr776OrNmvcmSJUsYMWIkBx9kRbQxpOrG21ahEjg9pbQt0A8YGhG9gLOAcSmlrYFx2X2yxwYD2wEDgWsiolX2WtcCQ4Cts23gqg5ustMEysrKmDjh78x+awrjxj3OpElTOOOMC/j1r89l5swJXPrr8/j5zy8tdpi5UN69K9vt+GWeffr55cY7denIgAP24a83jlhufKttenLQoQP49n7Hst83DqeqqopDDz+gQcfq3KUjc+e8DUBVVRULFyxikw4bL7fPTl/ZnjbrtOGNWW+t+ZtSg3zhC+X03ml7Jk58FoCLLvo/Xnt1EkcddSgXXPi7Iken+nTt1pm3Zs9ddn/2nAq6du1cxIi0ulJKFSmlZ7LbC4HpQDdgEHBzttvNwCHZ7UHAHSmlxSmlWcBMoG9EdAHap5SezKo5t9R6zko1ebITEcfX89iQiJgcEZOrqhatbLcWp7q6mr67DeSLW/Zl1z696dXrSwwZ8j3OPPNCttpqN8782YX86Y9+2Bba+hu05U83/54Lz/kNixZ+vNxjF/zq//j1hb+nunr5P09237MfO+zUi/vH3c6Yx+5i9z13Y4se5QAMv+VKxjx2FzePuIYde2/HmMfuYsxjd3H4dw8BIOLzFd3aFYSOnTbjymt/xRkn/dzKQoFtsMH6jLjzOk4/4/xlVZ1f/OI3fHHLPtx++3385Ccr/VhSM7CqnyWtherG22r/Ds+2IXUdMiJ6ADsDE4BOKaUKqEmIgI7Zbt2A2n8Fzs7GumW3VxyvVzGWnl8I3FjXAyml4cBwKK05O0t99NECxo9/kgH77sUxxxzGaaefD8A99zzAH6/9bZGjK22tW7fmTzf/nvvufpC/PzDuc4/v0LsXf/hzzfegQ4dN6P+tPaisrCIiuPuOUfzm4qs+95whx54KrHzOTsXceXTt1pm3586jVatWbNi+HR9+8BEA7TbcgBvvuJrLfvUHnp38/IovrUbUunVrRtx5Hbfffh9/+9uYzz1+xx33MXLkLVx00eVFiE4NMWd2Bd3Luy67X96ti63/RtKA9lPDX6vW7/CViYh2wD3AqSmlBXUlskt3resQ9YzXqyCVnYh4fiXbC0Culj1stlkHNtqoPQDrrbcee+/9dWbMmElFxTz23LMfAP37787MmbOKGWbJ+92wC5n58mv8+Zpb6nx8j533Y/feA9m990BGjxrLeWdewsOjH+Ff459i/4O/xaabdQBgo43b0628S4OOOXbMoxw2+GAA9h/0Lf79+ESgZu7Wdbdcyb133s+DIx9uhHen+lw3/HJeemkmV17138/grbbquez2QQfuy4wZrxYjNDXQpMlT2GqrnvTo0Z02bdpwxBGDuP8Bf3ZamohoQ02ic2tK6d5seF7WmiL7Oj8bnw10r/X0cmBuNl5ex3i9ClXZ6QQMAD5YYTyAfxfomM1S584duf7Pv6dVq1aUlZVx9z33M3rMOD78aAGXX3YBrVu35j//WcxPhpbGSpDmqM9uO/OdwQcz/cWXGfPYXQD89uJhdCuv6fn/9aa7VvrcV2a8xmW/+n/89Z4/UVZWRuWSSs772SXMmV2xyuPe+dd7ufKPv2b85Af58IOPOOmHPwPgwEMG0vdru7Bxh4057KhBAJw+9DymTZ2xtm9VK9j9a3045pjDeOGFaUyeVPPL8byfX8rxxw9mm222JFVX88abcxjqz1+zVlVVxSmnnsfoB2+jVVkZN918J9OmvVzssEpDE51UMGpKONcD01NKV9R6aBRwHHBp9nVkrfHbIuIKoCs1E5EnppSqImJhRPSjpg12LPD/Vnn8QvQ9I+J64MaU0hN1PHZbSum7q3qNUmxj5UlzWnqu1VNKS8/zyA/Olq2pl56/863GW3q++dh6l57vATwOvMB/U6xzqElYRgBbAG8Ch6eU3s+ecy7wA2pWcp2aUhqTje/Kf5eejwFOXtXSc8+zo4Iw2Wm5THZaNj84W7ZSTXaKzWtjSZKUU405Qbk5M9mRJCmn8pLseFJBSZJU0qzsSJKUV6nZTrNpVCY7kiTllG0sSZKkEmBlR5KknErVtrEkSVIJs40lSZJUAqzsSJKUU8nVWJIkqZTZxpIkSSoBVnYkScopV2NJkqSSlhrtmufNm20sSZJU0qzsSJKUU7axJElSSctLsmMbS5IklbSVVnYi4n5gpVOXUkoHFyQiSZLUJPIyQbm+NtZlTRaFJElqcnlpY6002UkpPbb0dkS0BbZIKc1okqgkSZIaySrn7ETEQcAU4O/Z/d4RMarAcUmSpAJLKRpta84ashrrAqAv8ChASmlKRPQoXEiSJKkpeG2s/6pMKX1U8EgkSZIKoCGVnakR8V2gVURsDfwU+Hdhw5IkSYVW3czbT42lIZWdk4HtgMXA7cAC4NQCxiRJkpqAc3YyKaVPgHMj4jc1d9PCwoclSZLUOFaZ7EREH+AGYMPs/kfAD1JKTxc4NkmSVEC5P89OLdcDP0kpPQ4QEXsANwI7FjIwSZJUWHk5g3JD5uwsXJroAKSUngBsZUmSpBahvmtjfSW7OTEi/kTN5OQEHEl2zh1JktRy2caCy1e4f36t2zkpfEmSVLrysvS8vmtj9W/KQCRJkgqhIROUiYgDqDnXznpLx1JKFxUqKEmSVHjN/fw4jaUhS8//CKwP9Af+DBwGTCxwXJIkqcBcjfVfX0spHQt8kFK6EPgq0L2wYUmSJDWOhrSxPs2+fhIRXYH3gJ6FC0mSJDWF3E9QruWBiNgY+B3wDDUrsa4rZFCSJKnwnLOTSSldnN28JyIeoGaS8pcLGpUkSVIjadBqrKVSSouBxRFxF7BFYUKSJElNIS8TlFcr2aklH3UvSZJKWF7m7DRkNVZdcpILSpKklq6+a2PdT91JTQCbFiyiTFV1daEPoQKqWPR+sUPQGvIvGSk/nKAMl63hY5IkqQXISxurvmtjPbbiWER8JaX0TGFDkiRJajyrO2fnzwWJQpIkNbnUiFtztrqrsfJR75IkKQdy38ZaiQsLEoUkSWpyTlDOREQARwNfTCldFBFbAJ1TSl75XJIkNXsNmbNzDTVXOj8qu78QuLpgEUmSpCZR3Yhbc9aQZGe3lNJQ4D8AKaUPgHUKGpUkSSq4RDTatioRcUNEzI+IqbXGLoiIORExJdv2r/XY2RExMyJmRMSAWuO7RMQL2WPDsg5UvRqS7CyJiFZkk60jYnOafxInSZKal5uAgXWM/z6l1DvbRgNERC9gMLBd9pxrslwE4FpgCLB1ttX1mstpSLIzDLgP6BgRlwBPAL9qwPMkSVIzVp0ab1uVlNJ4oKGn1x8E3JFSWpxSmgXMBPpGRBegfUrpyZRSAm4BDlnVi61ygnJK6daIeBrYh5ql54eklKY3MFhJktRMVTfiGWUiYgg1FZelhqeUhjfgqSdFxLHAZOD0bLpMN+CpWvvMzsaWZLdXHK/XKis72eqrT4D7gVHAx9mYJEkSACml4SmlXWttDUl0rgW2BHoDFcDl2XhdWViqZ7xeDTnPzoO1DrAe0BOYQU0fTZIktVANmVhc0OOnNG/p7Yi4Dngguzsb6F5r13JgbjZeXsd4vVZZ2Ukp7ZBS2jH7ujXQl5p5O5IkqQUr9tLzbA7OUocCS1dqjQIGR8S6EdGTmonIE1NKFcDCiOiXrcI6Fhi5quOs7hmUSSk9ExF9Vvd5kiQpvyLidmAvYLOImA2cD+wVEb2p6SC9DvwIIKX0YkSMAKYBlcDQlFJV9lInUrOyqy0wJtvqP3bNZOZ6gzut1t0y4CvApimlASt5SqNovU635n5dMdUjHycgL03+4EnFU/nZnCb9+Hy40+BG+5Hfd94dzfajvyGVnQ1r3a6kZg7PPYUJR5IkNZW8nDSv3mQnO4FPu5TSmU0UjyRJUqNaabITEa1TSpUR8ZWmDEiSJDUNKzswkZr5OVMiYhRwF/Dx0gdTSvcWODZJklRAxV563lQaMmenA/AesDf/Pd9OAkx2JElSs1dfstMxW4k1lc+ftdAFG5IktXDV+Sjs1JvstALasYanZpYkSc1bY14bqzmrL9mpSCld1GSRSJIkFUB9yU4+0j1JknIqL22a+pKdfZosCkmS1OTysvR8pRcCTSm935SBSJIkFcJqXwhUkiSVhurIx4wVkx1JknIqL3N2VtrGkiRJKgVWdiRJyqm8TFA22ZEkKafycgZl21iSJKmkWdmRJCmnvFyEJEkqaa7GkiRJKgFWdiRJyqm8TFA22ZEkKafysvTcNpYkSSppVnYkScqpvExQNtmRJCmn8jJnxzaWJEkqaSY7TWzAvnvx4tTxvDTtCX525tBih6NVuG745cyZ/RzPPjvuc4/97//+iCWfzWHTTTcpQmRaXdtssyWTJz28bHv/3Zf46ck/LHZYaiA/OwujuhG35sxkpwmVlZUx7KpLOPCgY9hhp/4ceeQhbLvt1sUOS/W4+ZYRHHjg0Z8bLy/vyjf32ZM33phdhKi0Jl5++VV27bMvu/bZl767DeSTTz7lbyPHFDssNYCfnYVjsqNG17fPzrz66uvMmvUmS5YsYcSIkRx80IBih6V6PPHEBN7/4MPPjV922QWcfc4lpJSX6X2lZZ+99+C1197gzTfnFDsUNYCfnVpbBUt2IuLLEbFPRLRbYXxgoY7Z3HXt1pm3Zs9ddn/2nAq6du1cxIi0Jg488FvMnVPB889PK3YoWkNHHDGIO+78W7HDUAP52Vk4KRpva84KkuxExE+BkcDJwNSIGFTr4V/V87whETE5IiZXV39ciNCKKuLz/xqsDLQsbduux9ln/ZQLLrys2KFoDbVp04aDDtyXu+95oNihqIH87CycvLSxCrX0/H+AXVJKiyKiB3B3RPRIKV0FK7/EakppODAcoPU63UruX/Kc2RV0L++67H55ty5UVMwrYkRaXVtu2YMePbbg6cljASgv78LECQ/xtd0PYN68d4ocnRpi4MD+PPvsC8yf/26xQ1ED+dmptVWoZKdVSmkRQErp9YjYi5qE5wvUk+yUukmTp7DVVj3p0aM7c+a8zRFHDOJ7x7qqoCWZOvUlupXvtOz+Ky8/Rb+v7sd7731QxKi0OgYfeYgtrBbGz87Cae4VmcZSqDk7b0dE76V3ssTnQGAzYIcCHbPZq6qq4pRTz2P0g7cx9flHufvu+5k27eVih6V6/OUvV/P4+FF8aZstmfXaZI7//uBih6S10Lbtenxznz2572+uwmpJ/OwsnNSIW3MWheh7RkQ5UJlSeruOx3ZPKf1rVa9Rim2sPMlt+a4E+IMnFU/lZ3Oa9OPz/3U/ptF+5E9+66/N9qO/IG2slNJKTz7SkERHkiQVXl4uF+G1sSRJyinn7EiSJJUAKzuSJOVUXio7JjuSJOVUXhYk2MaSJEklzcqOJEk55WosSZJU0pyzI0mSSppzdiRJkkqAlR1JknKqOie1HZMdSZJyKi9zdmxjSZKkkmZlR5KknMpHE8tkR5Kk3LKNJUmSVAJMdiRJyqnqaLxtVSLihoiYHxFTa411iIixEfFK9nWTWo+dHREzI2JGRAyoNb5LRLyQPTYsIlZ5dJMdSZJyqprUaFsD3AQMXGHsLGBcSmlrYFx2n4joBQwGtsuec01EtMqecy0wBNg621Z8zc8x2ZEkSQWXUhoPvL/C8CDg5uz2zcAhtcbvSCktTinNAmYCfSOiC9A+pfRkSikBt9R6zkqZ7EiSlFOpEbeIGBIRk2ttQxoQQqeUUgVA9rVjNt4NeKvWfrOzsW7Z7RXH6+VqLEmScqoxV2OllIYDwxvp5eqah5PqGa+XlR1JklQs87LWFNnX+dn4bKB7rf3KgbnZeHkd4/Uy2ZEkKaeaeIJyXUYBx2W3jwNG1hofHBHrRkRPaiYiT8xaXQsjol+2CuvYWs9ZKdtYkiTlVFOeQTkibgf2AjaLiNnA+cClwIiIOAF4EzgcIKX0YkSMAKYBlcDQlFJV9lInUrOyqy0wJtvqZbIjSZIKLqV01Eoe2mcl+18CXFLH+GRg+9U5tsmOJEk5lZfLRZjsSJKUU2sx16ZFcYKyJEkqaVZ2JEnKqXzUdUx2JEnKrbzM2bGNJUmSSpqVHUmScirlpJFlsiNJUk7ZxpIkSSoBVnYkScqpvJxnx2RHkqScykeqYxtLkiSVOCs7kiTllG0sSZJU0lyNJUmSVAKs7EiSlFOeVFCSJJU021iSJEklwMqOCiIfhVFJatlsY0mSpJJmG0uSJKkEWNmRJCmnqpNtLEmSVMLykerYxpIkSSXOyo4kSTnltbEkSVJJy8vSc9tYkiSppFnZkSQpp/Jynh2THUmSciovc3ZsY0mSpJJmZUeSpJzKywRlkx1JknIqL3N2bGNJkqSSZmVHkqScSl4bS5IklTJXY0mSJJUAKzuSJOVUXiYom+xIkpRTLj2XJEklzTk7kiRJJcDKjiRJOeXSc0mSVNLyMkHZNpYkSSppVnYkScopV2NJkqSS5mosSZKkEmBlR5KknHI1liRJKmm2sSRJkkqAlR1JknIqL6uxrOxIkpRT1Sk12rYqEfF6RLwQEVMiYnI21iEixkbEK9nXTWrtf3ZEzIyIGRExYG3ep8mOJElqKv1TSr1TSrtm988CxqWUtgbGZfeJiF7AYGA7YCBwTUS0WtODmuxIkpRTqRG3NTQIuDm7fTNwSK3xO1JKi1NKs4CZQN81PYjJjiRJOVVNarQtIoZExORa25AVDpeAhyPi6VqPdUopVQBkXztm492At2o9d3Y2tkacoCxJktZaSmk4MLyeXXZPKc2NiI7A2Ih4qZ59o65DrGlsJjuSJOVUU55nJ6U0N/s6PyLuo6YtNS8iuqSUKiKiCzA/23020L3W08uBuWt6bNtYkiTlVEqp0bb6RMQGEbHh0tvAvsBUYBRwXLbbccDI7PYoYHBErBsRPYGtgYlr+j6t7EiSpELrBNwXEVCTe9yWUvp7REwCRkTECcCbwOEAKaUXI2IEMA2oBIamlKrW9ODRXK+L0Xqdbs0zMEmSCqTyszl1zVUpmL5dv9Fov2snzn2sSWNfHVZ2JEnKKc+gLEmSVAJMdprYgH334sWp43lp2hP87MyhxQ5Hq+m64Zczd/ZzTHl2XLFD0WoqL+/KPx6+ixeef5TnpjzCySedUOyQtBr87CyMppqgXGwmO02orKyMYVddwoEHHcMOO/XnyCMPYdttty52WFoNt9wyggMOPLrYYWgNVFZWcubPLmSHHfdi9z0O4sQTv+/PXwvhZ2fhNOZJBZszk50m1LfPzrz66uvMmvUmS5YsYcSIkRx80Fpd20xN7PEnJvD+Bx8WOwytgbffns+zU6YCsGjRx7z00it069q5yFGpIfzs1NoqWLITEX0jok92u1dEnBYR+xfqeC1B126deWv2f8+JNHtOBV39sJWa3Be+UE7vnbZnwsRnix2KGsDPzsLJSxurIKuxIuJ8YD+gdUSMBXYDHgXOioidU0qXrOR5Q4AhANFqI8rKNihEeEWTnV9gOc39H4hUajbYYH1G3Hkdp51xPgsXLip2OGoAPzsLp7m3nxpLoZaeHwb0BtYF3gbKU0oLIuJ3wASgzmSn9nU1SvE8O3NmV9C9vOuy++XdulBRMa+IEUn50rp1a+668zpuv/0+/va3McUORw3kZ6fWVqHaWJUppaqU0ifAqymlBQAppU+B6gIds9mbNHkKW23Vkx49utOmTRuOOGIQ9z/wcLHDknLjuuGXM/2lmVx5VX3XKlRz42dn4aRG/K85K1Sy81lErJ/d3mXpYERsRI6TnaqqKk459TxGP3gbU59/lLvvvp9p014udlhaDX/9y9U8MX4UX9pmS15/bTLHf39wsUNSA+3+tT5875jD6N//a0ye9DCTJz3MfgP3LnZYagA/OwunOqVG25qzglwuIiLWTSktrmN8M6BLSumFVb1GKbaxJEmqT1NfLmL7Tv0a7Xft1HlP5etyEXUlOtn4u8C7hTimJElaPc29/dRYvDaWJEk51dzbT43FkwpKkqSSZmVHkqScso0lSZJKmm0sSZKkEmBlR5KknLKNJUmSSpptLEmSpBJgZUeSpJyyjSVJkkpaSvm4XKVtLEmSVNKs7EiSlFPVtrEkSVIpS67GkiRJavms7EiSlFO2sSRJUkmzjSVJklQCrOxIkpRTeblchMmOJEk5lZczKNvGkiRJJc3KjiRJOZWXCcomO5Ik5ZRLzyVJUknLS2XHOTuSJKmkWdmRJCmnXHouSZJKmm0sSZKkEmBlR5KknHI1liRJKmm2sSRJkkqAlR1JknLK1ViSJKmkeSFQSZKkEmBlR5KknLKNJUmSSpqrsSRJkkqAlR1JknIqLxOUTXYkScop21iSJEklwGRHkqScSik12rYqETEwImZExMyIOKsJ3t4yJjuSJOVUasStPhHRCrga2A/oBRwVEb0a+e2slMmOJEkqtL7AzJTSaymlz4A7gEFNdfBmO0G58rM5UewYCikihqSUhhc7Dq0Zv38tl9+7ls3vX+NqzN+1ETEEGFJraHit71U34K1aj80GdmusY6+KlZ3iGbLqXdSM+f1rufzetWx+/5qplNLwlNKutbbaSWldSVWTLQUz2ZEkSYU2G+he6345MLepDm6yI0mSCm0SsHVE9IyIdYDBwKimOniznbOTA/acWza/fy2X37uWze9fC5RSqoyIk4CHgFbADSmlF5vq+JGXsydKkqR8so0lSZJKmsmOJEkqaSY7TayYp8vW2ouIGyJifkRMLXYsWj0R0T0i/hkR0yPixYg4pdgxqWEiYr2ImBgRz2XfuwuLHZNaFufsNKHsdNkvA9+iZhneJOColNK0ogamBouIPYFFwC0ppe2LHY8aLiK6AF1SSs9ExIbA08Ah/vw1fxERwAYppUUR0QZ4AjglpfRUkUNTC2Flp2kV9XTZWnsppfHA+8WOQ6svpVSRUnomu70QmE7NWV3VzKUai7K7bbLNv9TVYCY7Tauu02X7YSs1sYjoAewMTChyKGqgiGgVEVOA+cDYlJLfOzWYyU7TKurpsiVBRLQD7gFOTSktKHY8apiUUlVKqTc1Z97tGxG2kdVgJjtNq6iny5byLpvvcQ9wa0rp3mLHo9WXUvoQeBQYWNxI1JKY7DStop4uW8qzbJLr9cD0lNIVxY5HDRcRm0fExtnttsA3gZeKGpRaFJOdJpRSqgSWni57OjCiKU+XrbUXEbcDTwJfiojZEXFCsWNSg+0OfA/YOyKmZNv+xQ5KDdIF+GdEPE/NH41jU0oPFDkmtSAuPZckSSXNyo4kSSppJjuSJKmkmexIkqSSZrIjSZJKmsmOJEkqaSY7UhFFRFW2BHpqRNwVEeuvxWvdFBGHZbf/HBG96tl3r4j42hoc4/WI2KyO8e9HxB/W9nXq2X+1Xl+SajPZkYrr05RS7+wK6p8BP679YES0WpMXTSn9cBVX894LWO1kR5JaIpMdqfl4HNgqq7r8MyJuA17ILoD4u4iYFBHPR8SPoOaMwBHxh4iYFhEPAh2XvlBEPBoRu2a3B0bEMxHxXESMyy6C+WPgf7Oq0tezM9Tekx1jUkTsnj1304h4OCKejYg/Uff13VYqIq6NiMkR8WJEXLjCw2dGxMRs2yrbv844JGlttC52AJIgIloD+wF/z4b6AtunlGZFxBDgo5RSn4hYF/hXRDxMzVW7vwTsAHQCpgE3rPC6mwPXAXtmr9UhpfR+RPwRWJRSuizb7zbg9ymlJyJiC2rO8r0tcD7wRErpoog4ABiymm/t3Ox4rYBxEbFjSun57LEFKaW+EXEscCVwIHDVSuKQpDVmsiMVV9uImJLdfpyaazd9DZiYUpqVje8L7Lh0Pg6wEbA1sCdwe0qpCpgbEY/U8fr9gPFLXyul9P5K4vgm0Kvm8lEAtI+IDbNjfDt77oMR8cFqvr8jsmStNTWn/O8FLE12bq/19feriEOS1pjJjlRcn6aUetceyH7Rf1x7CDg5pfTQCvvtD6zqei/RgH2gpqX91ZTSp3XE8rnnR8RQ4H+yu3VeXyoiegJnAH1SSh9ExE3AerV2SXXcri8OSVojztmRmr+HgBMjog1ARGwTERsA44HB2ZyeLkD/Op77JPCNLPEgIjpk4wuB2hWTh6m5SC3Zfr2zm+OBo7Ox/YBNAFJKV2cTq3unlOauJO721CRtH0VEJ2radLUdWevrk6uIQ5LWmJUdqfn7M9ADeCZqShzvAIcA9wF7Ay8ALwOPrfjElNI7WRvp3ogoA+YD3wLuB+6OiEHAycBPgauzq0q3pibJ+TFwIXB7RDyTvf6b9cT5/Yg4pNb9fsCzwIvAa8C/Vth/3YiYQM0fXUdlYyuLQ5LWmFc9lyRJJc02liRJKmkmO5IkqaSZ7EiSpJJmsiNJkkqayY4kSSppJjuSJKmkmexIkqSS9v8BkvyvA55HO/gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "        \"eta\": 0.1,\n",
    "        \"subsample\" : study.best_params[\"subsample\"],\n",
    "        \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "        'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "        'tweedie_variance_power': best_tweedie_variance_power,\n",
    "        'gamma': study.best_params[\"gamma\"],\n",
    "        'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "        'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "        'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "        \"objective\": 'reg:tweedie',\n",
    "        }\n",
    "early_stopping_rounds = 30\n",
    "eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "num_round= 1000\n",
    "\n",
    "t_v_t = train_validate_n_test()\n",
    "best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "t_v_t.evaluate_predictions(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "####################################### PREDICTION #################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       rem_blk_outf  net_inflow_stn  en_route_inf  net_inflow_clstr_10_min  \\\n",
       " 8928            0.0               1           0.0                      0.0   \n",
       " 8929            0.0               1           0.0                      0.0   \n",
       " 8930            0.0               0           0.0                      0.0   \n",
       " 8931            0.0               0           0.0                      0.0   \n",
       " 8932            0.0              -1           0.0                      0.0   \n",
       " ...             ...             ...           ...                      ...   \n",
       " 40195           1.0               1           0.0                      1.0   \n",
       " 40196           0.0               1           1.0                      1.0   \n",
       " 40197           0.0               2           0.0                      1.0   \n",
       " 40198           0.0               2           2.0                      1.0   \n",
       " 40199           0.0               4           0.0                      1.0   \n",
       " \n",
       "        DeepAR_agg_outflow  p_1wk_o  p_2wk_o  p_3wk_o  p_1ts_o  p_2ts_o  ...  \\\n",
       " 8928                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8929                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8930                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8931                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8932                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " ...                   ...      ...      ...      ...      ...      ...  ...   \n",
       " 40195                 1.0      1.0      0.0      1.0      0.0      0.0  ...   \n",
       " 40196                 1.0      0.0      1.0      0.0      0.0      0.0  ...   \n",
       " 40197                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40198                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40199                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " \n",
       "        day_of_mn_4  day_of_mn_5  day_of_mn_6  day_of_mn_7  day_of_mn_8  \\\n",
       " 8928             0            0            0            0            0   \n",
       " 8929             0            0            0            0            0   \n",
       " 8930             0            0            0            0            0   \n",
       " 8931             0            0            0            0            0   \n",
       " 8932             0            0            0            0            0   \n",
       " ...            ...          ...          ...          ...          ...   \n",
       " 40195            0            0            0            0            0   \n",
       " 40196            0            0            0            0            0   \n",
       " 40197            0            0            0            0            0   \n",
       " 40198            0            0            0            0            0   \n",
       " 40199            0            0            0            0            0   \n",
       " \n",
       "        day_of_mn_9  wk_of_mon_2  wk_of_mon_3  wk_of_mon_4  wk_of_mon_5  \n",
       " 8928             0            0            1            0            0  \n",
       " 8929             0            0            1            0            0  \n",
       " 8930             0            0            1            0            0  \n",
       " 8931             0            0            1            0            0  \n",
       " 8932             0            0            1            0            0  \n",
       " ...            ...          ...          ...          ...          ...  \n",
       " 40195            0            0            0            1            0  \n",
       " 40196            0            0            0            1            0  \n",
       " 40197            0            0            0            1            0  \n",
       " 40198            0            0            0            1            0  \n",
       " 40199            0            0            0            1            0  \n",
       " \n",
       " [4488 rows x 105 columns],\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "        \"eta\": 0.01,\n",
    "        \"subsample\" : study.best_params[\"subsample\"],\n",
    "        \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "        'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "        'tweedie_variance_power': best_tweedie_variance_power,\n",
    "        'gamma': study.best_params[\"gamma\"],\n",
    "        'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "        'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "        'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "        \"objective\": 'reg:tweedie',\n",
    "        }\n",
    "early_stopping_rounds = 30\n",
    "eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "num_round= 1000\n",
    "\n",
    "t_v_t = train_validate_n_test()\n",
    "best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "t_v_t.evaluate_predictions(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "####################################### PREDICTION #################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       rem_blk_outf  net_inflow_stn  en_route_inf  net_inflow_clstr_10_min  \\\n",
       " 8928            0.0               1           0.0                      0.0   \n",
       " 8929            0.0               1           0.0                      0.0   \n",
       " 8930            0.0               0           0.0                      0.0   \n",
       " 8931            0.0               0           0.0                      0.0   \n",
       " 8932            0.0              -1           0.0                      0.0   \n",
       " ...             ...             ...           ...                      ...   \n",
       " 40195           1.0               1           0.0                      1.0   \n",
       " 40196           0.0               1           1.0                      1.0   \n",
       " 40197           0.0               2           0.0                      1.0   \n",
       " 40198           0.0               2           2.0                      1.0   \n",
       " 40199           0.0               4           0.0                      1.0   \n",
       " \n",
       "        DeepAR_agg_outflow  p_1wk_o  p_2wk_o  p_3wk_o  p_1ts_o  p_2ts_o  ...  \\\n",
       " 8928                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8929                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8930                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8931                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8932                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " ...                   ...      ...      ...      ...      ...      ...  ...   \n",
       " 40195                 1.0      1.0      0.0      1.0      0.0      0.0  ...   \n",
       " 40196                 1.0      0.0      1.0      0.0      0.0      0.0  ...   \n",
       " 40197                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40198                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40199                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " \n",
       "        day_of_mn_4  day_of_mn_5  day_of_mn_6  day_of_mn_7  day_of_mn_8  \\\n",
       " 8928             0            0            0            0            0   \n",
       " 8929             0            0            0            0            0   \n",
       " 8930             0            0            0            0            0   \n",
       " 8931             0            0            0            0            0   \n",
       " 8932             0            0            0            0            0   \n",
       " ...            ...          ...          ...          ...          ...   \n",
       " 40195            0            0            0            0            0   \n",
       " 40196            0            0            0            0            0   \n",
       " 40197            0            0            0            0            0   \n",
       " 40198            0            0            0            0            0   \n",
       " 40199            0            0            0            0            0   \n",
       " \n",
       "        day_of_mn_9  wk_of_mon_2  wk_of_mon_3  wk_of_mon_4  wk_of_mon_5  \n",
       " 8928             0            0            1            0            0  \n",
       " 8929             0            0            1            0            0  \n",
       " 8930             0            0            1            0            0  \n",
       " 8931             0            0            1            0            0  \n",
       " 8932             0            0            1            0            0  \n",
       " ...            ...          ...          ...          ...          ...  \n",
       " 40195            0            0            0            1            0  \n",
       " 40196            0            0            0            1            0  \n",
       " 40197            0            0            0            1            0  \n",
       " 40198            0            0            0            1            0  \n",
       " 40199            0            0            0            1            0  \n",
       " \n",
       " [4488 rows x 105 columns],\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "        \"eta\": 0.001,\n",
    "        \"subsample\" : study.best_params[\"subsample\"],\n",
    "        \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "        'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "        'tweedie_variance_power': best_tweedie_variance_power,\n",
    "        'gamma': study.best_params[\"gamma\"],\n",
    "        'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "        'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "        'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "        \"objective\": 'reg:tweedie',\n",
    "        }\n",
    "early_stopping_rounds = 30\n",
    "eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "num_round= 1000\n",
    "\n",
    "t_v_t = train_validate_n_test()\n",
    "best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "t_v_t.evaluate_predictions(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "####################################### PREDICTION #################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       rem_blk_outf  net_inflow_stn  en_route_inf  net_inflow_clstr_10_min  \\\n",
       " 8928            0.0               1           0.0                      0.0   \n",
       " 8929            0.0               1           0.0                      0.0   \n",
       " 8930            0.0               0           0.0                      0.0   \n",
       " 8931            0.0               0           0.0                      0.0   \n",
       " 8932            0.0              -1           0.0                      0.0   \n",
       " ...             ...             ...           ...                      ...   \n",
       " 40195           1.0               1           0.0                      1.0   \n",
       " 40196           0.0               1           1.0                      1.0   \n",
       " 40197           0.0               2           0.0                      1.0   \n",
       " 40198           0.0               2           2.0                      1.0   \n",
       " 40199           0.0               4           0.0                      1.0   \n",
       " \n",
       "        DeepAR_agg_outflow  p_1wk_o  p_2wk_o  p_3wk_o  p_1ts_o  p_2ts_o  ...  \\\n",
       " 8928                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8929                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8930                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8931                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8932                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " ...                   ...      ...      ...      ...      ...      ...  ...   \n",
       " 40195                 1.0      1.0      0.0      1.0      0.0      0.0  ...   \n",
       " 40196                 1.0      0.0      1.0      0.0      0.0      0.0  ...   \n",
       " 40197                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40198                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40199                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " \n",
       "        day_of_mn_4  day_of_mn_5  day_of_mn_6  day_of_mn_7  day_of_mn_8  \\\n",
       " 8928             0            0            0            0            0   \n",
       " 8929             0            0            0            0            0   \n",
       " 8930             0            0            0            0            0   \n",
       " 8931             0            0            0            0            0   \n",
       " 8932             0            0            0            0            0   \n",
       " ...            ...          ...          ...          ...          ...   \n",
       " 40195            0            0            0            0            0   \n",
       " 40196            0            0            0            0            0   \n",
       " 40197            0            0            0            0            0   \n",
       " 40198            0            0            0            0            0   \n",
       " 40199            0            0            0            0            0   \n",
       " \n",
       "        day_of_mn_9  wk_of_mon_2  wk_of_mon_3  wk_of_mon_4  wk_of_mon_5  \n",
       " 8928             0            0            1            0            0  \n",
       " 8929             0            0            1            0            0  \n",
       " 8930             0            0            1            0            0  \n",
       " 8931             0            0            1            0            0  \n",
       " 8932             0            0            1            0            0  \n",
       " ...            ...          ...          ...          ...          ...  \n",
       " 40195            0            0            0            1            0  \n",
       " 40196            0            0            0            1            0  \n",
       " 40197            0            0            0            1            0  \n",
       " 40198            0            0            0            1            0  \n",
       " 40199            0            0            0            1            0  \n",
       " \n",
       " [4488 rows x 105 columns],\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "        \"eta\": 0.0001,\n",
    "        \"subsample\" : study.best_params[\"subsample\"],\n",
    "        \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "        'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "        'tweedie_variance_power': best_tweedie_variance_power,\n",
    "        'gamma': study.best_params[\"gamma\"],\n",
    "        'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "        'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "        'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "        \"objective\": 'reg:tweedie',\n",
    "        }\n",
    "early_stopping_rounds = 30\n",
    "eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "num_round= 1000\n",
    "\n",
    "t_v_t = train_validate_n_test()\n",
    "best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "t_v_t.evaluate_predictions(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " False \n",
      "\n",
      "####################################### PREDICTION #################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       rem_blk_outf  net_inflow_stn  en_route_inf  net_inflow_clstr_10_min  \\\n",
       " 8928            0.0               1           0.0                      0.0   \n",
       " 8929            0.0               1           0.0                      0.0   \n",
       " 8930            0.0               0           0.0                      0.0   \n",
       " 8931            0.0               0           0.0                      0.0   \n",
       " 8932            0.0              -1           0.0                      0.0   \n",
       " ...             ...             ...           ...                      ...   \n",
       " 40195           1.0               1           0.0                      1.0   \n",
       " 40196           0.0               1           1.0                      1.0   \n",
       " 40197           0.0               2           0.0                      1.0   \n",
       " 40198           0.0               2           2.0                      1.0   \n",
       " 40199           0.0               4           0.0                      1.0   \n",
       " \n",
       "        DeepAR_agg_outflow  p_1wk_o  p_2wk_o  p_3wk_o  p_1ts_o  p_2ts_o  ...  \\\n",
       " 8928                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8929                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8930                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8931                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 8932                  0.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " ...                   ...      ...      ...      ...      ...      ...  ...   \n",
       " 40195                 1.0      1.0      0.0      1.0      0.0      0.0  ...   \n",
       " 40196                 1.0      0.0      1.0      0.0      0.0      0.0  ...   \n",
       " 40197                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40198                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " 40199                 1.0      0.0      0.0      0.0      0.0      0.0  ...   \n",
       " \n",
       "        day_of_mn_4  day_of_mn_5  day_of_mn_6  day_of_mn_7  day_of_mn_8  \\\n",
       " 8928             0            0            0            0            0   \n",
       " 8929             0            0            0            0            0   \n",
       " 8930             0            0            0            0            0   \n",
       " 8931             0            0            0            0            0   \n",
       " 8932             0            0            0            0            0   \n",
       " ...            ...          ...          ...          ...          ...   \n",
       " 40195            0            0            0            0            0   \n",
       " 40196            0            0            0            0            0   \n",
       " 40197            0            0            0            0            0   \n",
       " 40198            0            0            0            0            0   \n",
       " 40199            0            0            0            0            0   \n",
       " \n",
       "        day_of_mn_9  wk_of_mon_2  wk_of_mon_3  wk_of_mon_4  wk_of_mon_5  \n",
       " 8928             0            0            1            0            0  \n",
       " 8929             0            0            1            0            0  \n",
       " 8930             0            0            1            0            0  \n",
       " 8931             0            0            1            0            0  \n",
       " 8932             0            0            1            0            0  \n",
       " ...            ...          ...          ...          ...          ...  \n",
       " 40195            0            0            0            1            0  \n",
       " 40196            0            0            0            1            0  \n",
       " 40197            0            0            0            1            0  \n",
       " 40198            0            0            0            1            0  \n",
       " 40199            0            0            0            1            0  \n",
       " \n",
       " [4488 rows x 105 columns],\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGpCAYAAABrkPeOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqGUlEQVR4nO3deZhdZZWo8XdVVRLmIUAgkwSFVgYRECINDkGUQUFwCqAIXtAojTKoKAhXGpTbdIPQcBXbKJOtDGlBGZVgZJQpESKQMAsXkhQJIJIAkaRS6/5RO6GASlUlqVOnzt7vz+c8Oec7++y9zrM5ZmWt79s7MhNJkqSyaqp3AJIkSbVksiNJkkrNZEeSJJWayY4kSSo1kx1JklRqLfUOYHkWP/9Xl4k1sNdOP7beIWglrXfutHqHIFVW26LZ0Z/H68u/awdt+PZ+jX1FWNmRJEmlNmArO5Ikqcbal9Q7gn5hsiNJUlVle70j6Be2sSRJUqlZ2ZEkqaraq1HZMdmRJKmi0jaWJElS47OyI0lSVdnGkiRJpWYbS5IkqfFZ2ZEkqaq8qKAkSSo121iSJEmNz8qOJElV5WosSZJUZl5UUJIkqQSs7EiSVFW2sSRJUqnZxpIkSWp8VnYkSaoqLyooSZJKzTaWJElS47OyI0lSVbkaS5IklZptLEmSpMZnZUeSpKqyjSVJksossxpLz21jSZKkUrOyI0lSVVVkgrLJjiRJVeWcHUmSVGoVqew4Z0eSJJWalR1JkqrKG4FKkqRSs40lSZLU+KzsSJJUVa7GkiRJpWYbS5IkqfFZ2ZEkqapsY0mSpFKrSLJjG0uSJJWalR1Jkioq04sKSpKkMqtIG8tkpxda5z7Hd79/Js//7UWaIvjMfnvzhfH7d7ntAw89wucnfIMzTz2ePXb7wCodd9GiRZzw/R8y85HHWG/ddTjz1BMYOXxj5jw7l2O++wOWLGmnra2Nz33mExzwyY+v0rHKbMj4r9O81Y7kyy+x8Myj3vL+oHGfpGX7D3a8aG6madgoXjn5EFj48softLmFIQcdS/Ood5CvLuAf/30G+eI8Yv2NWO3Q4yGaoLmFxX+6jrY7f7/yx9EK2XOPcZx11qk0NzVxwYWX8h9n/LjeIamXPHdaFc7Z6YWW5maO+/qXueaSiVwy8Wwuu/Jannjy/71luyVLlnD2eRey69gdVmj/s1vn8sWvffst41deO5l11l6L3026gC8csD9nnXcBABttMJRf/tcPueLiH3Ppz/6T8385iXnPvbByX64CFk+bwj9+dsry37/5Nyw8+1gWnn0si67/b5b8dUavE51YfxirH/GDt4y3vO+jsPBlXj39qyy+9WoGf/xQAHL+iyz8v9/pON65xzF4t08R6wxduS+mFdLU1MS555zGPvsezLvfsxsHHLA/W265Rb3DUi947moo2/vuMYCZ7PTCRhsOZat3bg7Ammuuwds3Hc3cLpKLS359NR8dtytD11/vDePX3PBHDvzS0Xz60CM55T/OZcmS3vVI/3jbnez3sY8AsMe4D3D3n6eTmQwaNIjBgwcDsGjxYtozV+HblV/7X2eSr/YueWnZ7gO03Xfr6693+BCrH3UGqx97NkM+fURHRaY3+9n6fSye9kcA2u7/Ey1bbNvxxpK2jgdAy6Be70+rbuxO2/PEE0/x5JNPs3jxYiZNuopP7LtnvcNSL3juaqi9ve8eA1jN/p82It4VEd+JiHMj4pzi+Za1Ol5/md06l4cee4Jtt37nG8bnPvc8U269g/H7f+wN40889TS/n3IL/11UYpqamrh28k29Ota8515gk2EbAtDS0sxaa67B31+aD3S01j55yBF85JOHcPjnP8uwjTbog29XcYMG0/KuHWi7/04AYtgoWrZ7Pwt/dDwLzz4Wsp2WHT7Uq13FukPJvz/f8aK9nVz4CqyxdvHehqz+jXNY86TzWXzTleT8v9Xk6+iNRozchGdmzVn2etbsVkaM2KSOEam3PHdaVTWZsxMR3wEOAi4D7imGRwGXRsRlmXn6cj43AZgAcN4Pf8CXDjmoFuGttFdfXcixJ/6A7xz1FdZac803vPfv5/yUY484jObm5jeM3z1tOjMffpwDDz8agNdee21Z5eeoE05l9py5LG5bTOvc5/j0oUcCcPD4/fjkx/cgu6jYRAQAwzfeiN/84ifMe+4FjjrhVD662/vZcOj6ff2VK6Vlq7EseeqhZS2sli22pWnk5qx+9JkAxKAh5MsvAbDaoScQQ4cRLYOI9TZk9WPPBmDx7dfSNnUKEMs9Tr70PAvPOppYZyirffEE2u7/07L9qnaW/nY66+o3poHHc1dDA7z91FdqNUH5cGDrzFzceTAizgJmAF0mO5k5EZgIsPj5vw6o/5IXt7VxzIk/4ON77MZHx+36lvdnPPwYx53c8bVefGk+t905lebmZjKTT+z9EY494n+95TPn/tv3gI5q0Ymn/ZCLfvQfb3h/42Eb8uy859lk2Ea0tS3h5VdeZd111n7DNsM22oDNN9uUe//y4CpPiK66jhbWbZ1GgrZpf2TR7/77Ldv+4+J/69hi/WGsduBRLPzJSW94P196gVhvQ/KlF6CpiVh9TXh1wRu3mf832uc+Q9Pbt2bJ/Xf0+ffRG82e1croUSOWvR41cjitrXPrGJF6y3NXQwO8/dRXatXGagdGdDE+vHivoWQm3/u3/+Ttm47m0AM/1eU2N/z6IiZfcTGTr7iYPca9n5O+dSS7f3AXdt5xO268+XZeePHvALw0fwFznu3dj3S39+/MVdf/AYDJN9/G+977HiKCZ+c9xz9ee23Z/u57YCZj3jZq1b9ola22Bs3v2Jq2GXcvG2p7/H5att2FWGvdjoHV1yLW36hXu1sy4x4G7fhhAFq23ZW2x+8HINbdAFoGF/tbk+Yx7yLnze6776HlmjptOptvvhljxoxm0KBBjB+/H9dcO7neYakXPHdaVbWq7BwDTImIx4BnirG3AZsDX6vRMWvmvvtncM3vp7DFO8YsazUd/ZVDaZ37HEC3y77fsdmmfP3LhzDhmBNpz3YGtbRw4jf+hRGbbNzjcT+1z56c8P0z2Hv8Yay7ztqcccrxAPz1qWc440c/IyLITL540Kf4p3ds1gfftJyGfP6bNL9jG2LNdVjjpPNZNPlSaO74T3/psu+WbXam7ZHpsOi1ZZ/Luc+w6Pe/YrUv/2vHROL2Nl678qfki8/1eMzF99zIagcdyxrH/1fH0vNfdrTCmoaNYvC+hwEJBItu/i3tz751ZZ/63pIlSzj6mJO4/rpLaG5q4qKLL2fmzEfrHZZ6wXNXQxVpY0Wt+p4R0QSMBUbSMYFhFjA1e3m5xoHWxtKKee30Y+sdglbSeudOq3cIUmW1LZq9/Al/NbDwd+f22d+1q+99VL/GviJqdlHBzGwH7qrV/iVJknrDKyhLklRVFZmgbLIjSVJVVWTOjpdvlSRJpWZlR5KkqrKNJUmSSs02liRJUuOzsiNJUlXZxpIkSaVmG0uSJKnxWdmRJKmqbGNJkqRSq0iyYxtLkiSVmsmOJElVldl3j25ExOiIuCkiHoqIGRFxdDE+NCJujIjHij/X7/SZEyLi8Yh4JCL27DT+3oh4oHjv3Ijo8W7rJjuSJFVVe3vfPbrXBnwzM7cEdgaOjIitgOOBKZm5BTCleE3x3oHA1sBewHkR0Vzs6yfABGCL4rFXTwc32ZEkSTWVma2ZeW/xfAHwEDAS2A+4uNjsYmD/4vl+wGWZ+VpmPgk8DoyNiOHAOpl5Z2Ym8ItOn1kuJyhLklRVfThBOSIm0FFxWWpiZk7sYrsxwPbA3cDGmdkKHQlRRAwrNhsJ3NXpY7OKscXF8zePd8tkR5KkqurDiwoWic1bkpvOImIt4ArgmMyc3810m67eyG7Gu2UbS5Ik1VxEDKIj0flVZl5ZDM8tWlMUf84rxmcBozt9fBQwpxgf1cV4t0x2JEmqqn6aoFysmDofeCgzz+r01tXAocXzQ4GrOo0fGBFDImIzOiYi31O0vBZExM7FPg/p9Jnlso0lSVJV9bBkvA/tCnwBeCAiphdj3wVOByZFxOHA08BnO8LKGRExCZhJx0quIzNzSfG5I4CLgNWB3xWPbpnsSJKkmsrM2+l6vg3A7sv5zGnAaV2MTwO2WZHjm+xIklRVFbldhMmOJElVVZFkxwnKkiSp1KzsSJJUVX14nZ2BzGRHkqSKyvZ+W41VV7axJElSqVnZkSSpqioyQdlkR5KkqqrInB3bWJIkqdSs7EiSVFUVmaBssiNJUlU5Z0eSJJVaRZId5+xIkqRSs7IjSVJVpXN2JElSmdnGkiRJanxWdiRJqiqXnkuSpFLzCsqSJEmNz8qOJElVZRurvlYf8YF6h6BVsPXQTesdgiSpB+lqLEmSpMY3YCs7kiSpxmxjSZKkUnM1liRJUuOzsiNJUlXZxpIkSaXmaixJkqTGZ2VHkqSqso0lSZJKzdVYkiRJjc/KjiRJVWUbS5IklZn3xpIkSSoBKzuSJFWVbSxJklRqFUl2bGNJkqRSs7IjSVJVVeQ6OyY7kiRVlW0sSZKkxmdlR5KkisqKVHZMdiRJqqqKJDu2sSRJUqlZ2ZEkqaoqcrsIkx1JkqrKNpYkSVLjs7IjSVJVVaSyY7IjSVJFZVYj2bGNJUmSSs3KjiRJVWUbS5IklVpFkh3bWJIkqdSs7EiSVFHeG0uSJJVbRZId21iSJKnUrOxIklRV1bg1lsmOJElVVZU5O7axJElSqVnZkSSpqipS2THZkSSpqioyZ8c2liRJKjUrO5IkVVRVJiib7EiSVFW2sSRJkhqfyU4/23OPccx48FYennk73z7uyHqHU1mDhwzmV7/7OZOmXMyVt/ySI447fJX3ue/4vbn6jsu5+o7L2Xf83svG/8+PT+aq2y/lipt/ySlnf5eWluZVPpZWjr+/xuW5q41szz57DGQmO/2oqamJc885jX32PZh3v2c3Djhgf7bccot6h1VJi15bxJc+/XXG734o43c/lF1325l377B1rz778yt/xIjRm7xhbJ311uar3zyMgz/2JT6/95f46jcPY+111wbg+isns9/7D+LT4w5myGpD+OTnP9Hn30c98/fXuDx3NdTeh48BzGSnH43daXueeOIpnnzyaRYvXsykSVfxiX33rHdYlbXw1YUAtAxqoaWlBTIZtelIzrvkLC694QIu/O15jNl8017ta5dxO3PXLVOZ//cFLHhpAXfdMpVdd9sZgNun3Llsuwfvm8nGw4f1/ZdRj/z9NS7PXe1ke989BjKTnX40YuQmPDNrzrLXs2a3MmLEJt18QrXU1NTE5X+4iJsevI67bp3KA/fN5HtnfofTTzyLg/Y8jLNO+REnnv6tXu1r2PANeXbOvGWv57bOY9jwDd+wTUtLM/t8Zi/+dNNdffo91Dv+/hqX506rqt9XY0XE/8rMC5fz3gRgAkA0r0tT05r9GlutRcRbxjIHdp+zzNrb2zngI19k7XXW4uwL/43N3/V23rPjuznjZz9Yts3gwYMB2O/Aj/O5L30WgLdtNoof/eqHLF60mDlPt3LsYSd0eW5506n97unH8ee7pnPf3X+p2XfS8vn7a1yeuxoa4BWZvlKPpeenAF0mO5k5EZgI0DJ4ZOn+S549q5XRo0Ysez1q5HBaW+fWMSIBLJj/MlPvuI/dP/YhFsxfwAEf+eJbtrnqsuu46rLrgI45O987+gfMeebZZe/PnfMcO+2y/bLXGw8fxtQ77lv2+ivfPIz1N1iP7x/377X7IuqWv7/G5bmrnf5sP0XEBcA+wLzM3KYY+1fgy8BzxWbfzczri/dOAA4HlgBHZeYNxfh7gYuA1YHrgaOzh+y3Jm2siLh/OY8HgI1rccxGMHXadDbffDPGjBnNoEGDGD9+P665dnK9w6qk9TdYj7XXWQuAIasNZucP7MhDDzzC7Kdb+ei+uy3b7p+22rxX+7vj5rv453FjWXvdtVl73bX553FjuePmjnbVJz+3L7uMex/HH/E9/zVaR/7+GpfnrjQuAvbqYvzszNyueCxNdLYCDgS2Lj5zXkQsXcr6Ezq6QFsUj672+Qa1quxsDOwJvPim8QDuqNExB7wlS5Zw9DEncf11l9Dc1MRFF1/OzJmP1jusStpw2Ab84Nz/TVNzE01NTUy+egq33ngHTzzyJCeefhxfPuaLtAxq4Ybf/oFHZz7e4/7m/30BE8++kEt+fz4APz3rQub/fQEAJ/3HcbTOmssvrp0IwB+vv4WfntVlcVM15O+vcXnuaqgfKzuZeWtEjOnl5vsBl2Xma8CTEfE4MDYingLWycw7ASLiF8D+wO+621nU4l+aEXE+cGFm3t7Fe5dk5ud62kcZ21hVsvXQ3q1i0sAz42//r94hSJXVtmh2FxMAa+e5j36oz/6uHfaHW79CMe+2MLGYnrJMkexc+6Y21heB+cA04JuZ+WJE/Ai4KzN/WWx3Ph0JzVPA6Zn5kWL8A8B3MnOf7mKrSRsrMw/vKtEp3usx0ZEkSY0lMydm5o6dHhN7/hQ/Ad4BbAe0Aj8sxrtK+rKb8W55byxJkiqq3tfHycxlM80j4mfAtcXLWcDoTpuOAuYU46O6GO+W19mRJKmi6n1RwYgY3unlJ4EHi+dXAwdGxJCI2IyOicj3ZGYrsCAido6OaxIcAlzV03Gs7EiSpJqLiEuBccCGETELOBkYFxHb0dGKegr4CkBmzoiIScBMoA04MjOXFLs6gteXnv+OHiYng8mOJEnVlf03HzozD+pi+Pxutj8NOK2L8WnANitybJMdSZIqqt5zdvqLc3YkSVKpWdmRJKmisr1fL+tTNyY7kiRVlG0sSZKkErCyI0lSRWU/rsaqJ5MdSZIqyjaWJElSCVjZkSSpolyNJUmSSi17vF94OdjGkiRJpWZlR5KkirKNJUmSSq0qyY5tLEmSVGrLrexExDXAcqcuZeYnahKRJEnqF1WZoNxdG+vMfotCkiT1u6q0sZab7GTmLUufR8TqwNsy85F+iUqSJKmP9DhnJyL2BaYDvy9ebxcRV9c4LkmSVGOZ0WePgaw3q7H+FRgL3AyQmdMjYkztQpIkSf3Be2O9ri0zX6p5JJIkSTXQm8rOgxHxOaA5IrYAjgLuqG1YkiSp1toHePupr/SmsvN1YGvgNeBSYD5wTA1jkiRJ/cA5O4XMfBU4MSL+veNlLqh9WJIkSX2jx2QnInYCLgDWLl6/BByWmX+ucWySJKmGKn+dnU7OB/4lM28DiIj3AxcC29YyMEmSVFtVuYJyb+bsLFia6ABk5u2ArSxJktQQurs31g7F03si4qd0TE5O4ACKa+5IkqTGZRsLfvim1yd3el6RwpckSeVVlaXn3d0ba7f+DESSJKkWejNBmYj4OB3X2llt6VhmnlqroCRJUu0N9Ovj9JXeLD3/L2ANYDfg58BngHtqHJckSaoxV2O9bpfMPAR4MTNPAf4ZGF3bsCRJkvpGb9pYC4s/X42IEcALwGa1C0mSJPWHyk9Q7uTaiFgPOAO4l46VWD+rZVCSJKn2nLNTyMzvF0+viIhr6Zik/K6aRiVJktRHerUaa6nMfA14LSL+B3hbbUKSJEn9oSoTlFco2emkGnUvSZJKrCpzdnqzGqsrFckFJUlSo+vu3ljX0HVSE8AGNYtIpfDQi0/XOwRJUg+coAxnruR7kiSpAVSljdXdvbFuefNYROyQmffWNiRJkqS+s6Jzdn5ekygkSVK/yz58DGQruhqrGvUuSZIqoPJtrOU4pSZRSJKkfucE5UJEBPB54O2ZeWpEvA3YJDO987kkSRrwejNn5zw67nR+UPF6AfDjmkUkSZL6RXsfPgay3rSx3peZO0TEfQCZ+WJEDK5xXJIkqcayIlNxe1PZWRwRzRSTrSNiIwZ+EidJkgT0rrJzLvAbYFhEnAZ8BjipplFJkqSaax/oa8b7SI/JTmb+KiL+DOxOx9Lz/TPzoZpHJkmSaqq9Im2s3qzGehvwKnBN57HM9OZHkiRpwOtNG+s6OubrBLAasBnwCLB1DeOSJEk1VpUJyr1pY7278+uI2AH4Ss0ikiRJ/aIqq41W9N5YFDcC3akGsUiSJPW53szZ+Uanl03ADsBzNYtIkiT1C9tYr1u70/M2OubwXFGbcCRJUn+pShur22SnuJjgWpl5XD/FI0mS1KeWm+xEREtmthUTkiVJUslY2YF76JifMz0irgb+B3hl6ZuZeWWNY5MkSTXknJ3XDQVeAD7M69fbScBkR5IkDXjdJTvDipVYD/J6krNURe6mIUlSebVXo7DTbbLTDKwFXda4THYkSWpw3hsLWjPz1H6LRJIkqQa6S3aqke5JklRRVWnTdJfs7N5vUUiSpH5XlaXny703Vmb+rT8DkSRJqoXeLD2XJEkl1B7VmLFisiNJUkVVZc7OcttYkiRJZWCyI0lSRbX34aMnEXFBRMyLiAc7jQ2NiBsj4rHiz/U7vXdCRDweEY9ExJ6dxt8bEQ8U750b0XMvzmRHkqSKao++e/TCRcBebxo7HpiSmVsAU4rXRMRWwIHA1sVnzouI5uIzPwEmAFsUjzfv8y1MdiRJUs1l5q3Am1d67wdcXDy/GNi/0/hlmflaZj4JPA6MjYjhwDqZeWdmJvCLTp9ZLicoS5JUUX15u4iImEBHxWWpiZk5sYePbZyZrQCZ2RoRw4rxkcBdnbabVYwtLp6/ebxbJjuSJFVUX67GKhKbnpKb3lrefTlX6n6dtrEkSVK9zC1aUxR/zivGZwGjO203CphTjI/qYrxbJjuSJFVUP09Q7srVwKHF80OBqzqNHxgRQyJiMzomIt9TtLwWRMTOxSqsQzp9ZrlsY0mSVFH9eW+siLgUGAdsGBGzgJOB04FJEXE48DTwWYDMnBERk4CZQBtwZGYuKXZ1BB0ru1YHflc8umWyI0mSai4zD1rOW13eeDwzTwNO62J8GrDNihzbZEeSpIqqyu0iTHYkSaqoVZhr01CcoCxJkkrNZKef7bnHOGY8eCsPz7ydbx93ZL3DUQ9GjRrO5Bsmcf9fbmL6fVP42tcOB+DTn/o40++bwj8WPs0OO2xb5yjVW/7+Gpfnrjb6895Y9WSy04+ampo495zT2Gffg3n3e3bjgAP2Z8stt6h3WOpGW9sSvv2dU9n2Pbvx/g98giO+eihbvmsLZsx8hPEHfJnbbru73iGql/z9NS7PXe2Y7KjPjd1pe5544imefPJpFi9ezKRJV/GJfffs+YOqm2efncf06R036H355Vd4+OHHGDFyEx5++HEeffSvdY5OK8LfX+Py3GlV1SzZiYh3RcTuEbHWm8Z7vDtpWY0YuQnPzHr9Qo+zZrcyYsQmdYxIK2LTTUfxnvdswz333FfvULQS/P01Ls9d7WT03WMgq0myExFH0XFFw68DD0bEfp3e/j/dfG5CREyLiGnt7a/UIrS66rjY4xt13LRVA92aa67B5ZdN5Fvf+lcWLHi53uFoJfj7a1yeu9qpShurVkvPvwy8NzNfjogxwK8jYkxmnkPXN/EC3ngTsZbBI0v3X/LsWa2MHjVi2etRI4fT2jq3jhGpN1paWrj88olcetlv+O1VPV6oUwOUv7/G5bnTqqpVG6s5M18GyMyn6Lg89N4RcRbdJDtlN3XadDbffDPGjBnNoEGDGD9+P665dnK9w1IPJv70TB5++HHOOedn9Q5Fq8DfX+Py3NWOlZ1V82xEbJeZ0wGKCs8+wAXAu2t0zAFvyZIlHH3MSVx/3SU0NzVx0cWXM3Pmo/UOS93YZZedOPjgz/DAAw8x9Z4bAPjf3/t3hgwezNlnf5+NNhrKVb+9mL/cP4N99jm4ztGqO/7+GpfnrnZK10JZjqhF3zMiRgFtmflsF+/tmpl/6mkfZWxjVUlTFz12NYZ250JIddO2aHa//p/n/x19cJ/94L/+zC8H7P/x16Syk5mzunmvx0RHkiTVXlVuF+G9sSRJqqiBPtemr3hRQUmSVGpWdiRJqqiqVHZMdiRJqqiqLEewjSVJkkrNyo4kSRXlaixJklRqztmRJEml5pwdSZKkErCyI0lSRbVXpLZjsiNJUkVVZc6ObSxJklRqVnYkSaqoajSxTHYkSaos21iSJEklYGVHkqSK8grKkiSp1Kqy9Nw2liRJKjUrO5IkVVQ16jomO5IkVZarsSRJkkrAyo4kSRVVlQnKJjuSJFVUNVId21iSJKnkrOxIklRRVZmgbLIjSVJFVWXOjm0sSZJUalZ2JEmqqGrUdUx2JEmqrKrM2bGNJUmSSs3KjiRJFZUVaWSZ7EiSVFG2sSRJkkrAyo4kSRVVlevsmOxIklRR1Uh1bGNJkqSSs7IjSVJF2caSJEml5mosSZKkErCyI0lSRXlRQUmSVGq2sSRJkkrAyo5qoj2rURqVpEZmG0uSJJWabSxJkqQSsLIjSVJFVWXKgcmOJEkVVY1UxzaWJEkqOSs7kiRVlPfGkiRJpVaVpee2sSRJUqlZ2ZEkqaKqcp0dkx1JkiqqKnN2bGNJkqRSs7IjSVJFVWWCssmOJEkVVZU5O7axJElSzUXEUxHxQERMj4hpxdjQiLgxIh4r/ly/0/YnRMTjEfFIROy5Ksc22ZEkqaIys88evbRbZm6XmTsWr48HpmTmFsCU4jURsRVwILA1sBdwXkQ0r+z3NNmRJKmi2sk+e6yk/YCLi+cXA/t3Gr8sM1/LzCeBx4GxK3sQkx1JkrTKImJCREzr9Jjwpk0SmBwRf+703saZ2QpQ/DmsGB8JPNPps7OKsZXiBGVJkiqqLycoZ+ZEYGI3m+yamXMiYhhwY0Q83M220dUhVjY2kx1JkiqqP5eeZ+ac4s95EfEbOtpScyNieGa2RsRwYF6x+SxgdKePjwLmrOyxbWNJklRR/TVnJyLWjIi1lz4H9gAeBK4GDi02OxS4qnh+NXBgRAyJiM2ALYB7VvZ7WtmRJEm1tjHwm4iAjtzjksz8fURMBSZFxOHA08BnATJzRkRMAmYCbcCRmblkZQ9usiNJUkWtwJLxVT3OX4H3dDH+ArD7cj5zGnBaXxzfZEeSpIryCsqSJEklYGVHkqSK8kagkiSp1FbhyscNxTaWJEkqNSs7kiRVVH+txqo3kx1JkirKNpYkSVIJWNmRJKmiXI0lSZJKrb0ic3ZsY0mSpFKzsiNJUkVVo65jsiNJUmW5GkuSJKkErOxIklRRVansmOxIklRRVbmCsm0sSZJUalZ2JEmqKNtYkiSp1KpyBWXbWJIkqdRMdvrZnnuMY8aDt/LwzNv59nFH1jscrYAhQ4Zw55+u5c/TbuQv0//Iyd/7Zr1D0gry99e4PHe1kZl99hjIYqAG2DJ45MAMbBU0NTXx0Izb2OtjBzFrVit33Xk9B3/hX3joocfqHZp6ac011+CVV16lpaWFW2/+Dcd+42TuvufeeoelXvD317iqdO7aFs2O/jzeDsPf32d/197benu/xr4irOz0o7E7bc8TTzzFk08+zeLFi5k06So+se+e9Q5LK+CVV14FYNCgFloGDRrw/5rR6/z9NS7PnVZVzZKdiBgbETsVz7eKiG9ExMdqdbxGMGLkJjwza86y17NmtzJixCZ1jEgrqqmpiWlTJ9M6+36mTLmVe6beV++Q1Ev+/hqX5652qtLGqslqrIg4GdgbaImIG4H3ATcDx0fE9pl52nI+NwGYABDN69LUtGYtwqubiLdW+Ab6fyB6o/b2dnbcaQ/WXXcdrvif89l663cyY8Yj9Q5LveDvr3F57mrHpeer5jPAdsAQ4FlgVGbOj4gzgLuBLpOdzJwITIRyztmZPauV0aNGLHs9auRwWlvn1jEirayXXprPLbfe0TFp0mSnIfj7a1yeO62qWrWx2jJzSWa+CjyRmfMBMnMh0F6jYw54U6dNZ/PNN2PMmNEMGjSI8eP345prJ9c7LPXShhsOZd111wFgtdVWY/cPf4BHHnmizlGpt/z9NS7PXe1kH/5vIKtVZWdRRKxRJDvvXToYEetS4WRnyZIlHH3MSVx/3SU0NzVx0cWXM3Pmo/UOS700fPjGXHD+f9Lc3ERTUxO//vU1XHf9H+odlnrJ31/j8tzVTntF2oE1WXoeEUMy87UuxjcEhmfmAz3to4xtLEmSutPfS8+32XjnPvu79sG5dw3Ypec1qex0legU488Dz9fimJIkacUM9PZTX/HeWJIkVVRV2lheVFCSJJWalR1JkirKNpYkSSo121iSJEklYGVHkqSKso0lSZJKzTaWJElSCVjZkSSpomxjSZKkUsusxu0qbWNJkqRSs7IjSVJFtdvGkiRJZZauxpIkSWp8VnYkSaoo21iSJKnUbGNJkiSVgJUdSZIqqiq3izDZkSSpoqpyBWXbWJIkqdSs7EiSVFFVmaBssiNJUkW59FySJJVaVSo7ztmRJEmlZmVHkqSKcum5JEkqNdtYkiRJJWBlR5KkinI1liRJKjXbWJIkSSVgZUeSpIpyNZYkSSo1bwQqSZJUAlZ2JEmqKNtYkiSp1FyNJUmSVAJWdiRJqqiqTFA22ZEkqaJsY0mSJJWAyY4kSRWVmX326ElE7BURj0TE4xFxfD98vWVMdiRJqqjsw0d3IqIZ+DGwN7AVcFBEbNXHX2e5THYkSVKtjQUez8y/ZuYi4DJgv/46+ICdoNy2aHbUO4ZaiogJmTmx3nFo5Xj+GpfnrrF5/vpWX/5dGxETgAmdhiZ2OlcjgWc6vTcLeF9fHbsnVnbqZ0LPm2gA8/w1Ls9dY/P8DVCZOTEzd+z06JyUdpVU9dtSMJMdSZJUa7OA0Z1ejwLm9NfBTXYkSVKtTQW2iIjNImIwcCBwdX8dfMDO2akAe86NzfPXuDx3jc3z14Aysy0ivgbcADQDF2TmjP46flTl6omSJKmabGNJkqRSM9mRJEmlZrLTz+p5uWytuoi4ICLmRcSD9Y5FKyYiRkfETRHxUETMiIij6x2TeiciVouIeyLiL8W5O6XeMamxOGenHxWXy34U+Cgdy/CmAgdl5sy6BqZei4gPAi8Dv8jMbeodj3ovIoYDwzPz3ohYG/gzsL+/v4EvIgJYMzNfjohBwO3A0Zl5V51DU4OwstO/6nq5bK26zLwV+Fu949CKy8zWzLy3eL4AeIiOq7pqgMsOLxcvBxUP/6WuXjPZ6V9dXS7b/7OV+llEjAG2B+6ucyjqpYhojojpwDzgxsz03KnXTHb6V10vly0JImIt4ArgmMycX+941DuZuSQzt6PjyrtjI8I2snrNZKd/1fVy2VLVFfM9rgB+lZlX1jserbjM/DtwM7BXfSNRIzHZ6V91vVy2VGXFJNfzgYcy86x6x6Pei4iNImK94vnqwEeAh+salBqKyU4/ysw2YOnlsh8CJvXn5bK16iLiUuBO4J0RMSsiDq93TOq1XYEvAB+OiOnF42P1Dkq9Mhy4KSLup+MfjTdm5rV1jkkNxKXnkiSp1KzsSJKkUjPZkSRJpWayI0mSSs1kR5IklZrJjiRJKjWTHamOImJJsQT6wYj4n4hYYxX2dVFEfKZ4/vOI2KqbbcdFxC4rcYynImLDLsa/GBE/WtX9dLP9Cu1fkjoz2ZHqa2FmblfcQX0R8NXOb0ZE88rsNDO/1MPdvMcBK5zsSFIjMtmRBo7bgM2LqstNEXEJ8EBxA8QzImJqRNwfEV+BjisCR8SPImJmRFwHDFu6o4i4OSJ2LJ7vFRH3RsRfImJKcRPMrwLHFlWlDxRXqL2iOMbUiNi1+OwGETE5Iu6LiJ/S9f3dlisifhIR0yJiRkSc8qa3j4uIe4rH5sX2XcYhSauipd4BSIKIaAH2Bn5fDI0FtsnMJyNiAvBSZu4UEUOAP0XEZDru2v1O4N3AxsBM4II37Xcj4GfAB4t9Dc3Mv0XEfwEvZ+aZxXaXAGdn5u0R8TY6rvK9JXAycHtmnhoRHwcmrOBXO7E4XjMwJSK2zcz7i/fmZ+bYiDgE+E9gH+Cc5cQhSSvNZEeqr9UjYnrx/DY67t20C3BPZj5ZjO8BbLt0Pg6wLrAF8EHg0sxcAsyJiD92sf+dgVuX7isz/7acOD4CbNVx+ygA1omItYtjfKr47HUR8eIKfr/xRbLWQscl/7cCliY7l3b68+we4pCklWayI9XXwszcrvNA8Rf9K52HgK9n5g1v2u5jQE/3e4lebAMdLe1/zsyFXcTyls9HxJHAl4uXXd5fKiI2A74F7JSZL0bERcBqnTbJLp53F4ckrRTn7EgD3w3AERExCCAi/iki1gRuBQ4s5vQMB3br4rN3Ah8qEg8iYmgxvgDoXDGZTMdNaim22654eivw+WJsb2B9gMz8cTGxervMnLOcuNehI2l7KSI2pqNN19kBnf68s4c4JGmlWdmRBr6fA2OAe6OjxPEcsD/wG+DDwAPAo8Atb/5gZj5XtJGujIgmYB7wUeAa4NcRsR/wdeAo4MfFXaVb6EhyvgqcAlwaEfcW+3+6mzi/GBH7d3q9M3AfMAP4K/CnN20/JCLupuMfXQcVY8uLQ5JWmnc9lyRJpWYbS5IklZrJjiRJKjWTHUmSVGomO5IkqdRMdiRJUqmZ7EiSpFIz2ZEkSaX2/wFE2CbCFoJyuQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_tweedie_variance_power = study.best_params[\"tweedie_variance_power\"]\n",
    "best_params = {\"max_depth\": study.best_params[\"max_depth\"],\n",
    "        \"eta\": 0.00001,\n",
    "        \"subsample\" : study.best_params[\"subsample\"],\n",
    "        \"colsample_bytree\": study.best_params[\"colsample_bytree\"],\n",
    "        'eval_metric':'tweedie-nloglik@'+str(best_tweedie_variance_power), ## try using AUC as well.. \n",
    "        'tweedie_variance_power': best_tweedie_variance_power,\n",
    "        'gamma': study.best_params[\"gamma\"],\n",
    "        'reg_alpha': study.best_params[\"reg_alpha\"], \n",
    "        'reg_lambda': study.best_params[\"reg_lambda\"],\n",
    "        'min_child_weight': study.best_params[\"min_child_weight\"],\n",
    "        \"objective\": 'reg:tweedie',\n",
    "        }\n",
    "early_stopping_rounds = 30\n",
    "eval_metric = 'tweedie-nloglik@'+str(best_tweedie_variance_power)\n",
    "num_round= 1000\n",
    "\n",
    "t_v_t = train_validate_n_test()\n",
    "best_model = t_v_t.make_predictions(best_params,num_round, early_stopping_rounds)\n",
    "t_v_t.evaluate_predictions(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
