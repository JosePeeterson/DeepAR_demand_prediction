{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import FormatError\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os,sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\\\2_freq_nbinom_LSTM')))\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\\\2_freq_nbinom_LSTM\\\\1_cluster_demand_prediction\\data\\weather_data')))\n",
    "sys.path.append(os.path.abspath(os.path.join('C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\1_cluster_demand_prediction\\data\\demand_data')))\n",
    "\n",
    "\n",
    "\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, RMSE\n",
    "from torchmetrics import R2Score, SymmetricMeanAbsolutePercentageError, MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "import os,sys\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from scipy.signal import find_peaks\n",
    "import operator\n",
    "import statsmodels.api as sm\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "from pytorch_forecasting import Baseline\n",
    "import random\n",
    "from pytorch_forecasting import DeepAR,NegativeBinomialDistributionLoss\n",
    "from itertools import product\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set Random seed\n",
    "\"\"\"\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import pre-processed Data\n",
    "\n",
    "response and target are the same thing\n",
    "\"\"\"\n",
    "with open(\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\\\2_freq_nbinom_LSTM\\\\1_cluster_demand_prediction\\\\final_response_ts.pkl\",'rb') as f:\n",
    "    final_response_ts = pickle.load(f)\n",
    "\n",
    "with open(\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\\\2_freq_nbinom_LSTM\\\\1_cluster_demand_prediction\\\\final_num_covariate_ts.pkl\",'rb') as f:\n",
    "    final_num_covariate_ts = pickle.load(f)\n",
    "\n",
    "with open(\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\\\2_freq_nbinom_LSTM\\\\1_cluster_demand_prediction\\\\final_cat_covariate_ts.pkl\",'rb') as f:\n",
    "    final_cat_covariate_ts = pickle.load(f)\n",
    "\n",
    "###### concatenate response and covariate time series into a single dataframe  #########\n",
    "df3 = pd.DataFrame(final_response_ts) # response and target are the same thing\n",
    "df4 = pd.DataFrame(final_num_covariate_ts)\n",
    "df5 = pd.DataFrame(final_cat_covariate_ts)\n",
    "df6 = pd.concat([df4,df5], axis=1) # dataframe of all covariates\n",
    "\n",
    "df1 = pd.DataFrame({\"time_idx\":np.arange(0,len(df3))})\n",
    "df2 = pd.DataFrame({\"group\":np.tile(0,len(df3))}) # identifies the series in case of univariate and multivariate series\n",
    "df = pd.concat([df1,df2,df3], axis=1)\n",
    "###### concatenate response and covariate time series into a single dataframe  #########\n",
    "\n",
    "\n",
    "#################### add date information ts ####################\n",
    "df[\"date\"] = pd.Timestamp(\"2021-09-24\") + pd.to_timedelta(df.time_idx, \"H\")\n",
    "df['_hour_of_day'] = df[\"date\"].dt.hour.astype(str)\n",
    "df['_day_of_week'] = df[\"date\"].dt.dayofweek.astype(str)\n",
    "df['_day_of_month'] = df[\"date\"].dt.day.astype(str)\n",
    "df['_day_of_year'] = df[\"date\"].dt.dayofyear.astype(str)\n",
    "df['_week_of_year'] = df[\"date\"].dt.weekofyear.astype(str)\n",
    "df['_month_of_year'] = df[\"date\"].dt.month.astype(str)\n",
    "df['_year'] = df[\"date\"].dt.year.astype(str)\n",
    "#################### add date information ts ####################\n",
    "\n",
    "Target = list(final_response_ts.keys())[0] # response and target are the same thing\n",
    "\n",
    "tr_stop_idx = int(0.77*len(df3))\n",
    "val_stop_idx = tr_stop_idx + int(0.077*len(df3)) + 25\n",
    "tes_stop_idx = len(df3)\n",
    "\n",
    "cat_col1 = list(final_cat_covariate_ts.keys())[0] # for column name agnostic\n",
    "cat_col2 = list(final_cat_covariate_ts.keys())[1] # for column name agnostic\n",
    "cat_col3 = list(final_cat_covariate_ts.keys())[2] # for column name agnostic\n",
    "cat_col4 = list(final_cat_covariate_ts.keys())[3] # for column name agnostic\n",
    "\n",
    "num_cols_list = list(final_num_covariate_ts.keys())[:3] # for column name agnostic\n",
    "#num_cols_list.append(Target) # for column name agnostic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "set inputs here\n",
    "(hyperparameters grid search)\n",
    "\n",
    "\"\"\"\n",
    "######### Network Architecture ###################\n",
    "\n",
    "###### Create hyperparameters grid ###### \n",
    "# After tuning replace the list with the single best hparams value inside list\n",
    "hparams_grid = {\"LSTM_neuron_size\":[320],\n",
    "\t            \"num_layers\":[2],\n",
    "                \"batch_size\":[4,32],\n",
    "                \"learning_rate\":[0.1],\n",
    "                \"max_encoder_length\":[168],\n",
    "                \"max_prediction_length\":[24],\n",
    "                \"dropout\":[0.1],\n",
    "\t            \"Num_epochs\":[50],\n",
    "                \"df_cov1\":list(df6.columns)}\n",
    "#\"activation_functions\":[],\n",
    "###### Create hyperparameters grid ###### \n",
    "\n",
    "Loss=NegativeBinomialDistributionLoss()\n",
    "\n",
    "######### Network Architecture ###################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######### Training Routine ###################\n",
    "fdv_steps = 10 # fast_dev_run\n",
    "######### Training Routine ###################\n",
    "\n",
    "\n",
    "############## Inputs for 2) Persistance model ( seasonal naive forecast ) #######################\n",
    "season_len = 168 # length of season\n",
    "num_past_seas = 6 # number of past seasons to use in averaging\n",
    "seas_pred_strt_idx = 1008 # seasonal naive forecast start index, in hours use the df dataframe\n",
    "############## Inputs for 2) Persistance model ( seasonal naive forecast ) #######################\n",
    "\n",
    "\n",
    "param_comb_cnt=0\n",
    "for neu,lay,bat,lr,enc_len,pred_len,drop,num_ep,df_cov_col1 in product(*[x for x in hparams_grid.values()]):\n",
    "    param_comb_cnt+=1\n",
    "param_comb_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData loading sanity check\\n\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data loading sanity check\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "######## View the entire data using this code ##################\n",
    "#print(train_dataset.data['categoricals'])\n",
    "######## View the data entire using this code ##################\n",
    "\n",
    "######## View the data for each batch using this code ##################\n",
    "# for x,y in iter(train_dataloader):\n",
    "#     print(x[\"encoder_cat\"][0][0:72,2])\n",
    "#     break\n",
    "######## View the data for each batch using this code ##################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "\n",
      "  | Name                   | Type                             | Params\n",
      "----------------------------------------------------------------------------\n",
      "0 | loss                   | NegativeBinomialDistributionLoss | 0     \n",
      "1 | logging_metrics        | ModuleList                       | 0     \n",
      "2 | embeddings             | MultiEmbedding                   | 2.6 K \n",
      "3 | rnn                    | LSTM                             | 1.3 M \n",
      "4 | distribution_projector | Linear                           | 642   \n",
      "----------------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.256     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03691bdcaf294b79ae26035914395c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541d083031404a8d8bce6cdf72d440bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd425f8a563427e963111f912a9c878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/30 [00:00<?, ? batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  2.5495097567963922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\1_cluster_demand_prediction\\model\\DeepAR_prediction.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39mnum_ep,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     gpus\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m     \u001b[39m#default_root_dir=\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\1_cluster_demand_prediction\\logs\"\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39m#print(f\"training routing:\\n \\n {trainer}\")\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m deepar \u001b[39m=\u001b[39m DeepAR\u001b[39m.\u001b[39;49mfrom_dataset(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m     train_dataset,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     \u001b[39m#learning_rate=lr,\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     hidden_size\u001b[39m=\u001b[39;49mneu,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     rnn_layers\u001b[39m=\u001b[39;49mlay,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m     dropout\u001b[39m=\u001b[39;49mdrop,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     loss\u001b[39m=\u001b[39;49mLoss,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     log_interval\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     log_val_interval\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     log_gradient_flow\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m     \u001b[39m# reduce_on_plateau_patience=3,\u001b[39;49;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39m#print(f\"Number of parameters in network: {deepar.size()/1e3:.1f}k\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39m# print(f\"Model :\\n \\n {deepar}\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/DeepAR-pytorch/My_model/2_freq_nbinom_LSTM/1_cluster_demand_prediction/model/DeepAR_prediction.ipynb#W6sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m torch\u001b[39m.\u001b[39mset_num_threads(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mC:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\pytorch_forecasting\\models\\deepar\\__init__.py:196\u001b[0m, in \u001b[0;36mDeepAR.from_dataset\u001b[1;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), MultivariateDistributionLoss):\n\u001b[0;32m    193\u001b[0m     \u001b[39massert\u001b[39;00m (\n\u001b[0;32m    194\u001b[0m         dataset\u001b[39m.\u001b[39mmin_prediction_length \u001b[39m==\u001b[39m dataset\u001b[39m.\u001b[39mmax_prediction_length\n\u001b[0;32m    195\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mMultivariate models require constant prediction lenghts\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 196\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfrom_dataset(\n\u001b[0;32m    197\u001b[0m     dataset, allowed_encoder_known_variable_names\u001b[39m=\u001b[39mallowed_encoder_known_variable_names, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs\n\u001b[0;32m    198\u001b[0m )\n",
      "File \u001b[1;32mC:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\pytorch_forecasting\\models\\base_model.py:1484\u001b[0m, in \u001b[0;36mBaseModelWithCovariates.from_dataset\u001b[1;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[0;32m   1464\u001b[0m new_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m   1465\u001b[0m     static_categoricals\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mstatic_categoricals,\n\u001b[0;32m   1466\u001b[0m     time_varying_categoricals_encoder\u001b[39m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1481\u001b[0m     categorical_groups\u001b[39m=\u001b[39mdataset\u001b[39m.\u001b[39mvariable_groups,\n\u001b[0;32m   1482\u001b[0m )\n\u001b[0;32m   1483\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m-> 1484\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfrom_dataset(dataset, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mC:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\pytorch_forecasting\\models\\base_model.py:1807\u001b[0m, in \u001b[0;36mAutoRegressiveBaseModel.from_dataset\u001b[1;34m(cls, dataset, **kwargs)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     \u001b[39massert\u001b[39;00m lag \u001b[39m==\u001b[39m \u001b[39mset\u001b[39m(lags\u001b[39m.\u001b[39mget(target, [])), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall target lags in dataset must be the same but found \u001b[39m\u001b[39m{\u001b[39;00mlags\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1806\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mtarget_lags\u001b[39m\u001b[39m\"\u001b[39m, {name: dataset\u001b[39m.\u001b[39m_get_lagged_names(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m lags})\n\u001b[1;32m-> 1807\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfrom_dataset(dataset, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\pytorch_forecasting\\models\\base_model.py:997\u001b[0m, in \u001b[0;36mBaseModel.from_dataset\u001b[1;34m(cls, dataset, **kwargs)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39moutput_transformer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    996\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moutput_transformer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtarget_normalizer\n\u001b[1;32m--> 997\u001b[0m net \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    998\u001b[0m net\u001b[39m.\u001b[39mdataset_parameters \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_parameters()\n\u001b[0;32m    999\u001b[0m \u001b[39mif\u001b[39;00m dataset\u001b[39m.\u001b[39mmulti_target:\n",
      "File \u001b[1;32mC:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\pytorch_forecasting\\models\\deepar\\__init__.py:123\u001b[0m, in \u001b[0;36mDeepAR.__init__\u001b[1;34m(self, cell_type, hidden_size, rnn_layers, dropout, static_categoricals, static_reals, time_varying_categoricals_encoder, time_varying_categoricals_decoder, categorical_groups, time_varying_reals_encoder, time_varying_reals_decoder, embedding_sizes, embedding_paddings, embedding_labels, x_reals, x_categoricals, n_validation_samples, n_plotting_samples, target, target_lags, loss, logging_metrics, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         n_plotting_samples \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m--> 123\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_hyperparameters()\n\u001b[0;32m    124\u001b[0m \u001b[39m# store loss function separately as it is a module\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(loss\u001b[39m=\u001b[39mloss, logging_metrics\u001b[39m=\u001b[39mlogging_metrics, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\site-packages\\pytorch_lightning\\core\\mixins\\hparams_mixin.py:107\u001b[0m, in \u001b[0;36mHyperparametersMixin.save_hyperparameters\u001b[1;34m(self, ignore, frame, logger, *args)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m current_frame:\n\u001b[0;32m    106\u001b[0m         frame \u001b[39m=\u001b[39m current_frame\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 107\u001b[0m save_hyperparameters(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, ignore\u001b[39m=\u001b[39;49mignore, frame\u001b[39m=\u001b[39;49mframe)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:264\u001b[0m, in \u001b[0;36msave_hyperparameters\u001b[1;34m(obj, ignore, frame, *args)\u001b[0m\n\u001b[0;32m    262\u001b[0m obj\u001b[39m.\u001b[39m_set_hparams(hp)\n\u001b[0;32m    263\u001b[0m \u001b[39m# make deep copy so there is not other runtime changes reflected\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m obj\u001b[39m.\u001b[39m_hparams_initial \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(obj\u001b[39m.\u001b[39;49m_hparams)\n\u001b[0;32m    266\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39m_hparams\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, nn\u001b[39m.\u001b[39mModule):\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:296\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[0;32m    295\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 296\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    297\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[0;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\lib\\site-packages\\torch\\_tensor.py:85\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__deepcopy__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, memo)\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_leaf:\n\u001b[1;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly Tensors created explicitly by the user \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m(graph leaves) support the deepcopy protocol at the moment\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39min\u001b[39;00m memo:\n\u001b[0;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Full Training Routine \n",
    "with hyperparmeter grid search\n",
    "\n",
    "Load data into TimeSeriesDataSet object\n",
    "\n",
    "for fast development run\n",
    "uncomment fast_dev_run = fdv_steps\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "for neu,lay,bat,lr,enc_len,pred_len,drop,num_ep,df_cov_col1 in product(*[x for x in hparams_grid.values()]):\n",
    "\n",
    "    ######### Load DATA #############\n",
    "    df[df_cov_col1] = df6[df_cov_col1].values  # add the covariate column\n",
    "    if (df_cov_col1[:3] == 'wea'): # categorical covariate\n",
    "        num_cols_list = []\n",
    "        cat_col1 = df_cov_col1\n",
    "        cat_dict = {cat_col1: NaNLabelEncoder(add_nan=True).fit(df[cat_col1]),\"_hour_of_day\": NaNLabelEncoder(add_nan=True).fit(df._hour_of_day), \\\n",
    "        \"_day_of_week\": NaNLabelEncoder(add_nan=True).fit(df._day_of_week), \"_day_of_month\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_month), \"_day_of_year\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_year), \\\n",
    "            \"_week_of_year\": NaNLabelEncoder(add_nan=True).fit(df._week_of_year), \"_month_of_year\": NaNLabelEncoder(add_nan=True).fit(df._month_of_year) ,\"_year\": NaNLabelEncoder(add_nan=True).fit(df._year)}\n",
    "        cat_list = [cat_col1,\"_hour_of_day\",\"_day_of_week\",\"_day_of_month\",\"_day_of_year\",\"_week_of_year\",\"_month_of_year\",\"_year\"]\n",
    "    else:\n",
    "        num_cols_list = [df_cov_col1] # numerical covariate\n",
    "        cat_dict = {\"_hour_of_day\": NaNLabelEncoder(add_nan=True).fit(df._hour_of_day), \\\n",
    "        \"_day_of_week\": NaNLabelEncoder(add_nan=True).fit(df._day_of_week), \"_day_of_month\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_month), \"_day_of_year\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_year), \\\n",
    "            \"_week_of_year\": NaNLabelEncoder(add_nan=True).fit(df._week_of_year), \"_month_of_year\": NaNLabelEncoder(add_nan=True).fit(df._month_of_year) ,\"_year\": NaNLabelEncoder(add_nan=True).fit(df._year)}\n",
    "        cat_list = [\"_hour_of_day\",\"_day_of_week\",\"_day_of_month\",\"_day_of_year\",\"_week_of_year\",\"_month_of_year\",\"_year\"]\n",
    "\n",
    "    train_dataset = TimeSeriesDataSet(\n",
    "        df.iloc[0:tr_stop_idx],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=Target,\n",
    "        categorical_encoders=cat_dict,\n",
    "        group_ids=[\"group\"],\n",
    "        min_encoder_length=enc_len,\n",
    "        max_encoder_length=enc_len,\n",
    "        min_prediction_length=pred_len,\n",
    "        max_prediction_length=pred_len,\n",
    "        time_varying_unknown_reals=[Target],\n",
    "        time_varying_known_reals=num_cols_list,\n",
    "        time_varying_known_categoricals=cat_list,\n",
    "        add_relative_time_idx=False,\n",
    "        randomize_length=False,\n",
    "        scalers={},\n",
    "        target_normalizer=TorchNormalizer(method=\"identity\",center=False,transformation=None )\n",
    "\n",
    "    )\n",
    "\n",
    "    val_dataset = TimeSeriesDataSet.from_dataset(train_dataset,df.iloc[tr_stop_idx:val_stop_idx], stop_randomization=True)\n",
    "    test_dataset = TimeSeriesDataSet.from_dataset(train_dataset,df.iloc[val_stop_idx:tes_stop_idx], stop_randomization=True)\n",
    "\n",
    "    train_dataloader = train_dataset.to_dataloader(train=True, batch_size=bat)\n",
    "    val_dataloader = val_dataset.to_dataloader(train=False, batch_size=bat)\n",
    "    test_dataloader = test_dataset.to_dataloader(train=False, batch_size=bat)\n",
    "    ######### Load DATA #############\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "    # Baseline predictions START\n",
    "    # 1) Persistance model (last value)\n",
    "\n",
    "    # 2) Persistance model ( seasonal naive forecast )\n",
    "    # \"\"\"\n",
    "    # ############## 1) Persistance model (last value) #######################\n",
    "    # actuals = torch.cat([y[0] for x, y in iter(test_dataloader)])\n",
    "    # baseline_predictions = Baseline().predict(test_dataloader)\n",
    "    # print(f\" Persistance model (last value), sMAPE : {SMAPE()(baseline_predictions, actuals)}\")\n",
    "    # print(f\" Persistance model (last value), RMSE : {RMSE()(baseline_predictions,actuals)}\")\n",
    "    # r2score = R2Score()\n",
    "    # print(f\" Persistance model (last value), R2 Score : { np.mean([ r2score(baseline_predictions[i], actuals[i])    for i in range(len(actuals)) ]) }\" )\n",
    "    # ############## 1) Persistance model (last value) #######################\n",
    "\n",
    "\n",
    "    # ############## 2) Persistance model ( seasonal naive forecast ) #######################\n",
    "    # predictions = np.array([])\n",
    "    # actuals1 = df[Target][seas_pred_strt_idx:seas_pred_strt_idx+24]\n",
    "    # for h in range(24):\n",
    "    #     sum1 = 0\n",
    "    #     for n in range(num_past_seas):\n",
    "    #         sum1 = sum1 + df[Target][seas_pred_strt_idx+h - season_len*n]\n",
    "        \n",
    "    #     predictions = np.append(predictions,sum1/num_past_seas)\n",
    "\n",
    "    # predictions = predictions.astype(int)\n",
    "    # actuals1 = np.array(actuals1)\n",
    "\n",
    "    # smape = SymmetricMeanAbsolutePercentageError()\n",
    "    # mse = MeanSquaredError()\n",
    "    # print(f\"\\nseasonal prediction start index:  {seas_pred_strt_idx}\")\n",
    "    # print(f\" Persistance model ( seasonal naive forecast ) , sMAPE : { smape(  torch.Tensor(predictions),torch.Tensor(actuals1))    }\")\n",
    "    # print(f\" Persistance model ( seasonal naive forecast ) , RMSE : {np.sqrt(mse(torch.Tensor(predictions),torch.Tensor(actuals1)))}\")\n",
    "    # r2score = R2Score()\n",
    "    # print(f\" Persistance model ( seasonal naive forecast ) , R2 Score : {r2score( torch.Tensor(predictions),torch.Tensor(actuals1)) }\" )\n",
    "    # plt.title(\"(average) seasonal naive forecast\")\n",
    "    # plt.plot(predictions,color='r')\n",
    "    # plt.plot(actuals1,color='b')\n",
    "    # plt.show()\n",
    "    # ############## 2) Persistance model ( seasonal naive forecast ) #######################\n",
    "    # \"\"\"\n",
    "    # Baseline predictions END\n",
    "    # \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Machine Learning predictions START\n",
    "    1) DeepAR\n",
    "\n",
    "    \"\"\"\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_ep,\n",
    "        gpus=0,\n",
    "        auto_lr_find=True,\n",
    "        gradient_clip_val=0.1,\n",
    "        limit_train_batches=1.0,\n",
    "        limit_val_batches=1.0,\n",
    "        #fast_dev_run=fdv_steps,\n",
    "        logger=True,\n",
    "        #log_every_n_steps=10,\n",
    "        # profiler=True,\n",
    "        callbacks=[lr_logger, early_stop_callback],\n",
    "        enable_checkpointing=True,\n",
    "        #default_root_dir=\"C:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\DeepAR-pytorch\\My_model\\2_freq_nbinom_LSTM\\1_cluster_demand_prediction\\logs\"\n",
    "    )\n",
    "    #print(f\"training routing:\\n \\n {trainer}\")\n",
    "    deepar = DeepAR.from_dataset(\n",
    "        train_dataset,\n",
    "        #learning_rate=lr,\n",
    "        hidden_size=neu,\n",
    "        rnn_layers=lay,\n",
    "        dropout=drop,\n",
    "        loss=Loss,\n",
    "        log_interval=10,\n",
    "        log_val_interval=3,\n",
    "        log_gradient_flow=True,\n",
    "        # reduce_on_plateau_patience=3,\n",
    "    )\n",
    "    #print(f\"Number of parameters in network: {deepar.size()/1e3:.1f}k\")\n",
    "    # print(f\"Model :\\n \\n {deepar}\")\n",
    "    torch.set_num_threads(10)\n",
    "    trainer.fit(\n",
    "        deepar,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "\n",
    "    ########## Prediction #####################\n",
    "\n",
    "    test_output = deepar.predict(data=test_dataloader,mode='prediction',return_index=True,num_workers=8,show_progress_bar=True)\n",
    "\n",
    "    plt.plot(df['clstr_175'].iloc[2038:2038+pred_len].values)\n",
    "    pred = np.array(test_output[0][0]).astype(int)\n",
    "    plt.plot(pred)\n",
    "    plt.show()\n",
    "\n",
    "    print('RMSE : ',np.sqrt(mean_squared_error(df['clstr_175'].iloc[2038:2038+pred_len].values,pred )))\n",
    "    print('\\n Hyperparameter: neu,lay,bat,lr,enc_len,pred_len,drop,num_ep,df_cov_col1\\n')\n",
    "    print(neu,lay,bat,lr,enc_len,pred_len,drop,num_ep,df_cov_col1,'\\n')\n",
    "    ########## Prediction #####################\n",
    "    \n",
    "    \n",
    "    ## delete this covariate column in df so that only one covariate is available \n",
    "    df.drop(df_cov_col1, axis=1, inplace=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    Machine Learning predictions END\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFull Training Routine\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0213e7566dd6df184afb4bbdab7d267fb988f5f901680f5ca1af43b2a6441d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
