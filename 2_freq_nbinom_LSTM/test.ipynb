{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_forecasting import DeepAR\n",
    "\n",
    "checkpoint = torch.load('epoch=1-step=60.ckpt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(checkpoint['optimizer_states'])\n",
    "best_tft = DeepAR.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n",
    "from pytorch_forecasting import Baseline\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import SMAPE\n",
    "\n",
    "df = pd.DataFrame({\"cat\":np.array(['rain','shine','drizzle','hail','storm',\"shine\",\"rain\",\"hail\",\"drizzle\"])})\n",
    "df[\"time_idx\"] = np.arange(0,len(df))\n",
    "df[\"group\"] = np.tile(0,len(df))\n",
    "df[\"value\"] = np.random.rand(len(df))\n",
    "df[\"temp\"] = np.arange(325,325+len(df))\n",
    "Target = \"value\"\n",
    "\n",
    "\n",
    "df[\"date\"] = pd.Timestamp(\"2021-09-24\") + pd.to_timedelta(df.time_idx, \"H\")\n",
    "df['_hour_of_day'] = df[\"date\"].dt.hour.astype(str)\n",
    "df['_day_of_week'] = df[\"date\"].dt.dayofweek.astype(str)\n",
    "df['_day_of_month'] = df[\"date\"].dt.day.astype(str)\n",
    "df['_day_of_year'] = df[\"date\"].dt.dayofyear.astype(str)\n",
    "df['_week_of_year'] = df[\"date\"].dt.weekofyear.astype(str)\n",
    "df['_month_of_year'] = df[\"date\"].dt.month.astype(str)\n",
    "df['_year'] = df[\"date\"].dt.year.astype(str)\n",
    "\n",
    "max_encoder_length = 3\n",
    "max_prediction_length = 2\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    df.iloc[0:len(df)],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=Target,\n",
    "    categorical_encoders={\"cat\": NaNLabelEncoder(add_nan=True).fit(df.cat), \"_hour_of_day\": NaNLabelEncoder(add_nan=True).fit(df._hour_of_day), \\\n",
    "       \"_day_of_week\": NaNLabelEncoder(add_nan=True).fit(df._day_of_week), \"_day_of_month\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_month), \"_day_of_year\" : NaNLabelEncoder(add_nan=True).fit(df._day_of_year), \\\n",
    "        \"_week_of_year\": NaNLabelEncoder(add_nan=True).fit(df._week_of_year), \"_month_of_year\": NaNLabelEncoder(add_nan=True).fit(df._month_of_year) ,\"_year\": NaNLabelEncoder(add_nan=True).fit(df._year)},\n",
    "    group_ids=[\"group\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_categoricals=[\"cat\",\"_hour_of_day\",\"_day_of_week\",\"_day_of_month\",\"_day_of_year\",\"_week_of_year\",\"_month_of_year\",\"_year\"],\n",
    "    time_varying_unknown_reals=[Target,\"temp\"],\n",
    "    add_relative_time_idx=False,\n",
    "    randomize_length=None,\n",
    "    scalers={},\n",
    "    target_normalizer=TorchNormalizer(method=\"identity\",center=False,transformation=None )\n",
    "\n",
    ")\n",
    "\n",
    "batch_size = 2\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "print(df)\n",
    "print(train_dataset.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder_cat': tensor([[[3, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [4, 2, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 3, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[1, 3, 1, 1, 1, 1, 1, 1],\n",
      "         [2, 4, 1, 1, 1, 1, 1, 1],\n",
      "         [5, 5, 1, 1, 1, 1, 1, 1]]]), 'encoder_cont': tensor([[[ 0.1738, -1.5492],\n",
      "         [ 0.8419, -1.1619],\n",
      "         [ 0.7271, -0.7746]],\n",
      "\n",
      "        [[ 0.7271, -0.7746],\n",
      "         [ 0.6414, -0.3873],\n",
      "         [ 0.0627,  0.0000]]]), 'encoder_target': tensor([[0.1738, 0.8419, 0.7271],\n",
      "        [0.7271, 0.6414, 0.0627]]), 'encoder_lengths': tensor([3, 3]), 'decoder_cat': tensor([[[2, 4, 1, 1, 1, 1, 1, 1],\n",
      "         [5, 5, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[4, 6, 1, 1, 1, 1, 1, 1],\n",
      "         [3, 7, 1, 1, 1, 1, 1, 1]]]), 'decoder_cont': tensor([[[ 0.6414, -0.3873],\n",
      "         [ 0.0627,  0.0000]],\n",
      "\n",
      "        [[ 0.7052,  0.3873],\n",
      "         [ 0.3445,  0.7746]]]), 'decoder_target': tensor([[0.6414, 0.0627],\n",
      "        [0.7052, 0.3445]]), 'decoder_lengths': tensor([2, 2]), 'decoder_time_idx': tensor([[3, 4],\n",
      "        [5, 6]]), 'groups': tensor([[0],\n",
      "        [0]]), 'target_scale': tensor([[0., 1.],\n",
      "        [0., 1.]])}\n",
      "{'encoder_cat': tensor([[[4, 2, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 3, 1, 1, 1, 1, 1, 1],\n",
      "         [2, 4, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 4, 1, 1, 1, 1, 1, 1],\n",
      "         [5, 5, 1, 1, 1, 1, 1, 1],\n",
      "         [4, 6, 1, 1, 1, 1, 1, 1]]]), 'encoder_cont': tensor([[[ 0.8419, -1.1619],\n",
      "         [ 0.7271, -0.7746],\n",
      "         [ 0.6414, -0.3873]],\n",
      "\n",
      "        [[ 0.6414, -0.3873],\n",
      "         [ 0.0627,  0.0000],\n",
      "         [ 0.7052,  0.3873]]]), 'encoder_target': tensor([[0.8419, 0.7271, 0.6414],\n",
      "        [0.6414, 0.0627, 0.7052]]), 'encoder_lengths': tensor([3, 3]), 'decoder_cat': tensor([[[5, 5, 1, 1, 1, 1, 1, 1],\n",
      "         [4, 6, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "        [[3, 7, 1, 1, 1, 1, 1, 1],\n",
      "         [2, 8, 1, 1, 1, 1, 1, 1]]]), 'decoder_cont': tensor([[[0.0627, 0.0000],\n",
      "         [0.7052, 0.3873]],\n",
      "\n",
      "        [[0.3445, 0.7746],\n",
      "         [0.9612, 1.1619]]]), 'decoder_target': tensor([[0.0627, 0.7052],\n",
      "        [0.3445, 0.9612]]), 'decoder_lengths': tensor([2, 2]), 'decoder_time_idx': tensor([[4, 5],\n",
      "        [6, 7]]), 'groups': tensor([[0],\n",
      "        [0]]), 'target_scale': tensor([[0., 1.],\n",
      "        [0., 1.]])}\n",
      "tensor([[0.6414, 0.6414],\n",
      "        [0.3445, 0.3445],\n",
      "        [0.7271, 0.7271],\n",
      "        [0.0627, 0.0627]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate baseline absolute error\n",
    "actuals = torch.cat([y[0] for x, y in iter(train_dataloader)])\n",
    "for x, y in iter(train_dataloader):\n",
    "    print(x)\n",
    "baseline_predictions = Baseline().predict(train_dataloader)\n",
    "\n",
    "\n",
    "print(baseline_predictions)\n",
    "\n",
    "SMAPE()(baseline_predictions, actuals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0213e7566dd6df184afb4bbdab7d267fb988f5f901680f5ca1af43b2a6441d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
