{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_forecasting import NegativeBinomialDistributionLoss, DeepAR\n",
    "import torch\n",
    "from pytorch_forecasting.data.encoders import TorchNormalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>0</td>\n",
       "      <td>5014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>0</td>\n",
       "      <td>5015</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>0</td>\n",
       "      <td>5016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>0</td>\n",
       "      <td>5017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>0</td>\n",
       "      <td>5018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5019 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      series  time_idx  value\n",
       "0          0         0      0\n",
       "1          0         1      0\n",
       "2          0         2      0\n",
       "3          0         3     12\n",
       "4          0         4      0\n",
       "...      ...       ...    ...\n",
       "5014       0      5014      0\n",
       "5015       0      5015     12\n",
       "5016       0      5016      0\n",
       "5017       0      5017      0\n",
       "5018       0      5018      0\n",
       "\n",
       "[5019 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('1_f_nbinom_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "4399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josepeeterson.er\\AppData\\Local\\Temp\\ipykernel_22536\\2062568536.py:8: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  data['_week_of_year'] = str(data[\"date\"].dt.weekofyear)\n"
     ]
    }
   ],
   "source": [
    "data[\"date\"] = pd.Timestamp(\"2021-08-24\") + pd.to_timedelta(data.time_idx, \"H\")\n",
    "\n",
    "\n",
    "data['_hour_of_day'] = str(data[\"date\"].dt.hour)\n",
    "data['_day_of_week'] = str(data[\"date\"].dt.dayofweek)\n",
    "data['_day_of_month'] = str(data[\"date\"].dt.day)\n",
    "data['_day_of_year'] = str(data[\"date\"].dt.dayofyear)\n",
    "data['_week_of_year'] = str(data[\"date\"].dt.weekofyear)\n",
    "data['_month_of_year'] = str(data[\"date\"].dt.month)\n",
    "data['_year'] = str(data[\"date\"].dt.year)\n",
    "\n",
    "data['value'] = data['value'].astype(float)\n",
    "print(type(data['value'][0])) \n",
    "print(len(data.iloc[0:-620]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 60\n",
    "max_prediction_length = 20\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data.iloc[0:-620],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    categorical_encoders={\"series\": NaNLabelEncoder(add_nan=True).fit(data.series), \"_hour_of_day\": NaNLabelEncoder(add_nan=True).fit(data._hour_of_day), \\\n",
    "       \"_day_of_week\": NaNLabelEncoder(add_nan=True).fit(data._day_of_week), \"_day_of_month\" : NaNLabelEncoder(add_nan=True).fit(data._day_of_month), \"_day_of_year\" : NaNLabelEncoder(add_nan=True).fit(data._day_of_year), \\\n",
    "        \"_week_of_year\": NaNLabelEncoder(add_nan=True).fit(data._week_of_year), \"_year\": NaNLabelEncoder(add_nan=True).fit(data._year)},\n",
    "    group_ids=[\"series\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"value\"],\n",
    "    time_varying_known_categoricals=[\"_hour_of_day\",\"_day_of_week\",\"_day_of_month\",\"_day_of_year\",\"_week_of_year\",\"_year\" ],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    add_relative_time_idx=False,\n",
    "    randomize_length=None,\n",
    "    scalers=[],\n",
    "    target_normalizer=TorchNormalizer(method=\"identity\",center=False,transformation=None )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    data.iloc[-620:-420],\n",
    "    # predict=True,\n",
    "    stop_randomization=True,\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=8)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "training.save(\"training.pkl\")\n",
    "validation.save(\"validation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    gpus=0,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,\n",
    "    limit_val_batches=3,\n",
    "    # fast_dev_run=True,\n",
    "    # logger=logger,\n",
    "    # profiler=True,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepar = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.1,\n",
    "    hidden_size=32,\n",
    "    dropout=0.1,\n",
    "    loss=NegativeBinomialDistributionLoss(),\n",
    "    log_interval=10,\n",
    "    log_val_interval=3,\n",
    "    # reduce_on_plateau_patience=3,\n",
    ")\n",
    "print(f\"Number of parameters in network: {deepar.size()/1e3:.1f}k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #find optimal learning rate\n",
    "# deepar.hparams.log_interval = -1\n",
    "# deepar.hparams.log_val_interval = -1\n",
    "# trainer.limit_train_batches = 1.0\n",
    "# res = trainer.tuner.lr_find(\n",
    "#     deepar, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5, max_lr=1e2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                   | Type                             | Params\n",
      "----------------------------------------------------------------------------\n",
      "0 | loss                   | NegativeBinomialDistributionLoss | 0     \n",
      "1 | logging_metrics        | ModuleList                       | 0     \n",
      "2 | embeddings             | MultiEmbedding                   | 12    \n",
      "3 | rnn                    | LSTM                             | 13.8 K\n",
      "4 | distribution_projector | Linear                           | 66    \n",
      "----------------------------------------------------------------------------\n",
      "13.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.9 K    Total params\n",
      "0.056     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:428: UserWarning: The number of training samples (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:36<00:00,  3.03s/it, loss=1.92, v_num=17, train_loss_step=1.550, val_loss=1.590, train_loss_epoch=2.190]\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(10)\n",
    "trainer.fit(\n",
    "    deepar,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:24<00:00, 12.02s/ batches]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Work\\WORK_PACKAGE\\Demand_forecasting\\github\\pytorch-forecasting\\My_model\\My_demo.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/pytorch-forecasting/My_model/My_demo.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(actuals\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/pytorch-forecasting/My_model/My_demo.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m deepar\u001b[39m.\u001b[39mpredict(data\u001b[39m=\u001b[39mval_dataloader,mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m,return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Work/WORK_PACKAGE/Demand_forecasting/github/pytorch-forecasting/My_model/My_demo.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMean absolute error of model: \u001b[39m\u001b[39m{\u001b[39;00m(actuals \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mtensor(predictions))\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmean()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\josepeeterson.er\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "\n",
    "print(actuals.shape)\n",
    "\n",
    "predictions = deepar.predict(data=val_dataloader,mode='prediction',return_index=True,num_workers=8,show_progress_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean absolute error of model: {(actuals - torch.tensor(predictions)).abs().mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([121, 20])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(actuals.shape)\n",
    "print(len(predictions[0][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0213e7566dd6df184afb4bbdab7d267fb988f5f901680f5ca1af43b2a6441d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
